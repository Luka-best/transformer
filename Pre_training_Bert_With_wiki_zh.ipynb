{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pre-training-Bert-With-wiki_zh.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hellozhaojian/transformers/blob/master/Pre_training_Bert_With_wiki_zh.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVHz0pRPpTFl",
        "colab_type": "text"
      },
      "source": [
        "**简介**\n",
        "\n",
        "该文档描述了如何从零开始用TPU训练模型。\n",
        "前提假设：\n",
        "\n",
        "1. 有一个google cloud账号， 创建一个项目；创建一个bucket\n",
        "2. 有google drive账号\n",
        "\n",
        "操作步骤：\n",
        "  1. 安装必要软件。主要安装sentencepiece和bert\n",
        "  2. 测试运行环境。\n",
        "  3. 准备语料。将google drive 上的数据挂载到当前的运行环境。\n",
        "  4. 准备wordpiece词典。 并将结果转换为wordpiece需要的格式（支持中文)\n",
        "  5. 训练环境准备。\n",
        "  \n",
        "     准备训练数据。执行bert里的数据准的脚本生成tf-record格式的数据。\n",
        "     将tf-record，wordpiece词典，以及bert的配置文件拷贝的google cloud的文件系统中。\n",
        "  6. TPU训练。\n",
        "  7. 拷贝预训练模型。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTBogSVYmov-",
        "colab_type": "text"
      },
      "source": [
        "**一、安装必要的软件**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8reiP_Fn65F",
        "colab_type": "code",
        "outputId": "e7dad9cb-4df2-4a70-ef17-cf1651cf926d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install sentencepiece\n",
        "!git clone https://github.com/google-research/bert"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.83)\n",
            "fatal: destination path 'bert' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSd1IOWEoWXe",
        "colab_type": "text"
      },
      "source": [
        "**二、测试运行环境**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVWN1jVTofc-",
        "colab_type": "code",
        "outputId": "d8b9a312-1924-4756-bdc4-1f7fc847ab80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import nltk\n",
        "import random\n",
        "import logging\n",
        "import tensorflow as tf\n",
        "import sentencepiece as spm\n",
        "\n",
        "from glob import glob\n",
        "from google.colab import auth, drive\n",
        "from tensorflow.keras.utils import Progbar\n",
        "\n",
        "sys.path.append(\"bert\")\n",
        "\n",
        "from bert import modeling, optimization, tokenization\n",
        "from bert.run_pretraining import input_fn_builder, model_fn_builder\n",
        "print(tf.__version__)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLb7ibxJyMNB",
        "colab_type": "text"
      },
      "source": [
        "**三、准备语料**\n",
        "\n",
        "* 挂载google drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lA6xcchvruA",
        "colab_type": "code",
        "outputId": "96dbec1e-7805-447e-8b53-36dc234192aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dataset_file = \"/content/drive/My Drive/data/wiki.txt\"\n",
        "bert_meta_dir = \"/content/drive/My Drive/bert/\"\n",
        "! mkdir -p bert_meta_dir"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tKrEkEpTi7e",
        "colab_type": "text"
      },
      "source": [
        "* 语料截断"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE7O1Cx1U-Pl",
        "colab_type": "code",
        "outputId": "b582e045-ad23-4e48-c267-96a633090246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "DEMO_MODE = True #@param {type:\"boolean\"}\n",
        "\n",
        "if DEMO_MODE:\n",
        "  CORPUS_SIZE = 100000\n",
        "else:\n",
        "  CORPUS_SIZE = 100000000 #@param {type: \"integer\"}\n",
        "! wc -l \"/content/drive/My Drive/data/wiki.txt\"\n",
        "! (head -n $CORPUS_SIZE \"/content/drive/My Drive/data/wiki.txt\") > dataset.txt\n",
        "! head dataset.txt\n",
        "! wc -l dataset.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5249001 /content/drive/My Drive/data/wiki.txt\n",
            "燕顺，是《水浒传》人物，山东莱州人氏，赤色黄发，人称「锦毛虎」。原是羊马商人出身，后来本钱用光，便流落至清风山打劫，为清风山贼王，手下有王英及郑天寿。\n",
            "一次，宋江路过清风山，被山贼绑了，押往寨主燕顺处。燕顺的喽啰正要剖开宋江的心肝，宋江悲叹大喊「想不到我宋江竟要命丧于此!」，燕顺闻得宋江名号便下令叫停，领自己的手下一同向宋江下拜。\n",
            "宋江在清风山救了清风寨知寨刘高的妻子，但她恩将仇报，要刘高抓了宋江。当黄信押着宋江和花荣途经清风山时，燕顺等人前往劫囚，救出二人。然后，清风山一伙连同花荣与秦明都上了梁山泊。\n",
            "燕顺为马军小彪将兼远探出哨头领第十一员，后来随征辽国、方腊，在乌龙岭被方腊大将石宝的流星锤打死。\n",
            "六里屯街道\n",
            "六里屯街道是北京市朝阳区东部的一个街道办事处，前身为星火人民公社，辖区内的星火站因此得名（现属东风地区）。\n",
            "始建于1987年。东起双沙铁路，南至二道沟河，西邻团结湖街道，北到农展南路。面积4.4平方公里，常住人口8.9万。\n",
            "六里屯街道目前下辖的社区有：\n",
            "奇幻文学\n",
            "奇幻文学是指文学类的奇幻作品，主要表达于奇幻小说。广义上含有奇幻要素的文学作品也包括在内，玄幻小说、武侠小说与古代流传的童话、神话、民间传奇故事。\n",
            "100000 dataset.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAydONkxX6Bt",
        "colab_type": "text"
      },
      "source": [
        "**四、准备wordpiece的词典**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABFu1vM9UcSf",
        "colab_type": "text"
      },
      "source": [
        "* 训练sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xlq5-OvWX244",
        "colab_type": "code",
        "outputId": "599cc7f7-846f-4dff-aa39-7065aec1b6e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "PRC_DATA_FPATH = \"dataset.txt\"\n",
        "MODEL_PREFIX = \"tokenizer\" #@param {type: \"string\"}\n",
        "VOC_SIZE = 32000 #@param {type:\"integer\"}\n",
        "SUBSAMPLE_SIZE = 12800000 #@param {type:\"integer\"}\n",
        "NUM_PLACEHOLDERS = 256 #@param {type:\"integer\"}\n",
        "\n",
        "SPM_COMMAND = ('--input={} --model_prefix={} '\n",
        "               '--vocab_size={} --input_sentence_size={} '\n",
        "               '--shuffle_input_sentence=true ' \n",
        "               '--bos_id=-1 --eos_id=-1').format(\n",
        "               PRC_DATA_FPATH, MODEL_PREFIX, \n",
        "               VOC_SIZE - NUM_PLACEHOLDERS, SUBSAMPLE_SIZE)\n",
        "print(SPM_COMMAND)\n",
        "spm.SentencePieceTrainer.Train(SPM_COMMAND)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--input=dataset.txt --model_prefix=tokenizer --vocab_size=31744 --input_sentence_size=12800000 --shuffle_input_sentence=true --bos_id=-1 --eos_id=-1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJXPLj8G28fq",
        "colab_type": "text"
      },
      "source": [
        "* 测试sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhm_fwDg2wyC",
        "colab_type": "code",
        "outputId": "ed007271-2314-47a0-86de-212928a88ed0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load('{}.model'.format(MODEL_PREFIX))\n",
        "token_list =  sp.encode_as_pieces(\"这是一个测试，你要看看吗\")\n",
        "print(token_list)\n",
        "! ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['▁', '这是一个', '测试', ',', '你', '要', '看', '看', '吗']\n",
            "adc.json       bert_model   pretraining_data  tokenizer.model\n",
            "bert\t       dataset.txt  sample_data       tokenizer.vocab\n",
            "bert_meta_dir  drive\t    shards\t      vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KtBz0OLU3Ur",
        "colab_type": "text"
      },
      "source": [
        "* 将sentencepiece的词典 修正为wordpiece对应的词典\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrqDLdq4B3Ru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import unicodedata\n",
        "\n",
        "def _is_whitespace(char):\n",
        "  \"\"\"Checks whether `chars` is a whitespace character.\"\"\"\n",
        "  # \\t, \\n, and \\r are technically contorl characters but we treat them\n",
        "  # as whitespace since they are generally considered as such.\n",
        "  if char == \" \" or char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
        "    return True\n",
        "  cat = unicodedata.category(char)\n",
        "  if cat == \"Zs\":\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "\n",
        "def _is_control(char):\n",
        "  \"\"\"Checks whether `chars` is a control character.\"\"\"\n",
        "  # These are technically control characters but we count them as whitespace\n",
        "  # characters.\n",
        "  if char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
        "    return False\n",
        "  cat = unicodedata.category(char)\n",
        "  if cat in (\"Cc\", \"Cf\"):\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "\n",
        "def _is_punctuation(char):\n",
        "  \"\"\"Checks whether `chars` is a punctuation character.\"\"\"\n",
        "  cp = ord(char)\n",
        "  # We treat all non-letter/number ASCII as punctuation.\n",
        "  # Characters such as \"^\", \"$\", and \"`\" are not in the Unicode\n",
        "  # Punctuation class but we treat them as punctuation anyways, for\n",
        "  # consistency.\n",
        "  if ((cp >= 33 and cp <= 47) or (cp >= 58 and cp <= 64) or\n",
        "      (cp >= 91 and cp <= 96) or (cp >= 123 and cp <= 126)):\n",
        "    return True\n",
        "  cat = unicodedata.category(char)\n",
        "  if cat.startswith(\"P\"):\n",
        "    return True\n",
        "  return False\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GruDbQeY0nMI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "109eb50e-47fb-4b0c-8d01-b433a957191a"
      },
      "source": [
        "def parse_sentencepiece_token(token) :\n",
        "    \"\"\"\n",
        "    sentencepiece用特殊符号 \"▁\"截断字符串，而wordpiece用的是 ##, 该函数将sentencepiece学习出来的词映射为woedpiece的词。\n",
        "    \"\"\"\n",
        "    \n",
        "    def _is_chinese_char( cp):\n",
        "        \"\"\"Checks whether CP is the codepoint of a CJK character.\"\"\"\n",
        "        # This defines a \"chinese character\" as anything in the CJK Unicode block:\n",
        "        #   https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)\n",
        "        #\n",
        "        # Note that the CJK Unicode block is NOT all Japanese and Korean characters,\n",
        "        # despite its name. The modern Korean Hangul alphabet is a different block,\n",
        "        # as is Japanese Hiragana and Katakana. Those alphabets are used to write\n",
        "        # space-separated words, so they are not treated specially and handled\n",
        "        # like the all of the other languages.\n",
        "        if ((cp >= 0x4E00 and cp <= 0x9FFF) or  #\n",
        "            (cp >= 0x3400 and cp <= 0x4DBF) or  #\n",
        "            (cp >= 0x20000 and cp <= 0x2A6DF) or  #\n",
        "            (cp >= 0x2A700 and cp <= 0x2B73F) or  #\n",
        "            (cp >= 0x2B740 and cp <= 0x2B81F) or  #\n",
        "            (cp >= 0x2B820 and cp <= 0x2CEAF) or\n",
        "            (cp >= 0xF900 and cp <= 0xFAFF) or  #\n",
        "            (cp >= 0x2F800 and cp <= 0x2FA1F)):  #\n",
        "            return True\n",
        "    \n",
        "    if token.startswith('▁'):\n",
        "        return token[1:]\n",
        "    if len(list(token)) == 1 and (_is_chinese_char(ord(token)) or _is_punctuation(token) or _is_control(token)  or _is_whitespace(token)):\n",
        "        return token\n",
        "    else:\n",
        "        return  \"##\" + token\n",
        "    \n",
        "def strQ2B(ustring):\n",
        "    ss = []\n",
        "    for s in ustring:\n",
        "        rstring = \"\"\n",
        "        for uchar in s:\n",
        "            inside_code = ord(uchar)\n",
        "            if inside_code == 12288:  # 全角空格直接转换\n",
        "                inside_code = 32\n",
        "            elif (inside_code >= 65281 and inside_code <= 65374):  # 全角字符（除空格）根据关系转化\n",
        "                inside_code -= 65248\n",
        "            rstring += chr(inside_code)\n",
        "        ss.append(rstring)\n",
        "    return \"\".join(ss)\n",
        "\n",
        "print(list(map(parse_sentencepiece_token, token_list)))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', '##这是一个', '##测试', ',', '你', '要', '看', '看', '吗']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJIxWxo02KGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOC_FNAME = \"vocab.txt\" #@param {type:\"string\"}\n",
        "\n",
        "voc_file = \"{}.vocab\".format(MODEL_PREFIX)\n",
        "\n",
        "def read_sentencepiece_vocab(file_path):\n",
        "    voc = []\n",
        "    for line in open(file_path, \"r\"):\n",
        "        voc.append(line.strip().split(\"\\t\")[0])\n",
        "    voc = voc[1:]\n",
        "    return voc\n",
        "voc_words = read_sentencepiece_vocab(voc_file)\n",
        "\n",
        "new_voc_words = list(map(parse_sentencepiece_token, voc_words))\n",
        "\n",
        "ctrl_symbols =  [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
        "bert_words = ctrl_symbols +  new_voc_words\n",
        "\n",
        "bert_words += [\"[UNUSED_{}]\".format(i) for i in range(VOC_SIZE - len(bert_words))]\n",
        "\n",
        "\n",
        "fo =  open(VOC_FNAME, \"w\", encoding='utf-8')\n",
        "for token in bert_words:\n",
        "    fo.write(token + \"\\n\")\n",
        "fo.close()\n",
        "! head -n 20 $VOC_FNAME\n",
        "! tail -n 10 $VOC_FNAME\n",
        "bert_tokenizer = tokenization.FullTokenizer(VOC_FNAME)\n",
        "\n",
        "print(bert_tokenizer.tokenize(strQ2B(\"这是一个测试，你要看看吗, what are you doing here\")))\n",
        "print(bert_tokenizer.tokenize(\"Colorless geothermal substations are generating furiously\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ppu3RglVY0J9",
        "colab_type": "text"
      },
      "source": [
        "***五、训练环境准备***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrbbsPq5Wldd",
        "colab_type": "text"
      },
      "source": [
        "* 准备tf-record文件\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2fdGJSqZ-YM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "9b66c360-a7a7-4192-be2f-d86dfbdd2baa"
      },
      "source": [
        "! rm -rf shards\n",
        "! mkdir ./shards\n",
        "# 将文件切成多分，每一份最多250000行。 新的文件后缀用数字表示(-d), 用4位数字(-a 4)\n",
        "! split -a 4 -l 250000 -d dataset.txt ./shards/shard_d\n",
        "! ls ./shards/\n",
        "! wc -l ./shards/*\n",
        "! du -sm *"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shard_d0000\n",
            "100000 ./shards/shard_d0000\n",
            "1\tadc.json\n",
            "1\tbert\n",
            "1\tbert_meta_dir\n",
            "1\tbert_model\n",
            "26\tdataset.txt\n",
            "1167\tdrive\n",
            "214\tpretraining_data\n",
            "55\tsample_data\n",
            "26\tshards\n",
            "1\ttokenizer.model\n",
            "1\ttokenizer.vocab\n",
            "1\tvocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qhmf7Vxa9K4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SEQ_LENGTH = 128 #@param {type : \"integer\"}\n",
        "MASKED_LM_PROB = 0.15 #@param {type: \"number\" }\n",
        "# xxxx\n",
        "MAX_PREDICTIONS = 20 #@param {type: \"integer\"}\n",
        "DO_LOWER_CASE = True #@param {type: \"boolean\"}\n",
        "PROCESSES = 5 #@param {type: \"integer\"}\n",
        "PRETRAINING_DIR = \"pretraining_data\" #@param {type: \"string\"}\n",
        "GOOGLE_CLOUD_PROJECT_NAME = \"pre-train-bert-sogou\" #@param {type: \"string\"}\n",
        "BUCKET_NAME = \"bert-sogou-pretrain\"  #@param {type: \"string\"}\n",
        "\n",
        "MODEL_DIR = \"bert_model\" #@param {type: \"string\"}\n",
        "tf.gfile.MkDir(MODEL_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RcAG7rmb2fw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "XARGS_CMD = (\"ls ./shards/ | \"\n",
        "             \"xargs -n 1 -P {} -I{} \"\n",
        "             \"python3 bert/create_pretraining_data.py \"\n",
        "             \"--input_file=./shards/{} \"\n",
        "             \"--output_file={}/{}.tfrecord \"\n",
        "             \"--vocab_file={} \"\n",
        "             \"--do_lower_case={} \"\n",
        "             \"--max_predictions_per_seq={} \"\n",
        "             \"--max_seq_length={} \"\n",
        "             \"--masked_lm_prob={} \"\n",
        "             \"--random_seed=34 \"\n",
        "             \"--dupe_factor=5\")\n",
        "\n",
        "XARGS_CMD = XARGS_CMD.format(PROCESSES, '{}', '{}', PRETRAINING_DIR, '{}', \n",
        "                             VOC_FNAME, DO_LOWER_CASE, \n",
        "                             MAX_PREDICTIONS, MAX_SEQ_LENGTH, MASKED_LM_PROB)\n",
        "\n",
        "print (XARGS_CMD)\n",
        "tf.gfile.MkDir(PRETRAINING_DIR)\n",
        "! $XARGS_CMD\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wI2GA6IfOEv",
        "colab_type": "text"
      },
      "source": [
        "* 将bert相关的配置和数据上传到bucket里"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bn02ntc3fSjP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# use this for BERT-base\n",
        "\n",
        "bert_base_config = {\n",
        "  \"attention_probs_dropout_prob\": 0.1, \n",
        "  \"directionality\": \"bidi\", \n",
        "  \"hidden_act\": \"gelu\", \n",
        "  \"hidden_dropout_prob\": 0.1, \n",
        "  \"hidden_size\": 768, \n",
        "  \"initializer_range\": 0.02, \n",
        "  \"intermediate_size\": 3072, \n",
        "  \"max_position_embeddings\": 512, \n",
        "  \"num_attention_heads\": 12, \n",
        "  \"num_hidden_layers\": 12, \n",
        "  \"pooler_fc_size\": 768, \n",
        "  \"pooler_num_attention_heads\": 12, \n",
        "  \"pooler_num_fc_layers\": 3, \n",
        "  \"pooler_size_per_head\": 128, \n",
        "  \"pooler_type\": \"first_token_transform\", \n",
        "  \"type_vocab_size\": 2, \n",
        "  \"vocab_size\": VOC_SIZE\n",
        "}\n",
        "\n",
        "with open(\"{}/bert_config.json\".format(MODEL_DIR), \"w\") as fo:\n",
        "  json.dump(bert_base_config, fo, indent=2)\n",
        "  \n",
        "with open(\"{}/{}\".format(MODEL_DIR, VOC_FNAME), \"w\") as fo:\n",
        "  for token in bert_words:\n",
        "    fo.write(token+\"\\n\")\n",
        "\n",
        "! gcloud auth login\n",
        "! gcloud config set project $GOOGLE_CLOUD_PROJECT_NAME\n",
        "! gsutil -m cp -r $MODEL_DIR $PRETRAINING_DIR gs://$BUCKET_NAME\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDTUFOFWlAH2",
        "colab_type": "text"
      },
      "source": [
        "**六、TPU训练**\n",
        "\n",
        "* 链接TPU\n",
        "\n",
        "前提条件： 在项目$GOOGLE_CLOUD_PROJECT_NAME中已经申请了TPU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pqm33pCdlEGf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6975783e-a701-4d7b-99bd-cb58b2fb9c88"
      },
      "source": [
        "import logging\n",
        "log = logging.getLogger(\"pre-train-bert\")\n",
        "auth.authenticate_user()\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  log.info(\"Using TPU runtime\")\n",
        "  USE_TPU = True\n",
        "  TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "  with tf.Session(TPU_ADDRESS) as session:\n",
        "    print(TPU_ADDRESS)\n",
        "    log.info('TPU address is ' + TPU_ADDRESS)\n",
        "    # Upload credentials to TPU.\n",
        "    #with open('/content/adc.json', 'r') as f:\n",
        "    #  auth_info = json.load(f)\n",
        "    #tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "    tf.contrib.cloud.configure_gcs(session)\n",
        "else:\n",
        "  log.warning('Not connected to TPU runtime')\n",
        "  USE_TPU = False\n",
        "print(USE_TPU)\n",
        "\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "grpc://10.62.221.2:8470\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40Ru9ZuMXSS0",
        "colab_type": "text"
      },
      "source": [
        "* 设置训练参数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sGNRPOP1z0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Input data pipeline config\n",
        "TRAIN_BATCH_SIZE = 128 #@param {type:\"integer\"}\n",
        "MAX_PREDICTIONS = 20 #@param {type:\"integer\"}\n",
        "MAX_SEQ_LENGTH = 128 #@param {type:\"integer\"}\n",
        "MASKED_LM_PROB = 0.15 #@param\n",
        "\n",
        "# Training procedure config\n",
        "EVAL_BATCH_SIZE = 64\n",
        "LEARNING_RATE = 2e-5\n",
        "TRAIN_STEPS = 1000 #@param {type:\"integer\"}\n",
        "SAVE_CHECKPOINTS_STEPS = 25 #@param {type:\"integer\"}\n",
        "NUM_TPU_CORES = 8\n",
        "\n",
        "if BUCKET_NAME:\n",
        "  BUCKET_PATH = \"gs://{}\".format(BUCKET_NAME)\n",
        "else:\n",
        "  BUCKET_PATH = \".\"\n",
        "\n",
        "BERT_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, MODEL_DIR)\n",
        "DATA_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, PRETRAINING_DIR)\n",
        "\n",
        "VOCAB_FILE = os.path.join(BERT_GCS_DIR, VOC_FNAME)\n",
        "CONFIG_FILE = os.path.join(BERT_GCS_DIR, \"bert_config.json\")\n",
        "\n",
        "INIT_CHECKPOINT = tf.train.latest_checkpoint(BERT_GCS_DIR)\n",
        "\n",
        "bert_config = modeling.BertConfig.from_json_file(CONFIG_FILE)\n",
        "input_files = tf.gfile.Glob(os.path.join(DATA_GCS_DIR,'*tfrecord'))\n",
        "\n",
        "log.info(\"Using checkpoint: {}\".format(INIT_CHECKPOINT))\n",
        "log.info(\"Using {} data shards\".format(len(input_files)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNU5vVkGXWz_",
        "colab_type": "text"
      },
      "source": [
        "* 训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EQPY0SZF8ab",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "93110942-d01d-4e77-ec3b-b62ba3f30bfa"
      },
      "source": [
        "print(bert_config)\n",
        "\n",
        "model_fn = model_fn_builder(\n",
        "      bert_config=bert_config,\n",
        "      init_checkpoint=INIT_CHECKPOINT,\n",
        "      learning_rate=LEARNING_RATE,\n",
        "      num_train_steps=TRAIN_STEPS,\n",
        "      num_warmup_steps=10,\n",
        "      use_tpu=USE_TPU,\n",
        "      use_one_hot_embeddings=True)\n",
        "\n",
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "\n",
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    model_dir=BERT_GCS_DIR,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=SAVE_CHECKPOINTS_STEPS,\n",
        "        num_shards=NUM_TPU_CORES,\n",
        "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
        "\n",
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=USE_TPU,\n",
        "    model_fn=model_fn,\n",
        "    config=run_config,\n",
        "    train_batch_size=TRAIN_BATCH_SIZE,\n",
        "    eval_batch_size=EVAL_BATCH_SIZE)\n",
        "  \n",
        "train_input_fn = input_fn_builder(\n",
        "        input_files=input_files,\n",
        "        max_seq_length=MAX_SEQ_LENGTH,\n",
        "        max_predictions_per_seq=MAX_PREDICTIONS,\n",
        "        is_training=True)\n",
        "\n",
        "estimator.train(input_fn=train_input_fn, max_steps=TRAIN_STEPS)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bert.modeling.BertConfig object at 0x7f51e58f7710>\n",
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f51eaf25840>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://bert-sogou-pretrain/bert_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 25, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.62.221.2:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f51e3d41438>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.62.221.2:8470', '_evaluation_master': 'grpc://10.62.221.2:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=25, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f51eba81908>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.62.221.2:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 10425515327151257106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 3392928378319469628)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 8762502928553189596)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 11220768303371794376)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 9099487110777735969)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 9748976569726808127)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 9708255203154960367)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2942129184758599833)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 12300300899625414961)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 15069034782272189586)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 1192673176182659684)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Found small feature: next_sentence_labels [16, 1]\n",
            "INFO:tensorflow:Found small feature: next_sentence_labels [16, 1]\n",
            "INFO:tensorflow:Found small feature: next_sentence_labels [16, 1]\n",
            "INFO:tensorflow:Found small feature: next_sentence_labels [16, 1]\n",
            "INFO:tensorflow:Found small feature: next_sentence_labels [16, 1]\n",
            "INFO:tensorflow:Found small feature: next_sentence_labels [16, 1]\n",
            "INFO:tensorflow:Found small feature: next_sentence_labels [16, 1]\n",
            "INFO:tensorflow:Found small feature: next_sentence_labels [16, 1]\n",
            "INFO:tensorflow:*** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (16, 128)\n",
            "INFO:tensorflow:  name = input_mask, shape = (16, 128)\n",
            "INFO:tensorflow:  name = masked_lm_ids, shape = (16, 20)\n",
            "INFO:tensorflow:  name = masked_lm_positions, shape = (16, 20)\n",
            "INFO:tensorflow:  name = masked_lm_weights, shape = (16, 20)\n",
            "INFO:tensorflow:  name = next_sentence_labels, shape = (16, 1)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (16, 128)\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (32000, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = cls/predictions/transform/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = cls/predictions/transform/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = cls/predictions/output_bias:0, shape = (32000,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = cls/seq_relationship/output_weights:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = cls/seq_relationship/output_bias:0, shape = (2,), *INIT_FROM_CKPT*\n",
            "WARNING:tensorflow:From /content/bert/run_pretraining.py:160: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/run_pretraining.py:161: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
            "\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://bert-sogou-pretrain/bert_model/model.ckpt-100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 100 into gs://bert-sogou-pretrain/bert_model/model.ckpt.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 8 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Enqueue next (25) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (25) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 125 into gs://bert-sogou-pretrain/bert_model/model.ckpt.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:loss = 7.5700407, step = 125\n",
            "INFO:tensorflow:Enqueue next (25) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (25) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 150 into gs://bert-sogou-pretrain/bert_model/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.639995\n",
            "INFO:tensorflow:examples/sec: 81.9193\n",
            "INFO:tensorflow:Enqueue next (25) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (25) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (2, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 175 into gs://bert-sogou-pretrain/bert_model/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.704204\n",
            "INFO:tensorflow:examples/sec: 90.1381\n",
            "INFO:tensorflow:Enqueue next (25) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (25) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 200 into gs://bert-sogou-pretrain/bert_model/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.735441\n",
            "INFO:tensorflow:examples/sec: 94.1365\n",
            "INFO:tensorflow:Enqueue next (25) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (25) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (4, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 225 into gs://bert-sogou-pretrain/bert_model/model.ckpt.\n",
            "INFO:tensorflow:loss = 7.1431074, step = 225 (145.222 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.681934\n",
            "INFO:tensorflow:examples/sec: 87.2875\n",
            "INFO:tensorflow:Enqueue next (25) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (25) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 250 into gs://bert-sogou-pretrain/bert_model/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.781896\n",
            "INFO:tensorflow:examples/sec: 100.083\n",
            "INFO:tensorflow:Enqueue next (25) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (25) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 275 into gs://bert-sogou-pretrain/bert_model/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.691966\n",
            "INFO:tensorflow:examples/sec: 88.5716\n",
            "INFO:tensorflow:Enqueue next (25) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (25) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 300 into gs://bert-sogou-pretrain/bert_model/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.728066\n",
            "INFO:tensorflow:examples/sec: 93.1925\n",
            "INFO:tensorflow:Enqueue next (25) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (25) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (8, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 325 into gs://bert-sogou-pretrain/bert_model/model.ckpt.\n",
            "INFO:tensorflow:loss = 7.284114, step = 325 (134.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.786973\n",
            "INFO:tensorflow:examples/sec: 100.733\n",
            "INFO:tensorflow:Enqueue next (25) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (25) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 350 into gs://bert-sogou-pretrain/bert_model/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.663997\n",
            "INFO:tensorflow:examples/sec: 84.9917\n",
            "INFO:tensorflow:Enqueue next (25) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (25) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (10, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 375 into gs://bert-sogou-pretrain/bert_model/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.794287\n",
            "INFO:tensorflow:examples/sec: 101.669\n",
            "INFO:tensorflow:Enqueue next (25) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (25) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 400 into gs://bert-sogou-pretrain/bert_model/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.783133\n",
            "INFO:tensorflow:examples/sec: 100.241\n",
            "INFO:tensorflow:Enqueue next (25) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (25) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (12, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 425 into gs://bert-sogou-pretrain/bert_model/model.ckpt.\n",
            "INFO:tensorflow:loss = 6.9597015, step = 425 (135.660 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.7224\n",
            "INFO:tensorflow:examples/sec: 92.4671\n",
            "INFO:tensorflow:Enqueue next (25) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (25) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 450 into gs://bert-sogou-pretrain/bert_model/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.712256\n",
            "INFO:tensorflow:examples/sec: 91.1688\n",
            "INFO:tensorflow:Enqueue next (25) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (25) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (14, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 475 into gs://bert-sogou-pretrain/bert_model/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.660971\n",
            "INFO:tensorflow:examples/sec: 84.6043\n",
            "INFO:tensorflow:Enqueue next (25) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (25) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 500 into gs://bert-sogou-pretrain/bert_model/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.627795\n",
            "INFO:tensorflow:examples/sec: 80.3578\n",
            "INFO:tensorflow:Enqueue next (25) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (25) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (16, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 525 into gs://bert-sogou-pretrain/bert_model/model.ckpt.\n",
            "INFO:tensorflow:loss = 6.9301157, step = 525 (146.924 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.731407\n",
            "INFO:tensorflow:examples/sec: 93.6201\n",
            "INFO:tensorflow:Enqueue next (25) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (25) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 550 into gs://bert-sogou-pretrain/bert_model/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.767516\n",
            "INFO:tensorflow:examples/sec: 98.2421\n",
            "INFO:tensorflow:Enqueue next (25) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (25) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (18, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 575 into gs://bert-sogou-pretrain/bert_model/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.80261\n",
            "INFO:tensorflow:examples/sec: 102.734\n",
            "INFO:tensorflow:Enqueue next (25) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (25) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 600 into gs://bert-sogou-pretrain/bert_model/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.712866\n",
            "INFO:tensorflow:examples/sec: 91.2469\n",
            "INFO:tensorflow:Enqueue next (25) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (25) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (20, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 625 into gs://bert-sogou-pretrain/bert_model/model.ckpt.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjeJmXvCXdQv",
        "colab_type": "text"
      },
      "source": [
        "**七、拷贝预训练的模型**\n",
        "\n",
        "\n",
        "模型存储在 $MODEL_DIR 下面。用户需要拷贝 vocb.txt, bert_config.json, 以及训练的模型文件。\n"
      ]
    }
  ]
}