{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "#   Eventually this will be a demo notebook and go in the right place       #\n",
    "#                                                                           #\n",
    "#   For now it has scratch work for showing current branch capabilities     #\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/connorhenderson/Desktop/fun/huggingface/transformers/env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/connorhenderson/Desktop/fun/huggingface/transformers/env/lib/python3.9/site-packages/jax/_src/lib/__init__.py:33: UserWarning: JAX on Mac ARM machines is experimental and minimally tested. Please see https://github.com/google/jax/issues/5501 in the event of problems.\n",
      "  warnings.warn(\"JAX on Mac ARM machines is experimental and minimally tested. \"\n"
     ]
    }
   ],
   "source": [
    "from transformers import FastSpeech2ConformerConfig, FastSpeech2ConformerModel\n",
    "import yaml\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "config_files = {'model_file': '/Users/connorhenderson/Desktop/fun/porting/from-pretrained/train.total_count.ave_5best.pth',\n",
    " 'train_config': '/Users/connorhenderson/Desktop/fun/porting/from-pretrained/config.yaml'}\n",
    "\n",
    "train_config_file = Path(config_files['train_config'])\n",
    "with train_config_file.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    args = yaml.safe_load(f)\n",
    "    args = argparse.Namespace(**args)\n",
    "    \n",
    "\n",
    "config = FastSpeech2ConformerConfig(**args.tts_conf['text2mel_params'])\n",
    "model = FastSpeech2ConformerModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastSpeech2ConformerModel(\n",
      "  (encoder): FastSpeech2ConformerEncoder(\n",
      "    (embed): Embedding(78, 384, padding_idx=0)\n",
      "    (pos_enc): RelPositionalEncoding(\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (encoders): ModuleList(\n",
      "      (0): EncoderLayer(\n",
      "        (self_attn): RelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (linear_k): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (linear_v): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (linear_out): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (linear_pos): Linear(in_features=384, out_features=384, bias=False)\n",
      "        )\n",
      "        (feed_forward): MultiLayeredConv1d(\n",
      "          (w_1): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (w_2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (feed_forward_macaron): MultiLayeredConv1d(\n",
      "          (w_1): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (w_2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (conv_module): FastSpeech2ConformerConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,), groups=384)\n",
      "          (norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (norm_ff): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (1): EncoderLayer(\n",
      "        (self_attn): RelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (linear_k): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (linear_v): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (linear_out): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (linear_pos): Linear(in_features=384, out_features=384, bias=False)\n",
      "        )\n",
      "        (feed_forward): MultiLayeredConv1d(\n",
      "          (w_1): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (w_2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (feed_forward_macaron): MultiLayeredConv1d(\n",
      "          (w_1): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (w_2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (conv_module): FastSpeech2ConformerConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,), groups=384)\n",
      "          (norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (norm_ff): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (2): EncoderLayer(\n",
      "        (self_attn): RelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (linear_k): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (linear_v): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (linear_out): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (linear_pos): Linear(in_features=384, out_features=384, bias=False)\n",
      "        )\n",
      "        (feed_forward): MultiLayeredConv1d(\n",
      "          (w_1): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (w_2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (feed_forward_macaron): MultiLayeredConv1d(\n",
      "          (w_1): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (w_2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (conv_module): FastSpeech2ConformerConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,), groups=384)\n",
      "          (norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (norm_ff): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (3): EncoderLayer(\n",
      "        (self_attn): RelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (linear_k): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (linear_v): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (linear_out): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (linear_pos): Linear(in_features=384, out_features=384, bias=False)\n",
      "        )\n",
      "        (feed_forward): MultiLayeredConv1d(\n",
      "          (w_1): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (w_2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (feed_forward_macaron): MultiLayeredConv1d(\n",
      "          (w_1): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (w_2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (conv_module): FastSpeech2ConformerConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,), groups=384)\n",
      "          (norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (norm_ff): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (duration_predictor): DurationPredictor(\n",
      "    (conv): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Conv1d(384, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (1): ReLU()\n",
      "        (2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (3): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (1): ReLU()\n",
      "        (2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (3): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (linear): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      "  (pitch_predictor): VariancePredictor(\n",
      "    (conv): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Conv1d(384, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "        (1): ReLU()\n",
      "        (2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "        (1): ReLU()\n",
      "        (2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "        (1): ReLU()\n",
      "        (2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "        (1): ReLU()\n",
      "        (2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "        (1): ReLU()\n",
      "        (2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (linear): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      "  (pitch_embed): Sequential(\n",
      "    (0): Conv1d(1, 384, kernel_size=(1,), stride=(1,))\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (energy_predictor): VariancePredictor(\n",
      "    (conv): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Conv1d(384, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (1): ReLU()\n",
      "        (2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (1): ReLU()\n",
      "        (2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (linear): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      "  (energy_embed): Sequential(\n",
      "    (0): Conv1d(1, 384, kernel_size=(1,), stride=(1,))\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (length_regulator): LengthRegulator()\n",
      "  (decoder): FastSpeech2ConformerEncoder(\n",
      "    (pos_enc): Sequential(\n",
      "      (0): RelPositionalEncoding(\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (encoders): ModuleList(\n",
      "      (0): EncoderLayer(\n",
      "        (self_attn): RelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (linear_k): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (linear_v): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (linear_out): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (linear_pos): Linear(in_features=384, out_features=384, bias=False)\n",
      "        )\n",
      "        (feed_forward): MultiLayeredConv1d(\n",
      "          (w_1): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (w_2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (feed_forward_macaron): MultiLayeredConv1d(\n",
      "          (w_1): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (w_2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (conv_module): FastSpeech2ConformerConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(384, 384, kernel_size=(31,), stride=(1,), padding=(15,), groups=384)\n",
      "          (norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (norm_ff): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (1): EncoderLayer(\n",
      "        (self_attn): RelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (linear_k): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (linear_v): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (linear_out): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (linear_pos): Linear(in_features=384, out_features=384, bias=False)\n",
      "        )\n",
      "        (feed_forward): MultiLayeredConv1d(\n",
      "          (w_1): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (w_2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (feed_forward_macaron): MultiLayeredConv1d(\n",
      "          (w_1): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (w_2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (conv_module): FastSpeech2ConformerConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(384, 384, kernel_size=(31,), stride=(1,), padding=(15,), groups=384)\n",
      "          (norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (norm_ff): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (2): EncoderLayer(\n",
      "        (self_attn): RelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (linear_k): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (linear_v): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (linear_out): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (linear_pos): Linear(in_features=384, out_features=384, bias=False)\n",
      "        )\n",
      "        (feed_forward): MultiLayeredConv1d(\n",
      "          (w_1): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (w_2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (feed_forward_macaron): MultiLayeredConv1d(\n",
      "          (w_1): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (w_2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (conv_module): FastSpeech2ConformerConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(384, 384, kernel_size=(31,), stride=(1,), padding=(15,), groups=384)\n",
      "          (norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (norm_ff): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (3): EncoderLayer(\n",
      "        (self_attn): RelPositionMultiHeadedAttention(\n",
      "          (linear_q): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (linear_k): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (linear_v): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (linear_out): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (linear_pos): Linear(in_features=384, out_features=384, bias=False)\n",
      "        )\n",
      "        (feed_forward): MultiLayeredConv1d(\n",
      "          (w_1): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (w_2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (feed_forward_macaron): MultiLayeredConv1d(\n",
      "          (w_1): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (w_2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (conv_module): FastSpeech2ConformerConvolutionModule(\n",
      "          (pointwise_conv1): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
      "          (depthwise_conv): Conv1d(384, 384, kernel_size=(31,), stride=(1,), padding=(15,), groups=384)\n",
      "          (norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise_conv2): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (norm_ff): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_mha): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_ff_macaron): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_conv): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (norm_final): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (feat_out): Linear(in_features=384, out_features=80, bias=True)\n",
      "  (postnet): PostNet(\n",
      "    (postnet): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Conv1d(80, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
      "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (2): Tanh()\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
      "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (2): Tanh()\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
      "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (2): Tanh()\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
      "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "        (2): Tanh()\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): Conv1d(256, 80, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
      "        (1): GroupNorm(20, 80, eps=1e-05, affine=True)\n",
      "        (2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (criterion): FastSpeech2ConformerLoss(\n",
      "    (l1_criterion): L1Loss()\n",
      "    (mse_criterion): MSELoss()\n",
      "    (duration_criterion): DurationPredictorLoss(\n",
      "      (criterion): MSELoss()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "def load_model_weights(model):\n",
    "    tts_task_state_dict = torch.load(config_files['model_file'], map_location=device)\n",
    "    def filter_and_modify_keys(obj):\n",
    "        new_obj = {}\n",
    "        for key in obj:\n",
    "            if \"tts.generator.text2mel.\" in key:\n",
    "                if \"postnet\" in key and(\"running\" in key or \"num_batches_tracked\" in key):\n",
    "                    continue\n",
    "                if \"encoder.embed.0.weight\" in key:\n",
    "                    new_obj[\"encoder.embed.weight\"] = obj[key]\n",
    "                    continue\n",
    "                new_key = key.replace(\"tts.generator.text2mel.\", \"\")\n",
    "                new_obj[new_key] = obj[key]\n",
    "        return new_obj\n",
    "    text2mel_state_dict = filter_and_modify_keys(tts_task_state_dict)\n",
    "    model.load_state_dict(text2mel_state_dict)\n",
    "\n",
    "load_model_weights(model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end torch.Size([1, 21, 384])\n",
      "end torch.Size([1, 180, 384])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import SpeechT5HifiGan\n",
    "\n",
    "# Currently poor, but working input_ids -> saved wav file example\n",
    "\n",
    "def write_example_to_file(model):\n",
    "    # tokenized version of \"test that this generates speech\"\n",
    "    batch = {'text': torch.tensor([ 4, 15,  6,  4,  9, 18,  4,  9, 12,  6, 40, 15,  3, 21, 47,  4,  6,  6,\n",
    "        17, 27, 39])} \n",
    "    # with torch.no_grad():\n",
    "    feat_gen = model.inference(**batch)\n",
    "    \n",
    "    vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n",
    "    output_dict = model.generate_speech(feat_gen=feat_gen, vocoder=vocoder)\n",
    "    \n",
    "    import soundfile\n",
    "    file = './audios/test.wav'\n",
    "    soundfile.write(file=file, data=output_dict[\"wav\"].cpu().numpy(), samplerate=22050)\n",
    "\n",
    "write_example_to_file(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
