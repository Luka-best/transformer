{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eli5_utils import *\n",
    "\n",
    "eli5_dbuilder = ELI5NLP(data_dir='eli5')\n",
    "eli5_dbuilder.download_and_prepare()\n",
    "\n",
    "eli5_train = eli5_dbuilder.as_dataset(split=nlp.splits.Split.TRAIN)\n",
    "eli5_valid = eli5_dbuilder.as_dataset(split=nlp.splits.Split.VALIDATION)\n",
    "eli5_test = eli5_dbuilder.as_dataset(split=nlp.splits.Split.TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0     0 of   539 \t L: 6.342 \t -- 9.093\n",
      " 0    10 of   539 \t L: 6.347 \t -- 95.173\n",
      " 0    20 of   539 \t L: 6.308 \t -- 182.368\n",
      " 0    30 of   539 \t L: 6.243 \t -- 271.287\n",
      " 0    40 of   539 \t L: 6.161 \t -- 362.347\n",
      " 0    50 of   539 \t L: 6.010 \t -- 454.841\n",
      " 0    60 of   539 \t L: 5.733 \t -- 545.507\n",
      " 0    70 of   539 \t L: 5.391 \t -- 638.503\n",
      " 0    80 of   539 \t L: 4.973 \t -- 729.353\n",
      " 0    90 of   539 \t L: 4.670 \t -- 818.165\n",
      " 0   100 of   539 \t L: 4.343 \t -- 908.974\n",
      " 0   110 of   539 \t L: 4.084 \t -- 997.924\n",
      " 0   120 of   539 \t L: 3.877 \t -- 1086.849\n",
      " 0   130 of   539 \t L: 3.733 \t -- 1176.005\n",
      " 0   140 of   539 \t L: 3.645 \t -- 1264.747\n",
      " 0   150 of   539 \t L: 3.508 \t -- 1353.476\n",
      " 0   160 of   539 \t L: 3.459 \t -- 1443.157\n",
      " 0   170 of   539 \t L: 3.384 \t -- 1530.991\n",
      " 0   180 of   539 \t L: 3.237 \t -- 1619.006\n",
      " 0   190 of   539 \t L: 3.172 \t -- 1706.880\n",
      " 0   200 of   539 \t L: 3.150 \t -- 1794.816\n",
      " 0   210 of   539 \t L: 3.081 \t -- 1883.141\n",
      " 0   220 of   539 \t L: 3.028 \t -- 1972.121\n",
      " 0   230 of   539 \t L: 2.967 \t -- 2062.746\n",
      " 0   240 of   539 \t L: 2.911 \t -- 2155.731\n",
      " 0   250 of   539 \t L: 2.875 \t -- 2246.224\n",
      " 0   260 of   539 \t L: 2.822 \t -- 2337.107\n",
      " 0   270 of   539 \t L: 2.793 \t -- 2427.606\n",
      " 0   280 of   539 \t L: 2.749 \t -- 2518.952\n",
      " 0   290 of   539 \t L: 2.725 \t -- 2608.530\n",
      " 0   300 of   539 \t L: 2.745 \t -- 2699.923\n",
      " 0   310 of   539 \t L: 2.655 \t -- 2789.493\n",
      " 0   320 of   539 \t L: 2.686 \t -- 2879.028\n",
      " 0   330 of   539 \t L: 2.651 \t -- 2972.974\n",
      " 0   340 of   539 \t L: 2.547 \t -- 3069.774\n",
      " 0   350 of   539 \t L: 2.559 \t -- 3163.787\n",
      " 0   360 of   539 \t L: 2.638 \t -- 3252.771\n",
      " 0   370 of   539 \t L: 2.527 \t -- 3346.647\n",
      " 0   380 of   539 \t L: 2.503 \t -- 3441.576\n",
      " 0   390 of   539 \t L: 2.469 \t -- 3534.482\n",
      " 0   400 of   539 \t L: 2.478 \t -- 3625.381\n",
      " 0   410 of   539 \t L: 2.440 \t -- 3718.733\n",
      " 0   420 of   539 \t L: 2.411 \t -- 3811.525\n",
      " 0   430 of   539 \t L: 2.412 \t -- 3905.725\n",
      " 0   440 of   539 \t L: 2.420 \t -- 3999.737\n",
      " 0   450 of   539 \t L: 2.394 \t -- 4091.376\n",
      " 0   460 of   539 \t L: 2.366 \t -- 4181.881\n",
      " 0   470 of   539 \t L: 2.337 \t -- 4270.397\n",
      " 0   480 of   539 \t L: 2.385 \t -- 4359.426\n",
      " 0   490 of   539 \t L: 2.317 \t -- 4448.014\n",
      " 0   500 of   539 \t L: 2.293 \t -- 4536.675\n",
      " 0   510 of   539 \t L: 2.294 \t -- 4625.007\n",
      " 0   520 of   539 \t L: 2.341 \t -- 4713.461\n",
      " 0   530 of   539 \t L: 2.204 \t -- 4801.910\n",
      "Saving model retriever_models/eli5_retriever_model_512\n",
      "Evaluation loss epoch    0: 1.713\n",
      " 1     0 of   539 \t L: 2.350 \t -- 8.934\n",
      " 1    10 of   539 \t L: 2.201 \t -- 96.900\n",
      " 1    20 of   539 \t L: 2.151 \t -- 185.026\n",
      " 1    30 of   539 \t L: 2.183 \t -- 273.156\n",
      " 1    40 of   539 \t L: 2.171 \t -- 361.171\n",
      " 1    50 of   539 \t L: 2.178 \t -- 450.035\n",
      " 1    60 of   539 \t L: 2.153 \t -- 537.995\n",
      " 1    70 of   539 \t L: 2.164 \t -- 626.447\n",
      " 1    80 of   539 \t L: 2.110 \t -- 714.392\n",
      " 1    90 of   539 \t L: 2.104 \t -- 802.158\n",
      " 1   100 of   539 \t L: 2.149 \t -- 889.788\n",
      " 1   110 of   539 \t L: 2.121 \t -- 977.645\n",
      " 1   120 of   539 \t L: 2.101 \t -- 1064.971\n",
      " 1   130 of   539 \t L: 2.090 \t -- 1152.275\n",
      " 1   140 of   539 \t L: 2.088 \t -- 1239.722\n",
      " 1   150 of   539 \t L: 2.034 \t -- 1327.366\n",
      " 1   160 of   539 \t L: 2.036 \t -- 1414.945\n",
      " 1   170 of   539 \t L: 2.053 \t -- 1502.534\n",
      " 1   180 of   539 \t L: 2.092 \t -- 1590.218\n",
      " 1   190 of   539 \t L: 2.028 \t -- 1677.420\n",
      " 1   200 of   539 \t L: 2.046 \t -- 1764.602\n",
      " 1   210 of   539 \t L: 2.049 \t -- 1851.849\n",
      " 1   220 of   539 \t L: 2.002 \t -- 1939.014\n",
      " 1   230 of   539 \t L: 1.946 \t -- 2026.262\n",
      " 1   240 of   539 \t L: 2.016 \t -- 2113.546\n",
      " 1   250 of   539 \t L: 2.011 \t -- 2200.666\n",
      " 1   260 of   539 \t L: 2.038 \t -- 2288.072\n",
      " 1   270 of   539 \t L: 2.007 \t -- 2375.174\n",
      " 1   280 of   539 \t L: 1.960 \t -- 2462.835\n",
      " 1   290 of   539 \t L: 2.034 \t -- 2549.955\n",
      " 1   300 of   539 \t L: 1.970 \t -- 2637.162\n",
      " 1   310 of   539 \t L: 2.032 \t -- 2724.414\n",
      " 1   320 of   539 \t L: 1.977 \t -- 2811.584\n",
      " 1   330 of   539 \t L: 1.974 \t -- 2898.795\n",
      " 1   340 of   539 \t L: 1.940 \t -- 2985.901\n",
      " 1   350 of   539 \t L: 1.950 \t -- 3072.879\n",
      " 1   360 of   539 \t L: 1.934 \t -- 3160.036\n",
      " 1   370 of   539 \t L: 1.928 \t -- 3247.173\n",
      " 1   380 of   539 \t L: 1.974 \t -- 3334.147\n",
      " 1   390 of   539 \t L: 1.911 \t -- 3421.536\n",
      " 1   400 of   539 \t L: 1.895 \t -- 3508.960\n",
      " 1   410 of   539 \t L: 1.921 \t -- 3596.352\n",
      " 1   420 of   539 \t L: 1.907 \t -- 3683.608\n",
      " 1   430 of   539 \t L: 1.877 \t -- 3770.862\n",
      " 1   440 of   539 \t L: 1.907 \t -- 3858.924\n",
      " 1   450 of   539 \t L: 1.922 \t -- 3946.525\n",
      " 1   460 of   539 \t L: 1.864 \t -- 4033.750\n",
      " 1   470 of   539 \t L: 1.877 \t -- 4122.410\n",
      " 1   480 of   539 \t L: 1.863 \t -- 4213.893\n",
      " 1   490 of   539 \t L: 1.904 \t -- 4307.157\n",
      " 1   500 of   539 \t L: 1.844 \t -- 4397.943\n",
      " 1   510 of   539 \t L: 1.881 \t -- 4486.529\n",
      " 1   520 of   539 \t L: 1.895 \t -- 4574.634\n",
      " 1   530 of   539 \t L: 1.829 \t -- 4668.125\n",
      "Saving model retriever_models/eli5_retriever_model_512\n",
      "Evaluation loss epoch    1: 1.397\n",
      " 2     0 of   539 \t L: 1.769 \t -- 8.883\n",
      " 2    10 of   539 \t L: 1.779 \t -- 97.343\n",
      " 2    20 of   539 \t L: 1.816 \t -- 186.048\n",
      " 2    30 of   539 \t L: 1.826 \t -- 274.522\n",
      " 2    40 of   539 \t L: 1.784 \t -- 363.541\n",
      " 2    50 of   539 \t L: 1.772 \t -- 452.202\n",
      " 2    60 of   539 \t L: 1.776 \t -- 540.803\n",
      " 2    70 of   539 \t L: 1.747 \t -- 629.113\n",
      " 2    80 of   539 \t L: 1.751 \t -- 717.682\n",
      " 2    90 of   539 \t L: 1.823 \t -- 806.034\n",
      " 2   100 of   539 \t L: 1.729 \t -- 894.803\n",
      " 2   110 of   539 \t L: 1.793 \t -- 983.560\n",
      " 2   120 of   539 \t L: 1.732 \t -- 1074.494\n",
      " 2   130 of   539 \t L: 1.827 \t -- 1162.376\n",
      " 2   140 of   539 \t L: 1.769 \t -- 1249.509\n",
      " 2   150 of   539 \t L: 1.730 \t -- 1336.568\n",
      " 2   160 of   539 \t L: 1.787 \t -- 1423.449\n",
      " 2   170 of   539 \t L: 1.738 \t -- 1510.269\n",
      " 2   180 of   539 \t L: 1.766 \t -- 1596.714\n",
      " 2   190 of   539 \t L: 1.769 \t -- 1683.049\n",
      " 2   200 of   539 \t L: 1.694 \t -- 1769.316\n",
      " 2   210 of   539 \t L: 1.766 \t -- 1855.988\n",
      " 2   220 of   539 \t L: 1.742 \t -- 1942.415\n",
      " 2   230 of   539 \t L: 1.734 \t -- 2028.900\n",
      " 2   240 of   539 \t L: 1.694 \t -- 2115.601\n",
      " 2   250 of   539 \t L: 1.755 \t -- 2202.366\n",
      " 2   260 of   539 \t L: 1.700 \t -- 2289.074\n",
      " 2   270 of   539 \t L: 1.778 \t -- 2375.846\n",
      " 2   280 of   539 \t L: 1.671 \t -- 2462.652\n",
      " 2   290 of   539 \t L: 1.707 \t -- 2549.209\n",
      " 2   300 of   539 \t L: 1.708 \t -- 2635.866\n",
      " 2   310 of   539 \t L: 1.700 \t -- 2722.262\n",
      " 2   320 of   539 \t L: 1.709 \t -- 2808.789\n",
      " 2   330 of   539 \t L: 1.760 \t -- 2895.261\n",
      " 2   340 of   539 \t L: 1.720 \t -- 2981.767\n",
      " 2   350 of   539 \t L: 1.668 \t -- 3068.285\n",
      " 2   360 of   539 \t L: 1.781 \t -- 3155.354\n",
      " 2   370 of   539 \t L: 1.691 \t -- 3242.488\n",
      " 2   380 of   539 \t L: 1.728 \t -- 3329.260\n",
      " 2   390 of   539 \t L: 1.659 \t -- 3416.205\n",
      " 2   400 of   539 \t L: 1.732 \t -- 3502.918\n",
      " 2   410 of   539 \t L: 1.671 \t -- 3589.826\n",
      " 2   420 of   539 \t L: 1.663 \t -- 3677.483\n",
      " 2   430 of   539 \t L: 1.672 \t -- 3764.369\n",
      " 2   440 of   539 \t L: 1.721 \t -- 3851.108\n",
      " 2   450 of   539 \t L: 1.727 \t -- 3938.233\n",
      " 2   460 of   539 \t L: 1.698 \t -- 4024.773\n",
      " 2   470 of   539 \t L: 1.705 \t -- 4111.350\n",
      " 2   480 of   539 \t L: 1.679 \t -- 4198.160\n",
      " 2   490 of   539 \t L: 1.624 \t -- 4284.929\n",
      " 2   500 of   539 \t L: 1.613 \t -- 4371.517\n",
      " 2   510 of   539 \t L: 1.660 \t -- 4458.120\n",
      " 2   520 of   539 \t L: 1.671 \t -- 4544.541\n",
      " 2   530 of   539 \t L: 1.653 \t -- 4631.149\n",
      "Saving model retriever_models/eli5_retriever_model_512\n",
      "Evaluation loss epoch    2: 1.250\n",
      " 3     0 of   539 \t L: 1.498 \t -- 8.647\n",
      " 3    10 of   539 \t L: 1.631 \t -- 95.021\n",
      " 3    20 of   539 \t L: 1.645 \t -- 181.679\n",
      " 3    30 of   539 \t L: 1.660 \t -- 268.471\n",
      " 3    40 of   539 \t L: 1.598 \t -- 354.983\n",
      " 3    50 of   539 \t L: 1.616 \t -- 441.479\n",
      " 3    60 of   539 \t L: 1.622 \t -- 527.893\n",
      " 3    70 of   539 \t L: 1.637 \t -- 614.028\n",
      " 3    80 of   539 \t L: 1.593 \t -- 700.188\n",
      " 3    90 of   539 \t L: 1.605 \t -- 786.523\n",
      " 3   100 of   539 \t L: 1.592 \t -- 872.595\n",
      " 3   110 of   539 \t L: 1.563 \t -- 958.589\n",
      " 3   120 of   539 \t L: 1.590 \t -- 1044.918\n",
      " 3   130 of   539 \t L: 1.581 \t -- 1131.569\n",
      " 3   140 of   539 \t L: 1.608 \t -- 1218.226\n",
      " 3   150 of   539 \t L: 1.604 \t -- 1304.433\n",
      " 3   160 of   539 \t L: 1.586 \t -- 1390.357\n",
      " 3   170 of   539 \t L: 1.627 \t -- 1476.350\n",
      " 3   180 of   539 \t L: 1.620 \t -- 1562.546\n",
      " 3   190 of   539 \t L: 1.541 \t -- 1648.640\n",
      " 3   200 of   539 \t L: 1.610 \t -- 1734.878\n",
      " 3   210 of   539 \t L: 1.596 \t -- 1821.352\n",
      " 3   220 of   539 \t L: 1.613 \t -- 1908.036\n",
      " 3   230 of   539 \t L: 1.615 \t -- 1994.816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3   240 of   539 \t L: 1.592 \t -- 2081.457\n",
      " 3   250 of   539 \t L: 1.572 \t -- 2167.973\n",
      " 3   260 of   539 \t L: 1.563 \t -- 2254.105\n",
      " 3   270 of   539 \t L: 1.565 \t -- 2340.173\n",
      " 3   280 of   539 \t L: 1.548 \t -- 2426.425\n",
      " 3   290 of   539 \t L: 1.610 \t -- 2512.734\n",
      " 3   300 of   539 \t L: 1.562 \t -- 2598.918\n",
      " 3   310 of   539 \t L: 1.535 \t -- 2685.304\n",
      " 3   320 of   539 \t L: 1.556 \t -- 2772.164\n",
      " 3   330 of   539 \t L: 1.557 \t -- 2858.908\n",
      " 3   340 of   539 \t L: 1.598 \t -- 2945.203\n",
      " 3   350 of   539 \t L: 1.581 \t -- 3031.560\n",
      " 3   360 of   539 \t L: 1.568 \t -- 3117.719\n",
      " 3   370 of   539 \t L: 1.534 \t -- 3204.090\n",
      " 3   380 of   539 \t L: 1.583 \t -- 3290.546\n",
      " 3   390 of   539 \t L: 1.542 \t -- 3376.847\n",
      " 3   400 of   539 \t L: 1.580 \t -- 3463.172\n",
      " 3   410 of   539 \t L: 1.558 \t -- 3549.349\n",
      " 3   420 of   539 \t L: 1.541 \t -- 3635.657\n",
      " 3   430 of   539 \t L: 1.567 \t -- 3722.059\n",
      " 3   440 of   539 \t L: 1.571 \t -- 3808.347\n",
      " 3   450 of   539 \t L: 1.557 \t -- 3894.831\n",
      " 3   460 of   539 \t L: 1.574 \t -- 3981.229\n",
      " 3   470 of   539 \t L: 1.508 \t -- 4067.668\n",
      " 3   480 of   539 \t L: 1.531 \t -- 4154.226\n",
      " 3   490 of   539 \t L: 1.514 \t -- 4240.615\n",
      " 3   500 of   539 \t L: 1.563 \t -- 4327.012\n",
      " 3   510 of   539 \t L: 1.563 \t -- 4413.200\n",
      " 3   520 of   539 \t L: 1.532 \t -- 4499.699\n",
      " 3   530 of   539 \t L: 1.557 \t -- 4586.045\n",
      "Saving model retriever_models/eli5_retriever_model_512\n",
      "Evaluation loss epoch    3: 1.162\n",
      " 4     0 of   539 \t L: 1.355 \t -- 8.671\n",
      " 4    10 of   539 \t L: 1.513 \t -- 94.971\n",
      " 4    20 of   539 \t L: 1.561 \t -- 181.430\n",
      " 4    30 of   539 \t L: 1.506 \t -- 267.975\n",
      " 4    40 of   539 \t L: 1.495 \t -- 354.633\n",
      " 4    50 of   539 \t L: 1.453 \t -- 441.297\n",
      " 4    60 of   539 \t L: 1.495 \t -- 528.291\n",
      " 4    70 of   539 \t L: 1.494 \t -- 615.019\n",
      " 4    80 of   539 \t L: 1.500 \t -- 701.786\n",
      " 4    90 of   539 \t L: 1.513 \t -- 788.272\n",
      " 4   100 of   539 \t L: 1.479 \t -- 874.676\n",
      " 4   110 of   539 \t L: 1.481 \t -- 960.944\n",
      " 4   120 of   539 \t L: 1.485 \t -- 1047.233\n",
      " 4   130 of   539 \t L: 1.472 \t -- 1133.502\n",
      " 4   140 of   539 \t L: 1.492 \t -- 1219.808\n",
      " 4   150 of   539 \t L: 1.481 \t -- 1306.037\n",
      " 4   160 of   539 \t L: 1.500 \t -- 1392.458\n",
      " 4   170 of   539 \t L: 1.507 \t -- 1478.746\n",
      " 4   180 of   539 \t L: 1.460 \t -- 1565.014\n",
      " 4   190 of   539 \t L: 1.456 \t -- 1651.434\n",
      " 4   200 of   539 \t L: 1.503 \t -- 1737.826\n",
      " 4   210 of   539 \t L: 1.471 \t -- 1824.175\n",
      " 4   220 of   539 \t L: 1.499 \t -- 1910.606\n",
      " 4   230 of   539 \t L: 1.475 \t -- 1997.072\n",
      " 4   240 of   539 \t L: 1.543 \t -- 2084.149\n",
      " 4   250 of   539 \t L: 1.458 \t -- 2170.774\n",
      " 4   260 of   539 \t L: 1.448 \t -- 2257.340\n",
      " 4   270 of   539 \t L: 1.456 \t -- 2343.661\n",
      " 4   280 of   539 \t L: 1.474 \t -- 2430.098\n",
      " 4   290 of   539 \t L: 1.480 \t -- 2516.461\n",
      " 4   300 of   539 \t L: 1.451 \t -- 2603.071\n",
      " 4   310 of   539 \t L: 1.528 \t -- 2689.636\n",
      " 4   320 of   539 \t L: 1.463 \t -- 2776.334\n",
      " 4   330 of   539 \t L: 1.456 \t -- 2863.080\n",
      " 4   340 of   539 \t L: 1.494 \t -- 2949.598\n",
      " 4   350 of   539 \t L: 1.463 \t -- 3036.157\n",
      " 4   360 of   539 \t L: 1.439 \t -- 3122.864\n",
      " 4   370 of   539 \t L: 1.464 \t -- 3209.996\n",
      " 4   380 of   539 \t L: 1.486 \t -- 3296.532\n",
      " 4   390 of   539 \t L: 1.430 \t -- 3382.947\n",
      " 4   400 of   539 \t L: 1.467 \t -- 3469.676\n",
      " 4   410 of   539 \t L: 1.475 \t -- 3556.468\n",
      " 4   420 of   539 \t L: 1.487 \t -- 3643.128\n",
      " 4   430 of   539 \t L: 1.475 \t -- 3729.840\n",
      " 4   440 of   539 \t L: 1.473 \t -- 3816.742\n",
      " 4   450 of   539 \t L: 1.482 \t -- 3903.565\n",
      " 4   460 of   539 \t L: 1.474 \t -- 3990.453\n",
      " 4   470 of   539 \t L: 1.370 \t -- 4077.277\n",
      " 4   480 of   539 \t L: 1.459 \t -- 4164.046\n",
      " 4   490 of   539 \t L: 1.467 \t -- 4250.896\n",
      " 4   500 of   539 \t L: 1.471 \t -- 4337.777\n",
      " 4   510 of   539 \t L: 1.447 \t -- 4424.515\n",
      " 4   520 of   539 \t L: 1.422 \t -- 4511.179\n",
      " 4   530 of   539 \t L: 1.413 \t -- 4597.950\n",
      "Saving model retriever_models/eli5_retriever_model_512\n",
      "Evaluation loss epoch    4: 1.113\n",
      " 5     0 of   539 \t L: 1.444 \t -- 8.653\n",
      " 5    10 of   539 \t L: 1.374 \t -- 95.190\n",
      " 5    20 of   539 \t L: 1.429 \t -- 181.814\n",
      " 5    30 of   539 \t L: 1.431 \t -- 268.545\n",
      " 5    40 of   539 \t L: 1.436 \t -- 355.199\n",
      " 5    50 of   539 \t L: 1.380 \t -- 442.043\n",
      " 5    60 of   539 \t L: 1.429 \t -- 528.865\n",
      " 5    70 of   539 \t L: 1.400 \t -- 615.571\n",
      " 5    80 of   539 \t L: 1.438 \t -- 702.370\n",
      " 5    90 of   539 \t L: 1.399 \t -- 789.165\n",
      " 5   100 of   539 \t L: 1.407 \t -- 875.930\n",
      " 5   110 of   539 \t L: 1.420 \t -- 962.624\n",
      " 5   120 of   539 \t L: 1.425 \t -- 1049.014\n",
      " 5   130 of   539 \t L: 1.441 \t -- 1135.624\n",
      " 5   140 of   539 \t L: 1.406 \t -- 1222.123\n",
      " 5   150 of   539 \t L: 1.395 \t -- 1308.610\n",
      " 5   160 of   539 \t L: 1.416 \t -- 1395.029\n",
      " 5   170 of   539 \t L: 1.452 \t -- 1481.424\n",
      " 5   180 of   539 \t L: 1.420 \t -- 1567.912\n",
      " 5   190 of   539 \t L: 1.423 \t -- 1654.397\n",
      " 5   200 of   539 \t L: 1.371 \t -- 1740.923\n",
      " 5   210 of   539 \t L: 1.403 \t -- 1827.690\n",
      " 5   220 of   539 \t L: 1.375 \t -- 1914.445\n",
      " 5   230 of   539 \t L: 1.423 \t -- 2001.154\n",
      " 5   240 of   539 \t L: 1.388 \t -- 2088.011\n",
      " 5   250 of   539 \t L: 1.401 \t -- 2174.796\n",
      " 5   260 of   539 \t L: 1.362 \t -- 2261.551\n",
      " 5   270 of   539 \t L: 1.380 \t -- 2347.904\n",
      " 5   280 of   539 \t L: 1.395 \t -- 2434.228\n",
      " 5   290 of   539 \t L: 1.399 \t -- 2520.410\n",
      " 5   300 of   539 \t L: 1.371 \t -- 2606.782\n",
      " 5   310 of   539 \t L: 1.416 \t -- 2693.170\n",
      " 5   320 of   539 \t L: 1.396 \t -- 2779.645\n",
      " 5   330 of   539 \t L: 1.415 \t -- 2866.278\n",
      " 5   340 of   539 \t L: 1.449 \t -- 2953.048\n",
      " 5   350 of   539 \t L: 1.400 \t -- 3039.913\n",
      " 5   360 of   539 \t L: 1.358 \t -- 3126.410\n",
      " 5   370 of   539 \t L: 1.454 \t -- 3213.018\n",
      " 5   380 of   539 \t L: 1.384 \t -- 3299.618\n",
      " 5   390 of   539 \t L: 1.375 \t -- 3386.134\n",
      " 5   400 of   539 \t L: 1.380 \t -- 3473.283\n",
      " 5   410 of   539 \t L: 1.385 \t -- 3560.393\n",
      " 5   420 of   539 \t L: 1.436 \t -- 3647.661\n",
      " 5   430 of   539 \t L: 1.389 \t -- 3735.097\n",
      " 5   440 of   539 \t L: 1.356 \t -- 3822.430\n",
      " 5   450 of   539 \t L: 1.376 \t -- 3909.787\n",
      " 5   460 of   539 \t L: 1.395 \t -- 3996.904\n",
      " 5   470 of   539 \t L: 1.347 \t -- 4083.629\n",
      " 5   480 of   539 \t L: 1.384 \t -- 4170.464\n",
      " 5   490 of   539 \t L: 1.393 \t -- 4257.458\n",
      " 5   500 of   539 \t L: 1.361 \t -- 4344.189\n",
      " 5   510 of   539 \t L: 1.338 \t -- 4430.997\n",
      " 5   520 of   539 \t L: 1.389 \t -- 4517.744\n",
      " 5   530 of   539 \t L: 1.397 \t -- 4604.481\n",
      "Saving model retriever_models/eli5_retriever_model_512\n",
      "Evaluation loss epoch    5: 1.073\n",
      " 6     0 of   539 \t L: 1.441 \t -- 8.684\n",
      " 6    10 of   539 \t L: 1.345 \t -- 95.464\n",
      " 6    20 of   539 \t L: 1.358 \t -- 182.335\n",
      " 6    30 of   539 \t L: 1.368 \t -- 269.181\n",
      " 6    40 of   539 \t L: 1.292 \t -- 356.087\n",
      " 6    50 of   539 \t L: 1.323 \t -- 442.927\n",
      " 6    60 of   539 \t L: 1.343 \t -- 529.542\n",
      " 6    70 of   539 \t L: 1.331 \t -- 616.377\n",
      " 6    80 of   539 \t L: 1.358 \t -- 702.998\n",
      " 6    90 of   539 \t L: 1.368 \t -- 789.623\n",
      " 6   100 of   539 \t L: 1.333 \t -- 876.576\n",
      " 6   110 of   539 \t L: 1.338 \t -- 963.231\n",
      " 6   120 of   539 \t L: 1.380 \t -- 1049.904\n",
      " 6   130 of   539 \t L: 1.359 \t -- 1136.674\n",
      " 6   140 of   539 \t L: 1.420 \t -- 1224.438\n",
      " 6   150 of   539 \t L: 1.347 \t -- 1311.545\n",
      " 6   160 of   539 \t L: 1.365 \t -- 1398.543\n",
      " 6   170 of   539 \t L: 1.377 \t -- 1485.433\n",
      " 6   180 of   539 \t L: 1.373 \t -- 1572.311\n",
      " 6   190 of   539 \t L: 1.346 \t -- 1659.133\n",
      " 6   200 of   539 \t L: 1.390 \t -- 1745.910\n",
      " 6   210 of   539 \t L: 1.349 \t -- 1832.363\n",
      " 6   220 of   539 \t L: 1.387 \t -- 1918.896\n",
      " 6   230 of   539 \t L: 1.361 \t -- 2005.511\n",
      " 6   240 of   539 \t L: 1.338 \t -- 2092.235\n",
      " 6   250 of   539 \t L: 1.363 \t -- 2179.039\n",
      " 6   260 of   539 \t L: 1.364 \t -- 2265.778\n",
      " 6   270 of   539 \t L: 1.356 \t -- 2352.532\n",
      " 6   280 of   539 \t L: 1.340 \t -- 2439.388\n",
      " 6   290 of   539 \t L: 1.315 \t -- 2526.397\n",
      " 6   300 of   539 \t L: 1.335 \t -- 2613.230\n",
      " 6   310 of   539 \t L: 1.375 \t -- 2699.972\n",
      " 6   320 of   539 \t L: 1.388 \t -- 2786.750\n",
      " 6   330 of   539 \t L: 1.356 \t -- 2873.436\n",
      " 6   340 of   539 \t L: 1.317 \t -- 2960.208\n",
      " 6   350 of   539 \t L: 1.342 \t -- 3046.994\n",
      " 6   360 of   539 \t L: 1.357 \t -- 3133.798\n",
      " 6   370 of   539 \t L: 1.352 \t -- 3220.631\n",
      " 6   380 of   539 \t L: 1.317 \t -- 3307.585\n",
      " 6   390 of   539 \t L: 1.293 \t -- 3394.432\n",
      " 6   400 of   539 \t L: 1.305 \t -- 3481.155\n",
      " 6   410 of   539 \t L: 1.361 \t -- 3567.794\n",
      " 6   420 of   539 \t L: 1.386 \t -- 3654.507\n",
      " 6   430 of   539 \t L: 1.338 \t -- 3741.162\n",
      " 6   440 of   539 \t L: 1.300 \t -- 3827.931\n",
      " 6   450 of   539 \t L: 1.346 \t -- 3914.773\n",
      " 6   460 of   539 \t L: 1.382 \t -- 4001.614\n",
      " 6   470 of   539 \t L: 1.345 \t -- 4088.347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6   480 of   539 \t L: 1.359 \t -- 4175.100\n",
      " 6   490 of   539 \t L: 1.363 \t -- 4262.016\n",
      " 6   500 of   539 \t L: 1.304 \t -- 4348.756\n",
      " 6   510 of   539 \t L: 1.348 \t -- 4435.486\n",
      " 6   520 of   539 \t L: 1.379 \t -- 4522.126\n",
      " 6   530 of   539 \t L: 1.333 \t -- 4608.723\n",
      "Saving model retriever_models/eli5_retriever_model_512\n",
      "Evaluation loss epoch    6: 1.052\n",
      " 7     0 of   539 \t L: 1.236 \t -- 8.700\n",
      " 7    10 of   539 \t L: 1.370 \t -- 95.146\n",
      " 7    20 of   539 \t L: 1.316 \t -- 181.676\n",
      " 7    30 of   539 \t L: 1.288 \t -- 268.245\n",
      " 7    40 of   539 \t L: 1.285 \t -- 354.808\n",
      " 7    50 of   539 \t L: 1.307 \t -- 441.356\n",
      " 7    60 of   539 \t L: 1.277 \t -- 527.899\n",
      " 7    70 of   539 \t L: 1.306 \t -- 614.368\n",
      " 7    80 of   539 \t L: 1.296 \t -- 700.755\n",
      " 7    90 of   539 \t L: 1.303 \t -- 787.304\n",
      " 7   100 of   539 \t L: 1.329 \t -- 873.831\n",
      " 7   110 of   539 \t L: 1.322 \t -- 960.588\n",
      " 7   120 of   539 \t L: 1.340 \t -- 1047.184\n",
      " 7   130 of   539 \t L: 1.303 \t -- 1133.643\n",
      " 7   140 of   539 \t L: 1.384 \t -- 1220.307\n",
      " 7   150 of   539 \t L: 1.307 \t -- 1306.698\n",
      " 7   160 of   539 \t L: 1.300 \t -- 1393.196\n",
      " 7   170 of   539 \t L: 1.295 \t -- 1479.652\n",
      " 7   180 of   539 \t L: 1.322 \t -- 1566.341\n",
      " 7   190 of   539 \t L: 1.348 \t -- 1652.693\n",
      " 7   200 of   539 \t L: 1.300 \t -- 1739.119\n",
      " 7   210 of   539 \t L: 1.309 \t -- 1825.609\n",
      " 7   220 of   539 \t L: 1.285 \t -- 1911.988\n",
      " 7   230 of   539 \t L: 1.306 \t -- 1998.346\n",
      " 7   240 of   539 \t L: 1.294 \t -- 2084.727\n",
      " 7   250 of   539 \t L: 1.319 \t -- 2171.313\n",
      " 7   260 of   539 \t L: 1.271 \t -- 2258.118\n",
      " 7   270 of   539 \t L: 1.316 \t -- 2345.010\n",
      " 7   280 of   539 \t L: 1.329 \t -- 2431.458\n",
      " 7   290 of   539 \t L: 1.262 \t -- 2518.189\n",
      " 7   300 of   539 \t L: 1.380 \t -- 2604.945\n",
      " 7   310 of   539 \t L: 1.343 \t -- 2691.702\n",
      " 7   320 of   539 \t L: 1.296 \t -- 2778.491\n",
      " 7   330 of   539 \t L: 1.314 \t -- 2865.157\n",
      " 7   340 of   539 \t L: 1.288 \t -- 2951.403\n",
      " 7   350 of   539 \t L: 1.299 \t -- 3037.922\n",
      " 7   360 of   539 \t L: 1.330 \t -- 3124.593\n",
      " 7   370 of   539 \t L: 1.349 \t -- 3211.282\n",
      " 7   380 of   539 \t L: 1.312 \t -- 3297.982\n",
      " 7   390 of   539 \t L: 1.306 \t -- 3385.028\n",
      " 7   400 of   539 \t L: 1.338 \t -- 3471.898\n",
      " 7   410 of   539 \t L: 1.293 \t -- 3558.724\n",
      " 7   420 of   539 \t L: 1.294 \t -- 3645.678\n",
      " 7   430 of   539 \t L: 1.327 \t -- 3732.510\n",
      " 7   440 of   539 \t L: 1.347 \t -- 3819.362\n",
      " 7   450 of   539 \t L: 1.282 \t -- 3906.140\n",
      " 7   460 of   539 \t L: 1.325 \t -- 3993.064\n",
      " 7   470 of   539 \t L: 1.289 \t -- 4079.930\n",
      " 7   480 of   539 \t L: 1.265 \t -- 4166.597\n",
      " 7   490 of   539 \t L: 1.339 \t -- 4253.445\n",
      " 7   500 of   539 \t L: 1.300 \t -- 4340.094\n",
      " 7   510 of   539 \t L: 1.296 \t -- 4426.989\n",
      " 7   520 of   539 \t L: 1.303 \t -- 4513.855\n",
      " 7   530 of   539 \t L: 1.358 \t -- 4600.654\n",
      "Saving model retriever_models/eli5_retriever_model_512\n",
      "Evaluation loss epoch    7: 1.033\n",
      " 8     0 of   539 \t L: 1.310 \t -- 8.740\n",
      " 8    10 of   539 \t L: 1.301 \t -- 95.301\n",
      " 8    20 of   539 \t L: 1.261 \t -- 182.025\n",
      " 8    30 of   539 \t L: 1.253 \t -- 268.802\n",
      " 8    40 of   539 \t L: 1.299 \t -- 355.696\n",
      " 8    50 of   539 \t L: 1.365 \t -- 442.451\n",
      " 8    60 of   539 \t L: 1.269 \t -- 529.202\n",
      " 8    70 of   539 \t L: 1.290 \t -- 615.918\n",
      " 8    80 of   539 \t L: 1.257 \t -- 702.729\n",
      " 8    90 of   539 \t L: 1.252 \t -- 789.406\n",
      " 8   100 of   539 \t L: 1.268 \t -- 876.303\n",
      " 8   110 of   539 \t L: 1.281 \t -- 963.253\n",
      " 8   120 of   539 \t L: 1.267 \t -- 1050.025\n",
      " 8   130 of   539 \t L: 1.260 \t -- 1136.786\n",
      " 8   140 of   539 \t L: 1.305 \t -- 1223.553\n",
      " 8   150 of   539 \t L: 1.282 \t -- 1310.485\n",
      " 8   160 of   539 \t L: 1.327 \t -- 1397.430\n",
      " 8   170 of   539 \t L: 1.252 \t -- 1484.358\n",
      " 8   180 of   539 \t L: 1.257 \t -- 1571.128\n",
      " 8   190 of   539 \t L: 1.310 \t -- 1657.956\n",
      " 8   200 of   539 \t L: 1.319 \t -- 1744.811\n",
      " 8   210 of   539 \t L: 1.252 \t -- 1831.708\n",
      " 8   220 of   539 \t L: 1.244 \t -- 1918.519\n",
      " 8   230 of   539 \t L: 1.259 \t -- 2005.535\n",
      " 8   240 of   539 \t L: 1.282 \t -- 2092.507\n",
      " 8   250 of   539 \t L: 1.209 \t -- 2179.627\n",
      " 8   260 of   539 \t L: 1.329 \t -- 2266.543\n",
      " 8   270 of   539 \t L: 1.282 \t -- 2353.485\n",
      " 8   280 of   539 \t L: 1.296 \t -- 2440.402\n",
      " 8   290 of   539 \t L: 1.273 \t -- 2527.186\n",
      " 8   300 of   539 \t L: 1.254 \t -- 2613.672\n",
      " 8   310 of   539 \t L: 1.307 \t -- 2700.136\n",
      " 8   320 of   539 \t L: 1.324 \t -- 2786.682\n",
      " 8   330 of   539 \t L: 1.317 \t -- 2873.335\n",
      " 8   340 of   539 \t L: 1.314 \t -- 2960.014\n",
      " 8   350 of   539 \t L: 1.215 \t -- 3046.476\n",
      " 8   360 of   539 \t L: 1.251 \t -- 3133.316\n",
      " 8   370 of   539 \t L: 1.266 \t -- 3220.299\n",
      " 8   380 of   539 \t L: 1.308 \t -- 3307.243\n",
      " 8   390 of   539 \t L: 1.333 \t -- 3394.121\n",
      " 8   400 of   539 \t L: 1.285 \t -- 3480.953\n",
      " 8   410 of   539 \t L: 1.262 \t -- 3567.852\n",
      " 8   420 of   539 \t L: 1.317 \t -- 3654.947\n",
      " 8   430 of   539 \t L: 1.258 \t -- 3741.947\n",
      " 8   440 of   539 \t L: 1.306 \t -- 3828.663\n",
      " 8   450 of   539 \t L: 1.306 \t -- 3915.690\n",
      " 8   460 of   539 \t L: 1.288 \t -- 4002.750\n",
      " 8   470 of   539 \t L: 1.308 \t -- 4089.692\n",
      " 8   480 of   539 \t L: 1.285 \t -- 4176.616\n",
      " 8   490 of   539 \t L: 1.306 \t -- 4263.497\n",
      " 8   500 of   539 \t L: 1.272 \t -- 4350.372\n",
      " 8   510 of   539 \t L: 1.293 \t -- 4437.285\n",
      " 8   520 of   539 \t L: 1.231 \t -- 4524.211\n",
      " 8   530 of   539 \t L: 1.267 \t -- 4610.796\n",
      "Saving model retriever_models/eli5_retriever_model_512\n",
      "Evaluation loss epoch    8: 1.020\n",
      " 9     0 of   539 \t L: 1.230 \t -- 8.655\n",
      " 9    10 of   539 \t L: 1.246 \t -- 95.032\n",
      " 9    20 of   539 \t L: 1.303 \t -- 181.538\n",
      " 9    30 of   539 \t L: 1.268 \t -- 268.062\n",
      " 9    40 of   539 \t L: 1.288 \t -- 354.800\n",
      " 9    50 of   539 \t L: 1.225 \t -- 441.554\n",
      " 9    60 of   539 \t L: 1.246 \t -- 528.482\n",
      " 9    70 of   539 \t L: 1.250 \t -- 615.400\n",
      " 9    80 of   539 \t L: 1.265 \t -- 702.200\n",
      " 9    90 of   539 \t L: 1.280 \t -- 789.165\n",
      " 9   100 of   539 \t L: 1.269 \t -- 876.050\n",
      " 9   110 of   539 \t L: 1.219 \t -- 962.942\n",
      " 9   120 of   539 \t L: 1.237 \t -- 1050.076\n",
      " 9   130 of   539 \t L: 1.250 \t -- 1137.005\n",
      " 9   140 of   539 \t L: 1.291 \t -- 1223.896\n",
      " 9   150 of   539 \t L: 1.311 \t -- 1310.757\n",
      " 9   160 of   539 \t L: 1.270 \t -- 1398.543\n",
      " 9   170 of   539 \t L: 1.289 \t -- 1486.008\n",
      " 9   180 of   539 \t L: 1.259 \t -- 1572.896\n",
      " 9   190 of   539 \t L: 1.281 \t -- 1659.999\n",
      " 9   200 of   539 \t L: 1.262 \t -- 1746.896\n",
      " 9   210 of   539 \t L: 1.312 \t -- 1833.760\n",
      " 9   220 of   539 \t L: 1.250 \t -- 1920.671\n",
      " 9   230 of   539 \t L: 1.247 \t -- 2007.541\n",
      " 9   240 of   539 \t L: 1.297 \t -- 2094.403\n",
      " 9   250 of   539 \t L: 1.278 \t -- 2181.182\n",
      " 9   260 of   539 \t L: 1.252 \t -- 2267.897\n",
      " 9   270 of   539 \t L: 1.254 \t -- 2354.826\n",
      " 9   280 of   539 \t L: 1.236 \t -- 2441.643\n",
      " 9   290 of   539 \t L: 1.307 \t -- 2528.502\n",
      " 9   300 of   539 \t L: 1.274 \t -- 2615.297\n",
      " 9   310 of   539 \t L: 1.247 \t -- 2701.707\n",
      " 9   320 of   539 \t L: 1.328 \t -- 2788.466\n",
      " 9   330 of   539 \t L: 1.311 \t -- 2874.969\n",
      " 9   340 of   539 \t L: 1.298 \t -- 2961.516\n",
      " 9   350 of   539 \t L: 1.251 \t -- 3047.963\n",
      " 9   360 of   539 \t L: 1.217 \t -- 3134.442\n",
      " 9   370 of   539 \t L: 1.284 \t -- 3221.404\n",
      " 9   380 of   539 \t L: 1.273 \t -- 3308.263\n",
      " 9   390 of   539 \t L: 1.284 \t -- 3395.061\n",
      " 9   400 of   539 \t L: 1.245 \t -- 3481.874\n",
      " 9   410 of   539 \t L: 1.306 \t -- 3568.871\n",
      " 9   420 of   539 \t L: 1.259 \t -- 3655.799\n",
      " 9   430 of   539 \t L: 1.264 \t -- 3742.703\n",
      " 9   440 of   539 \t L: 1.262 \t -- 3829.505\n",
      " 9   450 of   539 \t L: 1.275 \t -- 3916.322\n",
      " 9   460 of   539 \t L: 1.282 \t -- 4003.001\n",
      " 9   470 of   539 \t L: 1.270 \t -- 4089.853\n",
      " 9   480 of   539 \t L: 1.267 \t -- 4176.915\n",
      " 9   490 of   539 \t L: 1.270 \t -- 4263.797\n",
      " 9   500 of   539 \t L: 1.259 \t -- 4350.687\n",
      " 9   510 of   539 \t L: 1.300 \t -- 4437.512\n",
      " 9   520 of   539 \t L: 1.230 \t -- 4524.319\n",
      " 9   530 of   539 \t L: 1.290 \t -- 4611.083\n",
      "Saving model retriever_models/eli5_retriever_model_512\n",
      "Evaluation loss epoch    9: 1.017\n"
     ]
    }
   ],
   "source": [
    "class ArgumentsQAR():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 2048\n",
    "        self.max_length = 128\n",
    "        self.checkpoint_batch_size = 128\n",
    "        self.print_freq = 10\n",
    "        self.pretrained_model_name = \"google/bert_uncased_L-8_H-512_A-8\"\n",
    "        self.model_save_name = \"retriever_models/eli5_retriever_model_2048\"\n",
    "        self.learning_rate = 2e-5\n",
    "        self.num_epochs = 20\n",
    "\n",
    "qar_args = ArgumentsQAR()\n",
    "\n",
    "qar_train_dset = ELI5DatasetQARetriver(eli5_train, min_answer_length=64, training=True)\n",
    "qar_valid_dset = ELI5DatasetQARetriver(eli5_valid, min_answer_length=64, training=False)\n",
    "\n",
    "qar_tokenizer, qar_model = make_qa_retriever_model(\n",
    "    model_name=qar_args.pretrained_model_name,\n",
    "    from_file=None,\n",
    "    device=\"cuda:0\"\n",
    ")\n",
    "\n",
    "qar_optimizer = AdamW(qar_model.parameters(), lr=qar_args.learning_rate, eps=1e-8)\n",
    "qar_scheduler = get_linear_schedule_with_warmup(\n",
    "        qar_optimizer,\n",
    "        num_warmup_steps=100,\n",
    "        num_training_steps=qar_args.num_epochs * math.ceil(len(qar_train_dset) / qar_args.batch_size)\n",
    ")\n",
    "\n",
    "for e in range(qar_args.num_epochs):\n",
    "    train_qa_retriever_epoch(\n",
    "        qar_model, qar_train_dset, qar_tokenizer,\n",
    "        qar_optimizer, qar_scheduler, qar_args, e\n",
    "    )\n",
    "    m_save_dict = {\n",
    "        'model': qar_model.state_dict(),\n",
    "        'optimizer': qar_optimizer.state_dict(),\n",
    "        'scheduler': qar_scheduler.state_dict(),\n",
    "    }\n",
    "    print(\"Saving model {}\".format(qar_args.model_save_name))\n",
    "    torch.save(m_save_dict, '{}_{}.pth'.format(qar_args.model_save_name, e))\n",
    "    eval_loss = evaluate_qa_retriever(qar_model, qar_valid_dset, qar_tokenizer, qar_args)\n",
    "    print(\"Evaluation loss epoch {:4d}: {:.3f}\".format(e, eval_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: evaluate recall@N for validation / test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Used train rtriever to index Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eli5_utils import *\n",
    "\n",
    "qar_tokenizer, qar_model = make_qa_retriever_model(\n",
    "    model_name=\"google/bert_uncased_L-8_H-512_A-8\",\n",
    "    from_file='{}_{}.pth'.format(\"retriever_models/eli5_retriever_model_512\", 9),\n",
    "    device=\"cuda:0\"\n",
    ")\n",
    "\n",
    "kilt_snippets_dbuilder = KiltSnippets(data_dir='kilt_snippets_100w')\n",
    "kilt_snippets_dbuilder.download_and_prepare()\n",
    "wiki_passages = kilt_snippets_dbuilder.as_dataset(split=nlp.splits.Split.TRAIN)\n",
    "\n",
    "make_qa_dense_index(qar_model, qar_tokenizer,\n",
    "                    wiki_passages,\n",
    "                    batch_size=512, max_length=96,\n",
    "                    index_name='kilt_passages_reps_16.dat',\n",
    "                    device='cuda:0')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the Seq2seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eli5_utils import *\n",
    "\n",
    "eli5_dbuilder = ELI5NLP(data_dir='eli5')\n",
    "eli5_dbuilder.download_and_prepare()\n",
    "\n",
    "eli5_train = eli5_dbuilder.as_dataset(split=nlp.splits.Split.TRAIN)\n",
    "eli5_valid = eli5_dbuilder.as_dataset(split=nlp.splits.Split.VALIDATION)\n",
    "\n",
    "eli5_train_docs = json.load(open('eli5_train_precomputed_dense_docs.json'))\n",
    "eli5_valid_docs = json.load(open('eli5_valid_precomputed_dense_docs.json'))\n",
    "\n",
    "s2s_train_dset = ELI5DatasetS2S(eli5_train, document_cache=dict([(k, d) for k, d, src_ls in eli5_train_docs]))\n",
    "s2s_valid_dset = ELI5DatasetS2S(eli5_valid, document_cache=dict([(k, d) for k, d, src_ls in eli5_valid_docs]), training=False)\n",
    "\n",
    "qa_s2s_tokenizer, qa_s2s_model = make_qa_s2s_model(\n",
    "    model_name=\"bart-large\",\n",
    "    from_file=None,\n",
    "    device=\"cuda:0\"\n",
    ")\n",
    "\n",
    "class ArgumentsS2S():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 1\n",
    "        self.backward_freq = 16\n",
    "        self.max_length = 1024\n",
    "        self.print_freq = 1000\n",
    "        self.model_save_name = \"seq2seq_models/eli5_bart_model_512\"\n",
    "        self.learning_rate = 2e-5\n",
    "        self.num_epochs = 10\n",
    "\n",
    "s2s_args = ArgumentsS2S()\n",
    "s2s_optimizer = AdamW(qa_s2s_model.parameters(), lr=s2s_args.learning_rate, eps=1e-8)\n",
    "s2s_scheduler = get_linear_schedule_with_warmup(\n",
    "        s2s_optimizer,\n",
    "        num_warmup_steps=100,\n",
    "        num_training_steps=s2s_args.num_epochs * math.ceil(len(s2s_train_dset) / s2s_args.batch_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(s2s_args.num_epochs):\n",
    "    train_qa_s2s_epoch(\n",
    "        qa_s2s_model,\n",
    "        s2s_train_dset, qa_s2s_tokenizer,\n",
    "        s2s_optimizer, s2s_scheduler,\n",
    "        s2s_args, e\n",
    "    )\n",
    "    m_save_dict = {\n",
    "        'model': qa_s2s_model.state_dict(),\n",
    "        'optimizer': s2s_optimizer.state_dict(),\n",
    "        'scheduler': s2s_scheduler.state_dict(),\n",
    "    }\n",
    "    print(\"Saving model {}\".format(s2s_args.model_save_name))\n",
    "    torch.save(m_save_dict, '{}_{}.pth'.format(s2s_args.model_save_name, e))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
