{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Form Question Answering with ELI5 and Wikipedia  \n",
    "\n",
    "---  \n",
    "\n",
    "### Table of Contents  \n",
    "\n",
    "1. [Introduction](#intro)  \n",
    "    a. [Preliminaries](#prelims)  \n",
    "    b. [Note on Data and Biases](#reddit_biases)\n",
    "2. [Task and Data Description](#task_description)  \n",
    "3. [Retrieving Support Documents](#retrieval)  \n",
    "    a. [Sparse Retrieval with ElasticSearch](#elasticsearch)  \n",
    "    b. [Training a Dense Retriever with ELI5 and in-batch Negatives](#dense_train)  \n",
    "    c. [Indexing Wikipedia with a Trained Dense Retriever](#dense_use)  \n",
    "    d. [Retriever Model Evaluation](#dense_eval)  \n",
    "4. [Answer Generation Model](#generation)  \n",
    "    a. [Conditional Generation with Seq2seq Models](#seq2seq_presentation)  \n",
    "    b. [Fine-Tuning Seq2seq Models](#seq2seq_train)  \n",
    "5. [Conclusion](#conclusion)  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"images/choco_bis.svg\" width=\"900\" align=\"center\"/>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "<a id='intro'></a>\n",
    "\n",
    "Imagine that you are taken with a sudden desire to understand **how the fruit of a tropical tree gets transformed into chocolate bars**, or want to understand **the role of fever in the human body's immune response**: how would you go about finding that information?\n",
    "\n",
    "If your specific question has already been asked and answered clearly and succintly on one of the many question answering platforms available on the Internet (such as [**Quora**](https://www.quora.com/How-is-chocolate-made), [**Reddit**](https://www.reddit.com/user/ex_5_libris/comments/9c8gb1/chocolate_how_chocolate_is_made/), or [**Yahoo Answers**](https://answers.yahoo.com/question/index?qid=20070615082202AArsYN1)), you're in luck: modern search engines will probably take you to that pre-existing answer pretty reliably in a matter of a few clicks.  \n",
    "\n",
    "Otherwise, the process will be a little more involved. You will likely have to collect relevant information from a variety of sources, figure out how these pieces of knowledge fit together in relation to your query, and synthetize a narrative that answers your initial question.\n",
    "\n",
    "Now, wouldn't it be great if your computer could do all of that for you: **gather** the right sources, **synthetize** the information, and **write up** an easy-to-read summary of the relevant points? Such a system isn't quite available yet, at least not one that can provide *reliable* information in its summary. However, a number of recent advances in natural language understanding and generation have made working toward solving this problem much easier! These advances include progress in the pre-training (e.g. [BART](https://arxiv.org/abs/1910.13461), [T5](https://arxiv.org/abs/1910.10683)) and evaluation (e.g. for [factuality](https://arxiv.org/abs/2004.04228)) of sequence-to-sequence models for conditional text generation, new ways to use language understanding models to find information in Wikipedia (e.g. [REALM](https://kentonl.com/pub/gltpc.2020.pdf), [DPR](https://arxiv.org/abs/2004.04906)), and new [training datasets](https://arxiv.org/abs/1907.09190).\n",
    "\n",
    "**In this notebook,** we show how we can take advantage of some of these recent works to train a **long form question answering** system which takes in a question, fetches 10 relevant passages from a [Wikipedia snapshot](https://www.aclweb.org/anthology/2020.lrec-1.297/), and writes a multi-sentence answer based on the question and retrieved passages. Follow along to learn about the steps involved and read some background on the state of the art for some related tasks, or go straight to the:  \n",
    "## [**Live Demo!**](http://35.226.96.115:8080/)  \n",
    "(And don't forget to scroll down on the left sidebar to show all of the generation options!)\n",
    "\n",
    "### 1.a - Preliminaries  \n",
    "<a id='prelims'></a>\n",
    "\n",
    "The implementation presented here relies on the [HuggingFace](https://huggingface.co/) [ðŸ¤—transformers](https://github.com/huggingface/transformers) and [ðŸ¤—nlp](https://github.com/huggingface/nlp) libraries. Wikipedia indexing relies on [ElasticSearch](https://www.elastic.co/elasticsearch) with its [python bindings](https://github.com/elastic/elasticsearch-py) for the sparse version, and [faiss](https://github.com/facebookresearch/faiss/) for the dense version. You can get all of these by running:\n",
    "> pip install elasticsearch  \n",
    "> pip install faiss_gpu  \n",
    "> pip install nlp  \n",
    "> pip install transformers  \n",
    ">  \n",
    "> wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.7.1-linux-x86_64.tar.gz  \n",
    "> tar -xzvf elasticsearch-7.7.1-linux-x86_64.tar.gz  \n",
    "\n",
    "The training relies on two datasets: [ELI5](https://arxiv.org/abs/1907.09190), a processed version of the [r/explainlikeimfive](https://www.reddit.com/r/explainlikeimfive/) subreddit, and the [Wiki40b](https://www.aclweb.org/anthology/2020.lrec-1.297/) Wikipedia image.\n",
    "\n",
    "Downloading ELI5 can take up to 72 hours since we need to to filter through all of the Reddit dumps for 8 years, so we suggest that you do that first (you will need a good download speed and about 10GB of disk space):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlp\n",
    "eli5 = nlp.load_dataset('explainlikeimfive', name='LFQA_reddit', experimental=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is meant to be run from the `transformers/examples/eli5` folder in the [ðŸ¤—transformers](https://github.com/huggingface/transformers) library, as all of the useful methods it relies on are compiled in the [eli5_utils.py](https://github.com/yjernite/transformers/blob/eli5_examples/examples/eli5/eli5_utils.py) script located there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eli5_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b - Note on Data and Biases\n",
    "<a id='reddit_biases'></a>\n",
    "\n",
    "Before we go any further, let us take a moment to talk about the provenance of our training data. While Reddit hosts a number of thriving communities with high quality discussions, it is also widely known to have corners where sexism, hate, and harassment are significant issues. See for example the [recent post from Reddit founder u/spez](https://www.reddit.com/r/announcements/comments/gxas21/upcoming_changes_to_our_content_policy_our_board/) outlining some of the ways he thinks the website's historical policies have been responsible for this problem, [Adrienne Massanari's 2015 article on GamerGate](https://www.researchgate.net/publication/283848479_Gamergate_and_The_Fappening_How_Reddit's_algorithm_governance_and_culture_support_toxic_technocultures) and follow-up works, or a [2019 Wired article on misogyny on Reddit](https://www.wired.com/story/misogyny-reddit-research/).\n",
    "\n",
    "While there has been some recent work in the NLP community on *de-biasing* models (e.g. [Black is to Criminal as Caucasian is to Police:\n",
    "Detecting and Removing Multiclass Bias in Word Embeddings](https://arxiv.org/abs/1904.04047) for word embeddings trained specifically on Reddit data), this problem is far from solved, and the likelihood that a trained model might learn the biases present in the data remains a significant concern.\n",
    "\n",
    "As mentioned above, the magnitude of the problem depends on the specific communities/subreddits. This work uses data from [r/explainlikeimfive](https://www.reddit.com/r/explainlikeimfive/), [r/askscience](https://www.reddit.com/r/askscience/), and [r/AskHistorians](https://www.reddit.com/r/AskHistorians/). There are some encouraging signs for all of these communities: [r/explainlikeimfive](https://www.reddit.com/r/explainlikeimfive/) and [r/askscience](https://www.reddit.com/r/askscience/) have similar structures and purposes, and [r/askscience](https://www.reddit.com/r/askscience/) was found in 2015 to show medium supportiveness and very low toxicity when compared to other subreddits (see a [hackerfall post](https://hackerfall.com/story/study-and-interactive-visualization-of-toxicity-in), [thecut.com write-up](https://www.thecut.com/2015/03/interactive-chart-of-reddits-toxicity.html) and supporting [data](https://chart-studio.plotly.com/~bsbell21/210/toxicity-vs-supportiveness-by-subreddit/#data)). Meanwhile, the [r/AskHistorians rules](https://www.reddit.com/r/AskHistorians/wiki/rules) mention that the admins will not tolerate \"*racism, sexism, or any other forms of bigotry*\".\n",
    "\n",
    "This is obviously not enough to exonerate the model, and there is still a lot of interesting work to do to be able to quantify the biases in a conditional text generation model. One thing you can do to help: if you find any particularly egregious answers provided by the model when using the demo, or want to work on this research question please send a DM to [@YJernite on Twitter](https://twitter.com/YJernite)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Task and Data Description\n",
    "<a id='task_description'></a>\n",
    "\n",
    "Let's recap: we are interested in the task of Long Form Question Answering. As in other Question Answering tasks, the model is presented with a question, and is required to generate a natural language answer. Whereas a majority of QA datasets contain mostly **factoid** questions, where the answer, such as a date or the name of a single entity, can be expressed in a few words or single sentence, Long Form QA focuses on questions which call for an **explanation** consisting of a few sentences or a few paragraphs.\n",
    "\n",
    "In order to teach a model to answer such questions, we use questions and answers written by Reddit users. Note that the `nlp.load_dataset` command above actually downloaded questions and their associated answers from the [r/explainlikeimfive](https://www.reddit.com/r/explainlikeimfive/), [r/askscience](https://www.reddit.com/r/askscience/), and [r/AskHistorians](https://www.reddit.com/r/AskHistorians/) subreddits. We focus here on the **ELI5/explainlikeimfive** part to train the system, as these examples tend to be a little simpler.  \n",
    "\n",
    "Let's look at one item from the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q_id': '8houtx',\n",
       " 'title': 'Why does water heated to room temperature feel colder than the air around it?',\n",
       " 'selftext': '',\n",
       " 'document': '',\n",
       " 'subreddit': 'explainlikeimfive',\n",
       " 'answers': {'a_id': ['dylcnfk', 'dylcj49'],\n",
       "  'text': [\"Water transfers heat more efficiently than air. When something feels cold it's because heat is being transferred from your skin to whatever you're touching. Since water absorbs the heat more readily than air, it feels colder.\",\n",
       "   \"Air isn't as good at transferring heat compared to something like water or steel (sit on a room temperature steel bench vs. a room temperature wooden bench, and the steel one will feel more cold).\\n\\nWhen you feel cold, what you're feeling is heat being transferred out of you.  If there is no breeze, you feel a certain way.  If there's a breeze, you will get colder faster (because the moving air is pulling the heat away from you), and if you get into water, its quite good at pulling heat from you.   Get out of the water and have a breeze blow on you while you're wet, all of the water starts evaporating, pulling even more heat from you.\"],\n",
       "  'score': [5, 2]},\n",
       " 'title_urls': {'url': []},\n",
       " 'selftext_urls': {'url': []},\n",
       " 'answers_urls': {'url': []}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5['test_eli5'][12345]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we have the question:\n",
    "> Why does water heated to room temperature feel colder than the air around it?  \n",
    "\n",
    "\n",
    "This definitely requires a multi-step explanation: no single phrase can sum up all of the information we are looking for. Here are the answers that were given on ELI5, and were given scores of +5 and +2 respectively by Reddit users:\n",
    "> 1. Water transfers heat more efficiently than air. When something feels cold it's because heat is being transferred from your skin to whatever you're touching. Since water absorbs the heat more readily than air, it feels colder.  \n",
    "\n",
    "> 2. Air isn't as good at transferring heat compared to something like water or steel (sit on a room temperature steel bench vs. a room temperature wooden bench, and the steel one will feel more cold). When you feel cold, what you're feeling is heat being transferred out of you. If there is no breeze, you feel a certain way.  If there's a breeze, you will get colder faster (because the moving air is pulling the heat away from you), and if you get into water, its quite good at pulling heat from you. Get out of the water and have a breeze blow on you while you're wet, all of the water starts evaporating, pulling even more heat from you.  \n",
    "\n",
    "First, note that in this case **we have two answers** which broadly describe the same phenomenon: the first one is scored higher because it is more succint and to the point. This example already illustrates one important feature of the LFQA task: **there are usually several valid ways to answer a given question.** Of the 272K examples in the ELI5 training set, nearly two thirds (167K) have at least two answers. We'll need to keep this in mind when training and evaluation of the model.  \n",
    "\n",
    "Secondly, we need to give our model access to the information that is expressed in both these answers. While recently released large models have been shown to hold a significant amount of information about the world in their parameters (see e.g. the [Closed-book QA performance of the T5 model](https://arxiv.org/abs/2002.08910)), there are several advantages to giving the model explicit access to information in text form. First, a larger number of parameters in a model implies a larger computational cost. Secondly, getting information from a text database allows us to easily update the model's knowledge without having to re-train its parameters.\n",
    "\n",
    "<img src=\"images/ELI5animation.gif\" width=\"750\" align=\"center\"/>  \n",
    "\n",
    "Here, we choose to give the model access to Wikipedia text. We follow previous work in splitting Wikipedia articles into disjoint snippets of 100 words, and keep track of the title of the article and sections a snippet came from. Here's how you can get a pre-processed Wiki40b version split into 100-word passages with the `nlp` library, and an example snippet which has some of the information we're looking for (\"*little conduction would occur since air is a poor conductor of heat*\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '{\"nlp_id\": 1665419, \"wiki_id\": \"Q179635\", \"sp\": 12, \"sc\": 653, \"ep\": 12, \"ec\": 1223}',\n",
       " 'nlp_id': 1665419,\n",
       " 'wiki_id': 'Q179635',\n",
       " 'start_paragraph': 12,\n",
       " 'start_character': 653,\n",
       " 'end_paragraph': 12,\n",
       " 'end_character': 1223,\n",
       " 'article_title': 'Heat transfer',\n",
       " 'section_title': 'Conduction',\n",
       " 'passage_text': 'from one place to another place without the movement of particles is called conduction, such as when placing a hand on a cold glass of water - heat is conducted from the warm skin to the cold glass, but if the hand is held a few inches from the glass, little conduction would occur since air is a poor conductor of heat. Steady state conduction is an idealized model of conduction that happens when the temperature difference driving the conduction is constant, so that after a time, the spatial distribution of temperatures in the conducting object does not change any'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki40b_snippets = nlp.load_dataset('wiki_snippets', name='wiki40b_en_100_0', experimental=True)['train']\n",
    "wiki40b_snippets[8991855]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, we show how we can use either a [sparse retriever](#elasticsearch) or a [trained dense retriever](#dense_train) to automatically find relevant snippets for a question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Retrieving Support Documents\n",
    "<a id='retrieval'></a>\n",
    "\n",
    "There has been a renewed interest in open domain question answering tasks in the last few years, as the availability of better text representations has made it possible to train models to first re-rank the outputs of \"classical\" information retrieval systems, and more recently to function as full IR systems themselves. See [this presentation](https://docs.google.com/presentation/d/1A5wJEzFYGdNem7egJ-BTm6EMI3jGNe1lalyChYL54gw) from the [Hugging Face reading group](https://github.com/huggingface/awesome-papers) for a non-exhaustive overview of work in this field published up to April 2020.\n",
    "\n",
    "In the rest of this section, we show how to use either such a \"classical\" IR system based on **sparse** word matching with ElasticSearch, or how to train a model to compute **dense** vector representations of Wikipedia passages which can be queried through Max Inner Product Search (MIPS) with a query embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.a - Sparse Retrieval with ElasticSearch\n",
    "<a id='elasticsearch'></a>\n",
    "\n",
    "[ElasticSearch](https://www.elastic.co/elasticsearch/) provides a convenient way to index documents so they can easily be queried for nearest neighbor search using the [BM25](https://en.wikipedia.org/wiki/Okapi_BM25) similarity function. In other words, given a query, the system can efficiently return a list of documents that have the most TF/IDF-weighted words in common with that query. While this word-matching based approach has obvious limitations, such as failing to take synonyms and sometimes grammatical variation into account, it does pretty well overall and has only recently been overtaken by embedding-based systems for Wikipedia-based Open-Domain QA tasks.\n",
    "\n",
    "In order to use ElasticSearch, you will first need to launch a server. In a different window, run:\n",
    "> ./elasticsearch-7.7.0/bin/elasticsearch\n",
    "\n",
    "By default, your ElasticSearch server will be listening on `localhost` port `9200`. To connect to it run: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch([{'host': 'localhost', 'port': '9200'}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `eli5_utils.py` script provides utilities to create (`make_es_index_snippets`) and query (`query_es_index`) an ElasticSearch index from within Python.\n",
    "\n",
    "The main implementation details are:  \n",
    "1. We index the article title, section title, and text of each of the passages for BM25 passages. These choices are implemented in the `index_config` variable:  \n",
    "```python\n",
    "    index_config = {\n",
    "      \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "      },\n",
    "      \"mappings\": {\n",
    "        \"properties\": {\n",
    "          \"article_title\": {\"type\": \"text\", \"analyzer\": \"standard\", \"similarity\": \"BM25\"},\n",
    "          \"section_title\": {\"type\": \"text\", \"analyzer\": \"standard\", \"similarity\": \"BM25\"},\n",
    "          \"passage_text\": {\"type\": \"text\", \"analyzer\": \"standard\", \"similarity\": \"BM25\"}\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "```\n",
    "2. To query the index, we found it useful to add a few task-dependent stop-words. The query text is then compared to all of the indexed fields, giving more weight to the passage text:\n",
    "```python\n",
    "    banned = ['how', 'why', 'what', 'where', 'which', 'do', 'does', 'is', '?', 'eli5', 'eli5:']\n",
    "    q = ' '.join([w for w in q.split() if w not in banned])\n",
    "    response = es_client.search(\n",
    "        index = index_name,\n",
    "        body = {\n",
    "            \"query\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": q,\n",
    "                    \"fields\": [\"article_title\", \"section_title\", \"passage_text^2\"],\n",
    "                    \"type\": \"cross_fields\",\n",
    "                }\n",
    "            },\n",
    "            \"size\": n_results,\n",
    "        }\n",
    "    )\n",
    "```  \n",
    "\n",
    "Here's the command to create the index, it should take one to three hours depending on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not es_client.indices.exists('wiki40b_snippets_100w'):\n",
    "    make_es_index_snippets(es_client, wiki40b_snippets, index_name='wiki40b_snippets_100w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test the ElasticSearch retriever with our running example ELI5 question about skin-to-water heat transfer by returning the 10 best candidate passages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why does water heated to room temperature feel colder than the air around it?\n",
      "-----\n",
      "\n",
      "1 Salt fingering: \n",
      "  Salt fingering\n",
      "----\n",
      "Salt fingering Salt fingering is a mixing process that occurs when relatively warm, salty water overlies relatively colder, fresher water. It is driven by the fact that heated water diffuses more readily than salty water. A small parcel of warm, salty water sinking downwards into a colder, fresher region will lose its heat before losing its salt, making the parcel of water increasingly denser than the water around it and sinking further. Likewise, a small parcel of colder, fresher water will be displaced upwards and gain heat by diffusion from surrounding water, which will then make it lighter than the\n",
      "\n",
      "2 Solar water heating: \n",
      "  Flat plate & Evacuated tube\n",
      "----\n",
      "protected by a glass panel. Consequently, these types of collectors are much less efficient when water temperature exceeds ambient air temperatures. For pool heating applications, the water to be heated is often colder than the ambient roof temperature, at which point the lack of thermal insulation allows additional heat to be drawn from the surrounding environment. Evacuated tube Evacuated tube collectors (ETC) are a way to reduce the heat loss, inherent in flat plates. Since heat loss due to convection cannot cross a vacuum, it forms an efficient isolation mechanism to keep heat inside the collector pipes. Since two flat\n",
      "\n",
      "3 Humidifier: \n",
      "  Fixed-installation humidifiers & Problems\n",
      "----\n",
      "to damage from overly dry air. In colder months, they may provide modest energy savings, since as humidity increases, occupants may feel warm at a lower temperature.\n",
      "Bypass humidifiers are connected between the heated and cold air return ducts, using the pressure difference between these ducts to cause some heated air to make a bypass through the humidifier and return to the furnace.\n",
      "Any humidifiers should usually be disabled during the summer months if air conditioning is used; air conditioners partially function to reducing indoor humidity, and having a humidifier continue to operate will waste significant amounts of energy. Problems The USEPA\n",
      "\n",
      "4 Drake Landing Solar Community: \n",
      "  How it works & Energy centre\n",
      "----\n",
      "the short-term storage tanks in the Energy Centre to be heated again in order to complete the circuit. During colder months the water from the BTES passes back to the short-term storage tank and is then directed to each home. Similar to a hot water tank, the heated water goes through a heat exchanger that blows air across the warm fan coil. Heat travels from the water to the air and is directed through the house via ductwork. When the temperature reaches that said on the thermostat, an automatic valve shuts off the heat transfer unit. Energy centre The Energy\n",
      "\n",
      "5 Diamond dust: \n",
      "  Characteristics & Formation\n",
      "----\n",
      "it looks like many tiny diamonds are flashing in the air. Formation These ice crystals usually form when a temperature inversion is present at the surface and the warmer air above the ground mixes with the colder air near the surface. Since warmer air frequently contains more water vapor than colder air, this mixing will usually also transport water vapor into the air near the surface, causing the relative humidity of the near-surface air to increase. If the relative humidity increase near the surface is large enough then ice crystals may form.\n",
      "To form diamond dust the temperature must be below\n",
      "\n",
      "6 Effects of global warming on oceans: \n",
      "  Ocean currents\n",
      "----\n",
      "changing latitudes of our planet. As the atmosphere is warmed nearest the equator, the hot air at the surface of our planet is heated, causing it to rise and draw in cooler air to take its place, creating what is known as circulation cells. This ultimately causes the air to be significantly colder near the poles than at the equator.\n",
      "Wind patterns associated with these circulation cells drive surface currents which push the surface water to the higher latitudes where the air is colder. This cools the water down enough to where it is capable of dissolving more gasses and minerals,\n",
      "\n",
      "7 Mesoscale convective system: \n",
      "  Lake-effect snow\n",
      "----\n",
      "for lake-effect rain or snow to form, the air moving across the lake must be significantly cooler than the surface air (which is likely to be near the temperature of the water surface). Specifically, the air temperature at the altitude where the air pressure is 850 millibars (or 1.5 kilometres (0.93Â mi) altitude) should be 13Â Â°C (24Â Â°F) lower than the temperature of the air at the surface.  Lake-effect occurring when the air at 850 millibars is 25Â Â°C (45Â Â°F) colder than the water temperature can produce thundersnow, snow showers accompanied by lightning and thunder (due to the larger amount of energy\n",
      "\n",
      "8 Thermal comfort: \n",
      "  Interplay of temperature and humidity\n",
      "----\n",
      "such as the heat index.\n",
      "For lower temperatures, a related interplay was identified only qualitatively:\n",
      "High humidity and low temperatures cause the air to feel chilly.\n",
      "Cold air with high relative humidity \"feels\" colder than dry air of the same temperature because high humidity in cold weather increases the conduction of heat from the body.\n",
      "There has been controversy over why damp cold air feels colder than dry cold air. Some believe it is because when the humidity is high, our skin and clothing become moist and are better conductors of heat, so there is more cooling by conduction.\n",
      "For more recent data look for\n",
      "\n",
      "9 Honyaki: \n",
      "  Traditional process\n",
      "----\n",
      "heat. The quench water or oil is prepared and brought to the right temperature. The forge is heated. Lights are turned off and the room shut from the outside. Once ready, the blade is buried and shuffled around in the charcoal and when it reaches the correct temperature it is thrust into water and moved forward and back (so as to prevent lateral distortion) and then after a couple seconds side to side. The knife could also be brought up slightly above temperature and then held in the room to the correct temperature before quench. The quench could be interrupted\n",
      "\n",
      "10 Greywell Tunnel: \n",
      "  SSSI\n",
      "----\n",
      "creates an ideal micro-climate for the bats, which is maintained at around 10Â Â°C (50Â Â°F) all year. When the temperature outside the tunnel is colder than this, cold air flows into the bottom of the tunnel where it is warmed by the water, and warmer air flows out along the top of the tunnel. During the summer the air flow is reversed, with warm air flowing into the top of the tunnel and being cooled as it flows back out over the water. By 2006, there were some 12,500 bats roosting in the tunnel, which included the largest known colony of\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = eli5['test_eli5'][12345]['title']\n",
    "doc, res_list = query_es_index(question, es_client, index_name='wiki40b_snippets_100w', n_results=10)\n",
    "\n",
    "print(question)\n",
    "print('-----\\n')\n",
    "for i, res in enumerate(res_list):\n",
    "    print(i+1, \"{}: \\n  {}\\n----\\n{}\\n\".format(\n",
    "        res['article_title'],\n",
    "        res['section_title'] if res['section_title'].strip() != '' else res['article_title'],\n",
    "        res['passage_text']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can immediately see both the strengths and limitations of this approach. The system manages to retrieve documents that are all broadly on topic, emntioning some combination of *water*, *air*, *relative temperature*, and *temperature transfer*. In spite of this, only example 8 ends up containing information that is actually relevant to the question:\n",
    "> Cold air with high relative humidity \"feels\" colder than dry air of the same temperature because high humidity in cold weather increases the conduction of heat from the body.  \n",
    "\n",
    "We got lucky this time, but this passage could as easily have been ranked 11th and not been included in the support document we provide to the answer generation system. As it is, the model will have to sort through mostly off-topic information to find this sentence when reading the resulting supporting document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.b - Training a Dense Retriever with ELI5 and in-batch Negatives\n",
    "<a id='dense_train'></a>\n",
    "\n",
    "The sparse retriever works by finding passages which feature the words from the query. However, it has no way to know *a priori* which of these words are more important in context, and seems to struggle with understanding the central theme of the query (human-perceived temperature).\n",
    "\n",
    "Thankfully, some recent works have taken advantage of advances in pre-trained contextual word representations to solve this problem. Models such as [DPR](https://arxiv.org/abs/2004.04906) or [REALM](https://arxiv.org/abs/2002.08909) for example learn to compute a vector representation of the query, as well as vector representations of Wikipedia passages in such a way that the passages that best answers a question maximize the dot product between the two representations. Retrieval is then reduced to a Maximum Inner Product Search, which can be executed efficiently using systems like [FAISS](https://github.com/facebookresearch/faiss).\n",
    "\n",
    "These successes are very encouraging for our Open-Domain Long Form QA application. However, our task and setup do not quite meet the requirements of either of either of these approaches. On the one hand, the [DPR](https://arxiv.org/abs/2004.04906) system is trained using gold passage annotations: most major QA dataset tell the system which Wikipedia passage contains the answer. Unfortunately, we do not have such annotations for the ELI5 data. On the other hand, while [REALM](https://arxiv.org/abs/2002.08909) is trained without passage supervision, it requires a pretty expensive pre-training step with an [Inverse Cloze Task](https://arxiv.org/abs/1906.00300) (100,000 steps with batch size 4096), and the ability to re-compute the embeddings of all Wikipedia passages regularly during training.\n",
    "\n",
    "We propose: contrastive training matching an ELI5 to its answer against answers of other questions.\n",
    "\n",
    "We start with a pre-trained sentence embedding model. We want a good balance of size: using one of the distilled BERT models presented in [this paper](https://arxiv.org/abs/1909.10351). We learn two different projection matrices to dimension 128 for the question and answer embedding.\n",
    "\n",
    "We compute the dot product between a question embedding end embeddings of all the answers in the batch, and compute the cross-entropy loss for the matching score. With gradient checkpointing, batch size 512, pretty compute-efficient on one GPU.\n",
    "\n",
    "We then use the answer embedding system to compute a representation for all Wikipedia snippets. Querying the index is then just MIPS between the question embedding and snippets representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qar_train_dset = ELI5DatasetQARetriver(eli5['train_eli5'], min_answer_length=64, training=True)\n",
    "qar_valid_dset = ELI5DatasetQARetriver(eli5['validation_eli5'], min_answer_length=64, training=False)\n",
    "\n",
    "class ArgumentsQAR():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 512\n",
    "        self.max_length = 128\n",
    "        self.checkpoint_batch_size = 32\n",
    "        self.print_freq = 100\n",
    "        self.pretrained_model_name = \"google/bert_uncased_L-8_H-768_A-12\"\n",
    "        self.model_save_name = \"retriever_models/eli5_retriever\"\n",
    "        self.learning_rate = 2e-4\n",
    "        self.num_epochs = 20\n",
    "\n",
    "qar_args = ArgumentsQAR()\n",
    "\n",
    "qar_tokenizer, qar_model = make_qa_retriever_model(\n",
    "    model_name=qar_args.pretrained_model_name,\n",
    "    from_file=None,\n",
    "    device=\"cuda:0\"\n",
    ")\n",
    "\n",
    "qar_optimizer = AdamW(qar_model.parameters(), lr=qar_args.learning_rate, eps=1e-8)\n",
    "qar_scheduler = get_linear_schedule_with_warmup(\n",
    "        qar_optimizer,\n",
    "        num_warmup_steps=100,\n",
    "        num_training_steps=qar_args.num_epochs * math.ceil(len(qar_train_dset) / qar_args.batch_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0     0 of   532 \t L: 6.489 \t -- 6.480\n",
      " 0     1 of   532 \t L: 6.465 \t -- 12.869\n",
      " 0    10 of   532 \t L: 6.345 \t -- 70.560\n",
      " 0    20 of   532 \t L: 6.190 \t -- 134.626\n",
      " 0    30 of   532 \t L: 5.623 \t -- 198.792\n",
      " 0    40 of   532 \t L: 4.562 \t -- 262.964\n",
      " 0    50 of   532 \t L: 3.838 \t -- 327.112\n",
      " 0    60 of   532 \t L: 3.340 \t -- 391.108\n",
      " 0    70 of   532 \t L: 3.009 \t -- 455.193\n",
      " 0    80 of   532 \t L: 2.823 \t -- 519.262\n",
      " 0    90 of   532 \t L: 2.625 \t -- 583.353\n",
      " 0   100 of   532 \t L: 2.514 \t -- 647.421\n",
      " 0   110 of   532 \t L: 2.432 \t -- 711.494\n",
      " 0   120 of   532 \t L: 2.266 \t -- 775.736\n",
      " 0   130 of   532 \t L: 2.260 \t -- 839.770\n",
      " 0   140 of   532 \t L: 2.196 \t -- 903.798\n",
      " 0   150 of   532 \t L: 2.060 \t -- 968.103\n",
      " 0   160 of   532 \t L: 2.055 \t -- 1032.143\n",
      " 0   170 of   532 \t L: 1.981 \t -- 1096.322\n",
      " 0   180 of   532 \t L: 1.910 \t -- 1160.407\n",
      " 0   190 of   532 \t L: 1.931 \t -- 1224.338\n",
      " 0   200 of   532 \t L: 1.865 \t -- 1288.429\n",
      " 0   210 of   532 \t L: 1.829 \t -- 1352.615\n",
      " 0   220 of   532 \t L: 1.802 \t -- 1416.758\n",
      " 0   230 of   532 \t L: 1.804 \t -- 1480.798\n",
      " 0   240 of   532 \t L: 1.707 \t -- 1544.887\n",
      " 0   250 of   532 \t L: 1.752 \t -- 1608.984\n",
      " 0   260 of   532 \t L: 1.706 \t -- 1673.054\n",
      " 0   270 of   532 \t L: 1.686 \t -- 1737.152\n",
      " 0   280 of   532 \t L: 1.652 \t -- 1801.269\n",
      " 0   290 of   532 \t L: 1.654 \t -- 1865.402\n",
      " 0   300 of   532 \t L: 1.666 \t -- 1929.520\n",
      " 0   310 of   532 \t L: 1.684 \t -- 1993.646\n",
      " 0   320 of   532 \t L: 1.593 \t -- 2057.753\n",
      " 0   330 of   532 \t L: 1.632 \t -- 2122.172\n",
      " 0   340 of   532 \t L: 1.563 \t -- 2186.190\n",
      " 0   350 of   532 \t L: 1.550 \t -- 2250.396\n"
     ]
    }
   ],
   "source": [
    "for e in range(qar_args.num_epochs):\n",
    "    train_qa_retriever_epoch(\n",
    "        qar_model, qar_train_dset, qar_tokenizer,\n",
    "        qar_optimizer, qar_scheduler, qar_args, e\n",
    "    )\n",
    "    m_save_dict = {\n",
    "        'model': qar_model.state_dict(),\n",
    "        'optimizer': qar_optimizer.state_dict(),\n",
    "        'scheduler': qar_scheduler.state_dict(),\n",
    "    }\n",
    "    print(\"Saving model {}\".format(qar_args.model_save_name))\n",
    "    torch.save(m_save_dict, '{}_{}.pth'.format(qar_args.model_save_name, e))\n",
    "    eval_loss = evaluate_qa_retriever(qar_model, qar_valid_dset, qar_tokenizer, qar_args)\n",
    "    print(\"Evaluation loss epoch {:4d}: {:.3f}\".format(e, eval_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code to build the index is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.c -  Indexing Wikipedia with a Trained Dense Retriever\n",
    "<a id='dense_use'></a>\n",
    "\n",
    "Can we take advantage of our data to do better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qar_tokenizer, qar_model = make_qa_retriever_model(\n",
    "    model_name=\"google/bert_uncased_L-8_H-768_A-12\",\n",
    "    from_file=\"retriever_models/eli5_retriever_model_l-8_h-768_b-512-512_9.pth\",\n",
    "    device=\"cuda:0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_res = faiss.StandardGpuResources()\n",
    "wiki40b_passage_reps = np.memmap(\n",
    "            'wiki40b_passages_reps_32_l-8_h-768_b-512-512.dat',\n",
    "            dtype='float32', mode='r',\n",
    "            shape=(wiki40b_snippets.num_rows, 128)\n",
    ")\n",
    "\n",
    "wiki40b_index_flat = faiss.IndexFlatIP(128)\n",
    "wiki40b_gpu_index = faiss.index_cpu_to_gpu(faiss_res, 1, wiki40b_index_flat)\n",
    "wiki40b_gpu_index.add(wiki40b_passage_reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why does water heated to room temperature feel colder than the air around it?\n",
      "-----\n",
      "\n",
      "0 Fugacity: \n",
      "  History\n",
      "----\n",
      "played a similar role to that of temperature in heat flow.\n",
      "\n",
      "1 Heat transfer: \n",
      "  Heat transfer in the human body & Evaporative cooling\n",
      "----\n",
      "when the skin is completely wet. The body continuously loses water by evaporation but the most significant amount of heat loss occurs during periods of increased physical activity. Evaporative cooling Evaporative cooling happens when water vapor is added to the surrounding air. The energy needed to evaporate the water is taken from the air in the form of sensible heat and converted into latent heat, while the air remains at a constant enthalpy. Latent heat describes the amount of heat that is needed to evaporate the liquid; this heat comes from the liquid itself and the surrounding gas and surfaces.\n",
      "\n",
      "2 Johan SandstrÃ¶m: \n",
      "  SandstrÃ¶m  Theorem\n",
      "----\n",
      "at greater pressures. There is an ambiguity, however, as to the meaning of the terms 'heating' and 'cooling' in Sandstrom's theorem. So far, heating and cooling has always been interpreted in the literature as being associated with 'surface heating' and 'surface cooling' respectively.\n",
      "In real fluids, however, molecular and turbulent diffusion always cause internal heating/cooling even in absence of external heating/cooling, as long as the temperature of the fluid considered is non-uniform. As is well-known, molecular and turbulent diffusion tends to relax the system toward thermodynamic equilibrium, i.e., toward an isothermal state, which for a statically stable fluid, will warm up\n",
      "\n",
      "3 Thermal equilibrium: \n",
      "  Bodies prepared with separately uniform temperatures, then put into purely thermal communication with each other\n",
      "----\n",
      "are not in a relation of thermal equilibrium, heat will flow from the hotter to the colder, by whatever pathway, conductive or radiative, is available, and this flow will continue until thermal equilibrium is reached and then they will have the same temperature.\n",
      "One form of thermal equilibrium is radiative exchange equilibrium. Two bodies, each with its own uniform temperature, in solely radiative connection, no matter how far apart, or what partially obstructive, reflective, or refractive, obstacles lie in their path of radiative exchange, not moving relative to one another, will exchange thermal radiation, in net the hotter transferring energy to\n",
      "\n",
      "4 Evaporative cooler: \n",
      "  Physical principles\n",
      "----\n",
      "air condition and moving along a line of constant enthalpy toward a state of higher humidity.\n",
      "A simple example of natural evaporative cooling is perspiration, or sweat, secreted by the body, evaporation of which cools the body. The amount of heat transfer depends on the evaporation rate, however for each kilogram of water vaporized 2,257Â kJ of energy (about 890Â BTU per pound of pure water, at 95Â Â°F (35Â Â°C)) are transferred. The evaporation rate depends on the temperature and humidity of the air, which is why sweat accumulates more on humid days, as it does not evaporate fast enough.\n",
      "Vapor-compression refrigeration uses evaporative cooling,\n",
      "\n",
      "5 Thermal contact conductance: \n",
      "  Factors influencing contact conductance & Contact pressure\n",
      "----\n",
      "Thermal contact conductance In physics, thermal contact conductance is the study of heat conduction between solid bodies in thermal contact. The thermal contact conductance coefficient, , is a property indicating the thermal conductivity, or ability to conduct heat, between two bodies in contact. The inverse of this property is termed thermal contact resistance. Factors influencing contact conductance Thermal contact conductance is a complicated phenomenon, influenced by many factors. Experience shows that the most important ones are as follows: Contact pressure For thermal transport between two contacting bodies, such as particles in a granular medium, the contact pressure is the factor\n",
      "\n",
      "6 Thermodynamic temperature: \n",
      "  The heat of phase changes\n",
      "----\n",
      "to completely boil or vaporize water (what is known as enthalpy of vaporization) is roughly 540 times that required for a one-degree increase.\n",
      "Water's sizable enthalpy of vaporization is why one's skin can be burned so quickly as steam condenses on it (heading from red to green in Fig.Â 7Â above). In the opposite direction, this is why one's skin feels cool as liquid water on it evaporates (a process that occurs at a sub-ambient wet-bulb temperature that is dependent on relative humidity). Water's highly energetic enthalpy of vaporization is also an important factor underlying why solar pool covers (floating, insulated blankets that\n",
      "\n",
      "7 Temperature: \n",
      "  Local thermodynamic equilibrium & Bodies in thermodynamic equilibrium\n",
      "----\n",
      "and this is because temperature is an intensive variable. Bodies in thermodynamic equilibrium For experimental physics, hotness means that, when comparing any two given bodies in their respective separate thermodynamic equilibria, any two suitably given empirical thermometers with numerical scale readings will agree as to which is the hotter of the two given bodies, or that they have the same temperature. This does not require the two thermometers to have a linear relation between their numerical scale readings, but it does require that the relation between their numerical readings shall be strictly monotonic. A definite sense of greater hotness can\n",
      "\n",
      "8 Tail flick test: \n",
      "  Limitations\n",
      "----\n",
      "water in place of heat has been developed to allow that distinction.\n",
      "\n",
      "9 Latent heat: \n",
      "  Usage\n",
      "----\n",
      "phase of atmospheric or ocean water,  vaporization, condensation, freezing or melting, whereas sensible heat is energy transferred that is evident in change of the temperature of the atmosphere or ocean, or ice, without those phase changes, though it is associated with changes of pressure and volume.\n",
      "The original usage of the term, as introduced by Black, was applied to systems that were intentionally held at constant temperature. Such usage referred to latent heat of expansion and several other related latent heats. These latent heats are defined independently of the conceptual framework of thermodynamics.\n",
      "When a body is heated at constant temperature\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = eli5['test_eli5'][12345]['title']\n",
    "doc, res_list = query_qa_dense_index(\n",
    "    question,\n",
    "    qar_model, qar_tokenizer,\n",
    "    wiki40b_snippets, wiki40b_gpu_index,\n",
    "    n_results=10\n",
    ")\n",
    "\n",
    "print(question)\n",
    "print('-----\\n')\n",
    "for i, res in enumerate(res_list):\n",
    "    print(i, \"{}: \\n  {}\\n----\\n{}\\n\".format(\n",
    "        res['article_title'],\n",
    "        res['section_title'] if res['section_title'].strip() != '' else res['article_title'],\n",
    "        res['passage_text']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.d -  Retriever Model Evaluation\n",
    "<a id='dense_eval'></a>\n",
    "\n",
    "How can we evaluate the embedding model? Let's start by grabbing a couple of useful metrics from the `nlp` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "010 Sparse: RG-0.2652 BS-0.8053 | Dense: RG-0.2521 BS-0.8141 \t 103.34\n",
      "020 Sparse: RG-0.2657 BS-0.8068 | Dense: RG-0.2647 BS-0.8193 \t 174.52\n",
      "030 Sparse: RG-0.2631 BS-0.8052 | Dense: RG-0.2591 BS-0.8156 \t 261.19\n",
      "040 Sparse: RG-0.2623 BS-0.8049 | Dense: RG-0.2594 BS-0.8149 \t 352.42\n",
      "050 Sparse: RG-0.2660 BS-0.8060 | Dense: RG-0.2639 BS-0.8176 \t 457.43\n",
      "060 Sparse: RG-0.2698 BS-0.8053 | Dense: RG-0.2649 BS-0.8172 \t 540.86\n",
      "070 Sparse: RG-0.2684 BS-0.8058 | Dense: RG-0.2630 BS-0.8187 \t 602.46\n",
      "080 Sparse: RG-0.2671 BS-0.8062 | Dense: RG-0.2640 BS-0.8185 \t 694.04\n",
      "090 Sparse: RG-0.2646 BS-0.8063 | Dense: RG-0.2622 BS-0.8182 \t 763.54\n",
      "100 Sparse: RG-0.2627 BS-0.8058 | Dense: RG-0.2619 BS-0.8190 \t 822.09\n",
      "110 Sparse: RG-0.2646 BS-0.8056 | Dense: RG-0.2626 BS-0.8186 \t 900.97\n",
      "120 Sparse: RG-0.2673 BS-0.8055 | Dense: RG-0.2661 BS-0.8177 \t 1013.28\n",
      "130 Sparse: RG-0.2685 BS-0.8053 | Dense: RG-0.2678 BS-0.8175 \t 1080.84\n",
      "140 Sparse: RG-0.2660 BS-0.8050 | Dense: RG-0.2654 BS-0.8180 \t 1380.19\n",
      "150 Sparse: RG-0.2646 BS-0.8049 | Dense: RG-0.2639 BS-0.8172 \t 1466.71\n",
      "160 Sparse: RG-0.2639 BS-0.8051 | Dense: RG-0.2648 BS-0.8178 \t 1607.58\n",
      "170 Sparse: RG-0.2612 BS-0.8053 | Dense: RG-0.2618 BS-0.8174 \t 1677.37\n",
      "180 Sparse: RG-0.2616 BS-0.8056 | Dense: RG-0.2627 BS-0.8168 \t 1779.52\n",
      "190 Sparse: RG-0.2614 BS-0.8055 | Dense: RG-0.2626 BS-0.8166 \t 1850.76\n",
      "200 Sparse: RG-0.2610 BS-0.8056 | Dense: RG-0.2641 BS-0.8177 \t 1971.58\n",
      "210 Sparse: RG-0.2620 BS-0.8057 | Dense: RG-0.2649 BS-0.8175 \t 2082.52\n",
      "220 Sparse: RG-0.2620 BS-0.8058 | Dense: RG-0.2638 BS-0.8169 \t 2129.78\n",
      "230 Sparse: RG-0.2626 BS-0.8060 | Dense: RG-0.2639 BS-0.8168 \t 2187.62\n",
      "240 Sparse: RG-0.2625 BS-0.8063 | Dense: RG-0.2638 BS-0.8169 \t 2264.72\n",
      "250 Sparse: RG-0.2628 BS-0.8066 | Dense: RG-0.2634 BS-0.8167 \t 2366.96\n",
      "260 Sparse: RG-0.2632 BS-0.8064 | Dense: RG-0.2633 BS-0.8166 \t 2441.70\n",
      "270 Sparse: RG-0.2635 BS-0.8063 | Dense: RG-0.2635 BS-0.8164 \t 2536.18\n",
      "280 Sparse: RG-0.2648 BS-0.8064 | Dense: RG-0.2641 BS-0.8172 \t 2623.53\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-63b330ce8393>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mes_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'wiki40b_snippets_100w'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mn_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     )\n\u001b[1;32m     48\u001b[0m     \u001b[0msparse_passages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'passage_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msparse_res_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/transformers/examples/eli5/eli5_utils.py\u001b[0m in \u001b[0;36mquery_es_index\u001b[0;34m(question, es_client, index_name, n_results)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 }\n\u001b[1;32m     80\u001b[0m             },\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;34m\"size\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mn_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         }\n\u001b[1;32m     83\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/elasticsearch/client/utils.py\u001b[0m in \u001b[0;36m_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/elasticsearch/client/__init__.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, body, index, doc_type, params, headers)\u001b[0m\n\u001b[1;32m   1621\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m             \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1624\u001b[0m         )\n\u001b[1;32m   1625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/elasticsearch/transport.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    360\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                     \u001b[0mignore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m                 )\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/elasticsearch/connection/http_urllib3.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             response = self.pool.urlopen(\n\u001b[0;32m--> 229\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRetry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_headers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m             )\n\u001b[1;32m    231\u001b[0m             \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    670\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m             )\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    419\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    414\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1342\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "# load the ROUGE and BERTscore metrics from the nlp library\n",
    "nlp_rouge = nlp.load_metric('rouge')\n",
    "nlp_bertscore = nlp.load_metric('bertscore')\n",
    "\n",
    "# takes a list of retrieved documents and a list of possible answers\n",
    "# for a question and returns a measure of the lexical overlap between the\n",
    "# passages and answer\n",
    "def get_aggregate_rouge(res_list, answers):\n",
    "    res = np.zeros((len(res_list), len(answers), 3))\n",
    "    for i, hit in enumerate(res_list):\n",
    "        for j, a in enumerate(answers):\n",
    "            if len(hit.strip()) > 0 and len(a.strip()) > 0:\n",
    "                # get Rouge-1 P/R/F for each passage/answer pair\n",
    "                score = nlp_rouge.compute([hit], [a], rouge_types=['rouge1'])['rouge1'].mid\n",
    "                res[i,j] = np.array([score.precision, score.recall, score.fmeasure])\n",
    "    # average P/R/F rouge scores, then find best passage-answer match\n",
    "    return res.mean(axis=2).max()\n",
    "\n",
    "# Same with BERTscore metri which aligns contextual word embedings\n",
    "def get_aggregate_bertscore(res_list, answers):\n",
    "    res = np.zeros((len(res_list), len(answers), 3))\n",
    "    for i, hit in enumerate(res_list):\n",
    "        for j, a in enumerate(answers):\n",
    "            if len(hit.strip()) > 0 and len(a.strip()) > 0:\n",
    "                # get Rouge-1 P/R/F for each passage/answer pair\n",
    "                score = nlp_bertscore.compute([hit], [a], lang='en')\n",
    "                res[i,j] = np.array([score['precision'].item(), score['recall'].item(), score['f1'].item()])\n",
    "    # average P/R/F rouge scores, then find best passage-answer match\n",
    "    return res.mean(axis=2).max()\n",
    "\n",
    "# Compare which retriever finds passages that have the most\n",
    "# lexical overlap with the ELI5 answers\n",
    "st_time = time()\n",
    "tot_rg_sparse = 0.\n",
    "tot_bs_sparse = 0.\n",
    "tot_rg_dense = 0.\n",
    "tot_bs_dense = 0.\n",
    "valid_slice = eli5['validation_eli5'][:1000]\n",
    "for i, (question, answers) in enumerate(zip(valid_slice['title'], valid_slice['answers'])):\n",
    "    # get documents with sparse retriever\n",
    "    _, sparse_res_list = query_es_index(\n",
    "        question,\n",
    "        es_client, index_name='wiki40b_snippets_100w',\n",
    "        n_results=5\n",
    "    )\n",
    "    sparse_passages = [res['passage_text'] for res in sparse_res_list]\n",
    "    if len(sparse_passages) == 0:\n",
    "        sparse_passages = [question]\n",
    "    tot_rg_sparse += get_aggregate_rouge(sparse_passages, answers['text'])\n",
    "    tot_bs_sparse += get_aggregate_bertscore(sparse_passages, answers['text'])\n",
    "    # get documents with dense retriever\n",
    "    _, dense_res_list = query_qa_dense_index(\n",
    "        question,\n",
    "        qar_model, qar_tokenizer,\n",
    "        wiki40b_snippets, wiki40b_gpu_index,\n",
    "        n_results=5\n",
    "    )\n",
    "    dense_passages = [res['passage_text'] for res in dense_res_list]\n",
    "    tot_rg_dense += get_aggregate_rouge(dense_passages, answers['text'])\n",
    "    tot_bs_dense += get_aggregate_bertscore(dense_passages, answers['text'])\n",
    "    # show average scores side by side\n",
    "    if (i+1) % 10 == 0:\n",
    "        print(\"{:03d} Sparse: RG-{:.4f} BS-{:.4f} | Dense: RG-{:.4f} BS-{:.4f} \\t {:.2f}\".format(\n",
    "            i+1,\n",
    "            tot_rg_sparse / (i+1), tot_bs_sparse / (i+1),\n",
    "            tot_rg_dense / (i+1), tot_bs_dense / (i+1),\n",
    "            time() - st_time\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 Sparse: RG-0.2609 BS-0.8014 | Dense: RG-0.2634 BS-0.8135 \t 1923.04\n"
     ]
    }
   ],
   "source": [
    "print(\"{:03d} Sparse: RG-{:.4f} BS-{:.4f} | Dense: RG-{:.4f} BS-{:.4f} \\t {:.2f}\".format(\n",
    "            i+1,\n",
    "            tot_rg_sparse / (i+1), tot_bs_sparse / (i+1),\n",
    "            tot_rg_dense / (i+1), tot_bs_dense / (i+1),\n",
    "            time() - st_time\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Answer Generation Model\n",
    "<a id='generation'></a>\n",
    "\n",
    "Once we have a question and a document containing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgumentsS2S():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 16\n",
    "        self.backward_freq = 8\n",
    "        self.max_length = 1024\n",
    "        self.print_freq = 100\n",
    "        self.model_save_name = \"seq2seq_models/bart_model_curriculim\"\n",
    "        self.learning_rate = 2e-4\n",
    "        self.num_epochs = 20\n",
    "\n",
    "s2s_args = ArgumentsS2S()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_s2s_tokenizer, pre_model = make_qa_s2s_model(\n",
    "    model_name=\"facebook/bart-large\",\n",
    "    from_file=None,\n",
    "    device=\"cuda:0\"\n",
    ")\n",
    "qa_s2s_model = torch.nn.DataParallel(pre_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5_train_docs = json.load(open('precomputed/eli5_train_precomputed_dense_docs.json'))\n",
    "eli5_valid_docs = json.load(open('precomputed/eli5_valid_precomputed_dense_docs.json'))\n",
    "\n",
    "s2s_train_dset = ELI5DatasetS2S(eli5['train_eli5'], document_cache=dict([(k, d) for k, d, src_ls in eli5_train_docs]))\n",
    "s2s_valid_dset = ELI5DatasetS2S(eli5['validation_eli5'], document_cache=dict([(k, d) for k, d, src_ls in eli5_valid_docs]), training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qda_difficulty(question_doc, answer):\n",
    "    qd_words = dict([(w, True) for w in question_doc.lower().split()])\n",
    "    recall = len([w for w in answer.lower().split() if w in qd_words]) / len(answer.split())\n",
    "    return recall\n",
    "\n",
    "recall_diff = [(i, qda_difficulty(*s2s_train_dset[i])) for i in range(len(s2s_train_dset))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "578953"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recall_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to mix it up a little to avoid teaching the model to only copy\n",
    "from random import seed, shuffle\n",
    "seed(1111)\n",
    "sorted_diff = [i for i, s in sorted(recall_diff, key=lambda x:x[1], reverse=True)]\n",
    "easy_diff = sorted_diff[:100000] + sorted_diff[300000:400000]\n",
    "shuffle(easy_diff)\n",
    "medium_diff = sorted_diff[100000:200000] + sorted_diff[400000:500000]\n",
    "shuffle(medium_diff)\n",
    "hard_diff =  sorted_diff[200000:300000] + sorted_diff[500000:]\n",
    "shuffle(hard_diff)\n",
    "\n",
    "curriculum_order = easy_diff + medium_diff + hard_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2s_train_dset.qa_id_list = [s2s_train_dset.qa_id_list[i] for i in curriculum_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_qa_s2s_epoch(model, dataset, tokenizer, optimizer, scheduler, args, e=0, curriculum=False):\n",
    "    model.train()\n",
    "    # make iterator\n",
    "    if curriculum:\n",
    "        train_sampler = SequentialSampler(dataset)\n",
    "    else:\n",
    "        train_sampler = RandomSampler(dataset)\n",
    "    model_collate_fn = functools.partial(\n",
    "        make_qa_s2s_batch,\n",
    "        tokenizer=tokenizer, max_len=args.max_length, device='cuda:0'\n",
    "    )\n",
    "    data_loader = DataLoader(\n",
    "        dataset, batch_size=args.batch_size,\n",
    "        sampler=train_sampler, collate_fn=model_collate_fn\n",
    "    )\n",
    "    epoch_iterator = tqdm(data_loader, desc=\"Iteration\", disable=True)\n",
    "    # accumulate loss since last print\n",
    "    loc_steps = 0\n",
    "    loc_loss = 0.0\n",
    "    st_time = time()\n",
    "    for step, batch_inputs in enumerate(epoch_iterator):\n",
    "        pre_loss = model(**batch_inputs)[0]\n",
    "        loss = pre_loss.sum() / pre_loss.shape[0]\n",
    "        loss.backward()\n",
    "        # optimizer\n",
    "        if step % args.backward_freq == 0:\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            model.zero_grad()\n",
    "        # some printing within the epoch\n",
    "        loc_loss += loss.item()\n",
    "        loc_steps += 1\n",
    "        if step % args.print_freq == 0 or step == 1:\n",
    "            print(\n",
    "                \"{:2d} {:5d} of {:5d} \\t L: {:.3f} \\t -- {:.3f}\".format(\n",
    "                    e, step,\n",
    "                    len(dataset) // args.batch_size,\n",
    "                    loc_loss / loc_steps,\n",
    "                    time() - st_time,\n",
    "                )\n",
    "            )\n",
    "            loc_loss = 0\n",
    "            loc_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yacine/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0     0 of 36184 \t L: 4.873 \t -- 29.738\n",
      " 0     1 of 36184 \t L: 4.564 \t -- 31.842\n",
      " 0   100 of 36184 \t L: 4.344 \t -- 151.468\n",
      " 0   200 of 36184 \t L: 3.670 \t -- 271.732\n",
      " 0   300 of 36184 \t L: 3.365 \t -- 390.455\n",
      " 0   400 of 36184 \t L: 3.256 \t -- 509.767\n",
      " 0   500 of 36184 \t L: 3.190 \t -- 628.361\n",
      " 0   600 of 36184 \t L: 3.165 \t -- 747.449\n",
      " 0   700 of 36184 \t L: 3.152 \t -- 865.724\n",
      " 0   800 of 36184 \t L: 3.129 \t -- 985.760\n",
      " 0   900 of 36184 \t L: 3.121 \t -- 1105.362\n",
      " 0  1000 of 36184 \t L: 3.132 \t -- 1223.780\n",
      " 0  1100 of 36184 \t L: 3.129 \t -- 1342.123\n",
      " 0  1200 of 36184 \t L: 3.118 \t -- 1460.694\n",
      " 0  1300 of 36184 \t L: 3.147 \t -- 1579.496\n",
      " 0  1400 of 36184 \t L: 3.119 \t -- 1698.458\n",
      " 0  1500 of 36184 \t L: 3.134 \t -- 1816.532\n",
      " 0  1600 of 36184 \t L: 3.108 \t -- 1935.115\n",
      " 0  1700 of 36184 \t L: 3.110 \t -- 2054.195\n",
      " 0  1800 of 36184 \t L: 3.089 \t -- 2172.775\n",
      " 0  1900 of 36184 \t L: 3.109 \t -- 2291.965\n",
      " 0  2000 of 36184 \t L: 3.094 \t -- 2411.028\n",
      " 0  2100 of 36184 \t L: 3.109 \t -- 2530.128\n",
      " 0  2200 of 36184 \t L: 3.095 \t -- 2649.164\n",
      " 0  2300 of 36184 \t L: 3.109 \t -- 2767.874\n",
      " 0  2400 of 36184 \t L: 3.133 \t -- 2886.084\n",
      " 0  2500 of 36184 \t L: 3.126 \t -- 3004.957\n",
      " 0  2600 of 36184 \t L: 3.112 \t -- 3123.163\n",
      " 0  2700 of 36184 \t L: 3.095 \t -- 3242.224\n",
      " 0  2800 of 36184 \t L: 3.105 \t -- 3360.680\n",
      " 0  2900 of 36184 \t L: 3.147 \t -- 3479.066\n",
      " 0  3000 of 36184 \t L: 3.136 \t -- 3597.927\n",
      " 0  3100 of 36184 \t L: 3.137 \t -- 3717.500\n",
      " 0  3200 of 36184 \t L: 3.145 \t -- 3835.843\n",
      " 0  3300 of 36184 \t L: 3.127 \t -- 3954.124\n",
      " 0  3400 of 36184 \t L: 3.148 \t -- 4072.302\n",
      " 0  3500 of 36184 \t L: 3.144 \t -- 4190.958\n",
      " 0  3600 of 36184 \t L: 3.127 \t -- 4309.110\n",
      " 0  3700 of 36184 \t L: 3.127 \t -- 4427.800\n",
      " 0  3800 of 36184 \t L: 3.123 \t -- 4547.440\n",
      " 0  3900 of 36184 \t L: 3.125 \t -- 4665.853\n",
      " 0  4000 of 36184 \t L: 3.118 \t -- 4785.041\n",
      " 0  4100 of 36184 \t L: 3.132 \t -- 4903.399\n",
      " 0  4200 of 36184 \t L: 3.142 \t -- 5021.421\n",
      " 0  4300 of 36184 \t L: 3.119 \t -- 5139.870\n",
      " 0  4400 of 36184 \t L: 3.122 \t -- 5257.836\n",
      " 0  4500 of 36184 \t L: 3.134 \t -- 5376.653\n",
      " 0  4600 of 36184 \t L: 3.115 \t -- 5494.935\n",
      " 0  4700 of 36184 \t L: 3.120 \t -- 5613.021\n",
      " 0  4800 of 36184 \t L: 3.129 \t -- 5731.224\n",
      " 0  4900 of 36184 \t L: 3.095 \t -- 5849.523\n",
      " 0  5000 of 36184 \t L: 3.114 \t -- 5968.352\n",
      " 0  5100 of 36184 \t L: 3.117 \t -- 6087.596\n",
      " 0  5200 of 36184 \t L: 3.111 \t -- 6206.362\n",
      " 0  5300 of 36184 \t L: 3.101 \t -- 6328.080\n",
      " 0  5400 of 36184 \t L: 3.120 \t -- 6446.945\n",
      " 0  5500 of 36184 \t L: 3.122 \t -- 6565.484\n",
      " 0  5600 of 36184 \t L: 3.111 \t -- 6684.981\n",
      " 0  5700 of 36184 \t L: 3.103 \t -- 6802.878\n",
      " 0  5800 of 36184 \t L: 3.113 \t -- 6921.241\n",
      " 0  5900 of 36184 \t L: 3.087 \t -- 7039.926\n",
      " 0  6000 of 36184 \t L: 3.102 \t -- 7157.613\n",
      " 0  6100 of 36184 \t L: 3.103 \t -- 7276.094\n",
      " 0  6200 of 36184 \t L: 3.147 \t -- 7394.036\n",
      " 0  6300 of 36184 \t L: 3.145 \t -- 7512.767\n",
      " 0  6400 of 36184 \t L: 3.129 \t -- 7630.784\n",
      " 0  6500 of 36184 \t L: 3.117 \t -- 7748.797\n",
      " 0  6600 of 36184 \t L: 3.103 \t -- 7866.446\n",
      " 0  6700 of 36184 \t L: 3.112 \t -- 7984.644\n",
      " 0  6800 of 36184 \t L: 3.112 \t -- 8102.808\n",
      " 0  6900 of 36184 \t L: 3.131 \t -- 8221.456\n",
      " 0  7000 of 36184 \t L: 3.116 \t -- 8340.579\n",
      " 0  7100 of 36184 \t L: 3.126 \t -- 8458.706\n",
      " 0  7200 of 36184 \t L: 3.126 \t -- 8576.907\n",
      " 0  7300 of 36184 \t L: 3.103 \t -- 8694.885\n",
      " 0  7400 of 36184 \t L: 3.096 \t -- 8813.591\n",
      " 0  7500 of 36184 \t L: 3.113 \t -- 8931.921\n",
      " 0  7600 of 36184 \t L: 3.116 \t -- 9050.482\n",
      " 0  7700 of 36184 \t L: 3.105 \t -- 9169.413\n",
      " 0  7800 of 36184 \t L: 3.095 \t -- 9287.338\n",
      " 0  7900 of 36184 \t L: 3.079 \t -- 9404.970\n",
      " 0  8000 of 36184 \t L: 3.077 \t -- 9523.181\n",
      " 0  8100 of 36184 \t L: 3.094 \t -- 9641.833\n",
      " 0  8200 of 36184 \t L: 3.099 \t -- 9761.149\n",
      " 0  8300 of 36184 \t L: 3.096 \t -- 9879.457\n",
      " 0  8400 of 36184 \t L: 3.085 \t -- 9997.936\n",
      " 0  8500 of 36184 \t L: 3.087 \t -- 10115.913\n",
      " 0  8600 of 36184 \t L: 3.073 \t -- 10233.882\n",
      " 0  8700 of 36184 \t L: 3.101 \t -- 10352.449\n",
      " 0  8800 of 36184 \t L: 3.076 \t -- 10470.441\n",
      " 0  8900 of 36184 \t L: 3.100 \t -- 10589.281\n",
      " 0  9000 of 36184 \t L: 3.108 \t -- 10707.630\n",
      " 0  9100 of 36184 \t L: 3.081 \t -- 10825.790\n",
      " 0  9200 of 36184 \t L: 3.098 \t -- 10944.375\n",
      " 0  9300 of 36184 \t L: 3.099 \t -- 11062.435\n",
      " 0  9400 of 36184 \t L: 3.105 \t -- 11180.650\n",
      " 0  9500 of 36184 \t L: 3.077 \t -- 11299.120\n",
      " 0  9600 of 36184 \t L: 3.076 \t -- 11416.897\n",
      " 0  9700 of 36184 \t L: 3.102 \t -- 11535.318\n",
      " 0  9800 of 36184 \t L: 3.105 \t -- 11654.471\n",
      " 0  9900 of 36184 \t L: 3.091 \t -- 11772.652\n",
      " 0 10000 of 36184 \t L: 3.096 \t -- 11890.651\n",
      " 0 10100 of 36184 \t L: 3.095 \t -- 12009.906\n",
      " 0 10200 of 36184 \t L: 3.107 \t -- 12127.986\n",
      " 0 10300 of 36184 \t L: 3.102 \t -- 12246.169\n",
      " 0 10400 of 36184 \t L: 3.074 \t -- 12365.400\n",
      " 0 10500 of 36184 \t L: 3.084 \t -- 12484.082\n",
      " 0 10600 of 36184 \t L: 3.100 \t -- 12602.851\n",
      " 0 10700 of 36184 \t L: 3.089 \t -- 12720.921\n",
      " 0 10800 of 36184 \t L: 3.083 \t -- 12839.534\n",
      " 0 10900 of 36184 \t L: 3.081 \t -- 12957.595\n",
      " 0 11000 of 36184 \t L: 3.106 \t -- 13076.102\n",
      " 0 11100 of 36184 \t L: 3.081 \t -- 13194.465\n",
      " 0 11200 of 36184 \t L: 3.090 \t -- 13313.404\n",
      " 0 11300 of 36184 \t L: 3.103 \t -- 13432.433\n",
      " 0 11400 of 36184 \t L: 3.085 \t -- 13552.142\n",
      " 0 11500 of 36184 \t L: 3.093 \t -- 13670.713\n",
      " 0 11600 of 36184 \t L: 3.095 \t -- 13789.575\n",
      " 0 11700 of 36184 \t L: 3.092 \t -- 13908.972\n",
      " 0 11800 of 36184 \t L: 3.078 \t -- 14028.050\n",
      " 0 11900 of 36184 \t L: 3.090 \t -- 14147.285\n",
      " 0 12000 of 36184 \t L: 3.093 \t -- 14266.613\n",
      " 0 12100 of 36184 \t L: 3.076 \t -- 14385.724\n",
      " 0 12200 of 36184 \t L: 3.094 \t -- 14505.126\n",
      " 0 12300 of 36184 \t L: 3.076 \t -- 14623.953\n",
      " 0 12400 of 36184 \t L: 3.086 \t -- 14744.313\n",
      " 0 12500 of 36184 \t L: 3.057 \t -- 14864.042\n",
      " 0 12600 of 36184 \t L: 3.197 \t -- 14983.551\n",
      " 0 12700 of 36184 \t L: 3.171 \t -- 15103.260\n",
      " 0 12800 of 36184 \t L: 3.173 \t -- 15222.084\n",
      " 0 12900 of 36184 \t L: 3.189 \t -- 15341.855\n",
      " 0 13000 of 36184 \t L: 3.201 \t -- 15461.407\n",
      " 0 13100 of 36184 \t L: 3.186 \t -- 15580.858\n",
      " 0 13200 of 36184 \t L: 3.176 \t -- 15700.522\n",
      " 0 13300 of 36184 \t L: 3.182 \t -- 15819.526\n",
      " 0 13400 of 36184 \t L: 3.168 \t -- 15938.934\n",
      " 0 13500 of 36184 \t L: 3.173 \t -- 16058.405\n",
      " 0 13600 of 36184 \t L: 3.174 \t -- 16178.298\n",
      " 0 13700 of 36184 \t L: 3.148 \t -- 16298.226\n",
      " 0 13800 of 36184 \t L: 3.156 \t -- 16418.003\n",
      " 0 13900 of 36184 \t L: 3.176 \t -- 16537.482\n",
      " 0 14000 of 36184 \t L: 3.173 \t -- 16656.152\n",
      " 0 14100 of 36184 \t L: 3.179 \t -- 16775.739\n",
      " 0 14200 of 36184 \t L: 3.174 \t -- 16895.625\n",
      " 0 14300 of 36184 \t L: 3.185 \t -- 17015.792\n",
      " 0 14400 of 36184 \t L: 3.173 \t -- 17135.994\n",
      " 0 14500 of 36184 \t L: 3.164 \t -- 17255.856\n",
      " 0 14600 of 36184 \t L: 3.163 \t -- 17374.778\n",
      " 0 14700 of 36184 \t L: 3.173 \t -- 17493.498\n",
      " 0 14800 of 36184 \t L: 3.185 \t -- 17612.475\n",
      " 0 14900 of 36184 \t L: 3.172 \t -- 17731.410\n",
      " 0 15000 of 36184 \t L: 3.184 \t -- 17850.656\n",
      " 0 15100 of 36184 \t L: 3.177 \t -- 17968.940\n",
      " 0 15200 of 36184 \t L: 3.165 \t -- 18088.315\n",
      " 0 15300 of 36184 \t L: 3.178 \t -- 18206.938\n",
      " 0 15400 of 36184 \t L: 3.176 \t -- 18325.541\n",
      " 0 15500 of 36184 \t L: 3.177 \t -- 18444.530\n",
      " 0 15600 of 36184 \t L: 3.178 \t -- 18563.831\n",
      " 0 15700 of 36184 \t L: 3.164 \t -- 18682.515\n",
      " 0 15800 of 36184 \t L: 3.151 \t -- 18801.754\n",
      " 0 15900 of 36184 \t L: 3.172 \t -- 18920.816\n",
      " 0 16000 of 36184 \t L: 3.165 \t -- 19039.724\n",
      " 0 16100 of 36184 \t L: 3.176 \t -- 19158.382\n",
      " 0 16200 of 36184 \t L: 3.168 \t -- 19276.558\n",
      " 0 16300 of 36184 \t L: 3.166 \t -- 19396.064\n",
      " 0 16400 of 36184 \t L: 3.178 \t -- 19513.974\n",
      " 0 16500 of 36184 \t L: 3.160 \t -- 19632.118\n",
      " 0 16600 of 36184 \t L: 3.185 \t -- 19751.219\n",
      " 0 16700 of 36184 \t L: 3.174 \t -- 19869.424\n",
      " 0 16800 of 36184 \t L: 3.168 \t -- 19988.217\n",
      " 0 16900 of 36184 \t L: 3.165 \t -- 20106.749\n",
      " 0 17000 of 36184 \t L: 3.185 \t -- 20225.599\n",
      " 0 17100 of 36184 \t L: 3.182 \t -- 20344.442\n",
      " 0 17200 of 36184 \t L: 3.182 \t -- 20463.011\n",
      " 0 17300 of 36184 \t L: 3.173 \t -- 20582.601\n",
      " 0 17400 of 36184 \t L: 3.159 \t -- 20701.124\n",
      " 0 17500 of 36184 \t L: 3.163 \t -- 20820.074\n",
      " 0 17600 of 36184 \t L: 3.149 \t -- 20939.329\n",
      " 0 17700 of 36184 \t L: 3.179 \t -- 21059.083\n",
      " 0 17800 of 36184 \t L: 3.142 \t -- 21177.793\n",
      " 0 17900 of 36184 \t L: 3.178 \t -- 21297.147\n",
      " 0 18000 of 36184 \t L: 3.168 \t -- 21415.721\n",
      " 0 18100 of 36184 \t L: 3.163 \t -- 21534.119\n",
      " 0 18200 of 36184 \t L: 3.153 \t -- 21653.124\n",
      " 0 18300 of 36184 \t L: 3.183 \t -- 21771.925\n",
      " 0 18400 of 36184 \t L: 3.176 \t -- 21891.032\n",
      " 0 18500 of 36184 \t L: 3.163 \t -- 22009.766\n",
      " 0 18600 of 36184 \t L: 3.167 \t -- 22128.176\n",
      " 0 18700 of 36184 \t L: 3.176 \t -- 22247.944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 18800 of 36184 \t L: 3.163 \t -- 22366.891\n",
      " 0 18900 of 36184 \t L: 3.187 \t -- 22485.498\n",
      " 0 19000 of 36184 \t L: 3.160 \t -- 22603.714\n",
      " 0 19100 of 36184 \t L: 3.169 \t -- 22722.886\n",
      " 0 19200 of 36184 \t L: 3.150 \t -- 22841.640\n",
      " 0 19300 of 36184 \t L: 3.170 \t -- 22959.092\n",
      " 0 19400 of 36184 \t L: 3.193 \t -- 23079.103\n",
      " 0 19500 of 36184 \t L: 3.170 \t -- 23197.797\n",
      " 0 19600 of 36184 \t L: 3.154 \t -- 23316.055\n",
      " 0 19700 of 36184 \t L: 3.154 \t -- 23434.163\n",
      " 0 19800 of 36184 \t L: 3.152 \t -- 23553.321\n",
      " 0 19900 of 36184 \t L: 3.159 \t -- 23671.085\n",
      " 0 20000 of 36184 \t L: 3.140 \t -- 23789.325\n",
      " 0 20100 of 36184 \t L: 3.161 \t -- 23907.872\n",
      " 0 20200 of 36184 \t L: 3.138 \t -- 24026.420\n",
      " 0 20300 of 36184 \t L: 3.161 \t -- 24144.614\n",
      " 0 20400 of 36184 \t L: 3.163 \t -- 24262.813\n",
      " 0 20500 of 36184 \t L: 3.170 \t -- 24382.525\n",
      " 0 20600 of 36184 \t L: 3.158 \t -- 24500.881\n"
     ]
    }
   ],
   "source": [
    "s2s_optimizer = AdamW(qa_s2s_model.parameters(), lr=s2s_args.learning_rate, eps=1e-8)\n",
    "s2s_scheduler = get_linear_schedule_with_warmup(\n",
    "        s2s_optimizer,\n",
    "        num_warmup_steps=400,\n",
    "        num_training_steps=s2s_args.num_epochs * math.ceil(len(s2s_train_dset) / s2s_args.batch_size)\n",
    ")\n",
    "\n",
    "for e in range(s2s_args.num_epochs):\n",
    "    train_qa_s2s_epoch(\n",
    "        qa_s2s_model,\n",
    "        s2s_train_dset, qa_s2s_tokenizer,\n",
    "        s2s_optimizer, s2s_scheduler,\n",
    "        s2s_args, e,\n",
    "        curriculum=(e == 0),\n",
    "    )\n",
    "    m_save_dict = {\n",
    "        'model': qa_s2s_model.state_dict(),\n",
    "        'optimizer': s2s_optimizer.state_dict(),\n",
    "        'scheduler': s2s_scheduler.state_dict(),\n",
    "    }\n",
    "    print(\"Saving model {}\".format(s2s_args.model_save_name))\n",
    "    torch.save(m_save_dict, '{}_{}.pth'.format(s2s_args.model_save_name, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2s_optimizer = AdamW(qa_s2s_model.parameters(), lr=s2s_args.learning_rate, eps=1e-8)\n",
    "s2s_scheduler = get_linear_schedule_with_warmup(\n",
    "        s2s_optimizer,\n",
    "        num_warmup_steps=400,\n",
    "        num_training_steps=s2s_args.num_epochs * math.ceil(len(s2s_train_dset) / s2s_args.batch_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yacine/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0     0 of 36184 \t L: 4.835 \t -- 29.596\n",
      " 0     1 of 36184 \t L: 4.687 \t -- 31.556\n",
      " 0   100 of 36184 \t L: 4.478 \t -- 150.420\n",
      " 0   200 of 36184 \t L: 3.755 \t -- 269.327\n",
      " 0   300 of 36184 \t L: 3.469 \t -- 387.855\n",
      " 0   400 of 36184 \t L: 3.360 \t -- 505.592\n",
      " 0   500 of 36184 \t L: 3.311 \t -- 624.245\n",
      " 0   600 of 36184 \t L: 3.274 \t -- 741.951\n",
      " 0   700 of 36184 \t L: 3.242 \t -- 860.024\n",
      " 0   800 of 36184 \t L: 3.231 \t -- 977.969\n",
      " 0   900 of 36184 \t L: 3.214 \t -- 1096.494\n",
      " 0  1000 of 36184 \t L: 3.230 \t -- 1214.687\n",
      " 0  1100 of 36184 \t L: 3.227 \t -- 1332.183\n",
      " 0  1200 of 36184 \t L: 3.186 \t -- 1450.259\n",
      " 0  1300 of 36184 \t L: 3.206 \t -- 1568.458\n",
      " 0  1400 of 36184 \t L: 3.209 \t -- 1686.349\n",
      " 0  1500 of 36184 \t L: 3.184 \t -- 1804.035\n",
      " 0  1600 of 36184 \t L: 3.204 \t -- 1922.431\n",
      " 0  1700 of 36184 \t L: 3.190 \t -- 2040.502\n",
      " 0  1800 of 36184 \t L: 3.174 \t -- 2158.630\n",
      " 0  1900 of 36184 \t L: 3.181 \t -- 2276.222\n",
      " 0  2000 of 36184 \t L: 3.187 \t -- 2393.720\n",
      " 0  2100 of 36184 \t L: 3.192 \t -- 2511.511\n",
      " 0  2200 of 36184 \t L: 3.200 \t -- 2629.640\n",
      " 0  2300 of 36184 \t L: 3.221 \t -- 2747.249\n",
      " 0  2400 of 36184 \t L: 3.221 \t -- 2864.976\n",
      " 0  2500 of 36184 \t L: 3.197 \t -- 2982.432\n",
      " 0  2600 of 36184 \t L: 3.182 \t -- 3100.747\n",
      " 0  2700 of 36184 \t L: 3.196 \t -- 3218.734\n",
      " 0  2800 of 36184 \t L: 3.222 \t -- 3335.701\n",
      " 0  2900 of 36184 \t L: 3.221 \t -- 3453.762\n",
      " 0  3000 of 36184 \t L: 3.243 \t -- 3571.395\n",
      " 0  3100 of 36184 \t L: 3.205 \t -- 3690.055\n",
      " 0  3200 of 36184 \t L: 3.211 \t -- 3807.780\n",
      " 0  3300 of 36184 \t L: 3.229 \t -- 3924.843\n",
      " 0  3400 of 36184 \t L: 3.209 \t -- 4042.701\n",
      " 0  3500 of 36184 \t L: 3.208 \t -- 4160.961\n",
      " 0  3600 of 36184 \t L: 3.217 \t -- 4278.657\n",
      " 0  3700 of 36184 \t L: 3.228 \t -- 4396.737\n",
      " 0  3800 of 36184 \t L: 3.227 \t -- 4513.915\n",
      " 0  3900 of 36184 \t L: 3.198 \t -- 4632.379\n",
      " 0  4000 of 36184 \t L: 3.199 \t -- 4750.382\n",
      " 0  4100 of 36184 \t L: 3.214 \t -- 4867.639\n",
      " 0  4200 of 36184 \t L: 3.215 \t -- 4984.908\n",
      " 0  4300 of 36184 \t L: 3.207 \t -- 5102.258\n",
      " 0  4400 of 36184 \t L: 3.226 \t -- 5220.051\n",
      " 0  4500 of 36184 \t L: 3.239 \t -- 5337.905\n",
      " 0  4600 of 36184 \t L: 3.193 \t -- 5455.712\n",
      " 0  4700 of 36184 \t L: 3.203 \t -- 5573.452\n",
      " 0  4800 of 36184 \t L: 3.204 \t -- 5690.157\n",
      " 0  4900 of 36184 \t L: 3.208 \t -- 5808.033\n",
      " 0  5000 of 36184 \t L: 3.207 \t -- 5926.227\n",
      " 0  5100 of 36184 \t L: 3.215 \t -- 6043.828\n",
      " 0  5200 of 36184 \t L: 3.203 \t -- 6160.895\n",
      " 0  5300 of 36184 \t L: 3.206 \t -- 6279.023\n",
      " 0  5400 of 36184 \t L: 3.211 \t -- 6396.484\n",
      " 0  5500 of 36184 \t L: 3.213 \t -- 6514.170\n",
      " 0  5600 of 36184 \t L: 3.200 \t -- 6631.168\n",
      " 0  5700 of 36184 \t L: 3.188 \t -- 6748.736\n",
      " 0  5800 of 36184 \t L: 3.195 \t -- 6866.302\n",
      " 0  5900 of 36184 \t L: 3.183 \t -- 6983.424\n",
      " 0  6000 of 36184 \t L: 3.200 \t -- 7102.387\n",
      " 0  6100 of 36184 \t L: 3.221 \t -- 7219.622\n",
      " 0  6200 of 36184 \t L: 3.197 \t -- 7337.168\n",
      " 0  6300 of 36184 \t L: 3.199 \t -- 7454.424\n",
      " 0  6400 of 36184 \t L: 3.201 \t -- 7571.341\n",
      " 0  6500 of 36184 \t L: 3.204 \t -- 7688.180\n",
      " 0  6600 of 36184 \t L: 3.196 \t -- 7806.484\n",
      " 0  6700 of 36184 \t L: 3.174 \t -- 7923.844\n",
      " 0  6800 of 36184 \t L: 3.196 \t -- 8041.343\n",
      " 0  6900 of 36184 \t L: 3.199 \t -- 8158.367\n",
      " 0  7000 of 36184 \t L: 3.169 \t -- 8275.210\n",
      " 0  7100 of 36184 \t L: 3.178 \t -- 8392.468\n",
      " 0  7200 of 36184 \t L: 3.185 \t -- 8509.654\n",
      " 0  7300 of 36184 \t L: 3.180 \t -- 8627.455\n",
      " 0  7400 of 36184 \t L: 3.183 \t -- 8744.929\n",
      " 0  7500 of 36184 \t L: 3.170 \t -- 8862.546\n",
      " 0  7600 of 36184 \t L: 3.193 \t -- 8980.655\n",
      " 0  7700 of 36184 \t L: 3.175 \t -- 9097.920\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-67b2fbd90830>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0ms2s_train_dset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqa_s2s_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0ms2s_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2s_scheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0ms2s_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     )\n\u001b[1;32m      8\u001b[0m     m_save_dict = {\n",
      "\u001b[0;32m~/Code/transformers/examples/eli5/eli5_utils.py\u001b[0m in \u001b[0;36mtrain_qa_s2s_epoch\u001b[0;34m(model, dataset, tokenizer, optimizer, scheduler, args, e)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0mst_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_inputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mpre_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpre_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mpre_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(s2s_args.num_epochs):\n",
    "    train_qa_s2s_epoch(\n",
    "        qa_s2s_model,\n",
    "        s2s_train_dset, qa_s2s_tokenizer,\n",
    "        s2s_optimizer, s2s_scheduler,\n",
    "        s2s_args, e,\n",
    "        curriculum=(e == 0),\n",
    "    )\n",
    "    m_save_dict = {\n",
    "        'model': qa_s2s_model.state_dict(),\n",
    "        'optimizer': s2s_optimizer.state_dict(),\n",
    "        'scheduler': s2s_scheduler.state_dict(),\n",
    "    }\n",
    "    print(\"Saving model {}\".format(s2s_args.model_save_name))\n",
    "    torch.save(m_save_dict, '{}_{}.pth'.format(s2s_args.model_save_name, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 of  2453 \t L: 3.521 \t -- 0.315\n",
      " 1000 of  2453 \t L: 3.260 \t -- 319.746\n",
      " 2000 of  2453 \t L: 3.264 \t -- 638.111\n",
      "Total \t L: 3.265 \t -- 782.534\n"
     ]
    }
   ],
   "source": [
    "_ = qa_s2s_model.eval()\n",
    "s2s_args.print_freq = 100\n",
    "eval_qa_s2s_epoch(\n",
    "        qa_s2s_model,\n",
    "        s2s_valid_dset, qa_s2s_tokenizer,\n",
    "        s2s_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q_id': '20q8w1',\n",
       " 'title': 'How do apps like soundhound and shazam know what song is playing?',\n",
       " 'selftext': '',\n",
       " 'document': '',\n",
       " 'subreddit': 'explainlikeimfive',\n",
       " 'answers': {'a_id': ['cg5r130'],\n",
       "  'text': ['ELI5:\\n\\nThink about when you hear your parents, you can recognize their voice right? Or when you see a dog, you can recognize it\\'s a dog in general. Now what kind of dog? You can typically recognize it\\'s a chihuahua or, my fav, a golden retriever. How? Chihuahuas are small and annoying with short hair, whereas a golden retriever is cute, cuddly, friendly, with long hair (I may have some bias here).\\n\\nIn the same way, Shazam and Soundhound does that! They take a look at features of a song, like the pitch, tone, or waveform (the \"shape\" of the song) and try to match it to a song in their memory.'],\n",
       "  'score': [2]},\n",
       " 'title_urls': {'url': []},\n",
       " 'selftext_urls': {'url': []},\n",
       " 'answers_urls': {'url': []}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5['validation_eli5'][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They don't know what song is playing, they just know that it's playing.\n",
      "\n",
      "Shazam, for example, has an app called \"shazam\" that has a list of songs that can be played at any time of the day.  Shazam then uses that list to determine which songs are being played at that time.\n"
     ]
    }
   ],
   "source": [
    "print(qa_s2s_generate(\n",
    "        s2s_valid_dset[11][0], qa_s2s_model.module, qa_s2s_tokenizer,\n",
    "        num_answers=1,\n",
    "        num_beams=8,\n",
    "        min_len=64,\n",
    "        max_len=256,\n",
    "        max_input_length=1024,\n",
    "        device=\"cuda:0\"\n",
    "    )[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = []\n",
    "st_time = time()\n",
    "for i in range(2000):\n",
    "    generated += [qa_s2s_generate(\n",
    "        s2s_valid_dset[i][0], qa_s2s_model.module, qa_s2s_tokenizer,\n",
    "        num_answers=1,\n",
    "        num_beams=8,\n",
    "        min_len=64,\n",
    "        max_len=256,\n",
    "        max_input_length=1024,\n",
    "        device=\"cuda:0\"\n",
    "    )[0]]\n",
    "    if i % 100 == 0:\n",
    "        print(eli5['validation_eli5'].num_rows, i, time() - st_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qda_difficulty(question_doc, answer):\n",
    "    qd_words = dict([(w, True) for w in question_doc.lower().split()])\n",
    "    recall = len([w for w in answer.lower().split() if w in qd_words]) / len(answer.split())\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_diff = [(i, qda_difficulty(*s2s_train_dset[i])) for i in range(len(s2s_train_dset))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4885, 1.0),\n",
       " (4112, 0.9523809523809523),\n",
       " (8829, 0.9090909090909091),\n",
       " (9692, 0.9090909090909091),\n",
       " (3443, 0.9032258064516129),\n",
       " (2563, 0.9),\n",
       " (4930, 0.9),\n",
       " (6940, 0.9),\n",
       " (9267, 0.8928571428571429),\n",
       " (7644, 0.8888888888888888)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(recall_diff, key=lambda x:x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELI5DatasetS2S(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 examples_array,\n",
    "                 make_doc_fun=None,\n",
    "                 extra_answer_threshold=3,\n",
    "                 document_cache=None,\n",
    "                 training=True):\n",
    "        self.training = training\n",
    "        self.data = examples_array\n",
    "        self.make_doc_function = make_doc_fun\n",
    "        self.document_cache = {} if document_cache is None else document_cache\n",
    "        assert not (make_doc_fun is None and document_cache is None)\n",
    "        # make index of specific question-answer pairs from multi-answers\n",
    "        if self.training:\n",
    "            self.qa_id_list = [(i, j)\n",
    "                               for i, qa in enumerate(self.data) \n",
    "                               for j, (a, sc) in enumerate(zip(qa['answers']['text'], qa['answers']['score']))\n",
    "                               if j == 0 or sc >= extra_answer_threshold]\n",
    "        else:\n",
    "            self.qa_id_list = [(i, 0) for i in range(self.data.num_rows)] \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.qa_id_list)\n",
    "\n",
    "    def make_example(self, idx):\n",
    "        i, j = self.qa_id_list[idx]\n",
    "        example = self.data[i]\n",
    "        question = example['title'] + ' ' + example['selftext']\n",
    "        answer = example['answers']['text'][j]\n",
    "        q_id = example['q_id']\n",
    "        if self.make_doc_function is not None:\n",
    "            self.document_cache[q_id] = self.document_cache.get(q_id, self.make_doc_function(example['title']))\n",
    "        document = self.document_cache[q_id]\n",
    "        in_st = \"question: {} context: {}\".format(\n",
    "            question.lower().replace(' --t--', '').strip(),\n",
    "            document.lower().strip(),\n",
    "        )\n",
    "        out_st = answer\n",
    "        return (in_st, out_st)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.make_example(idx)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
