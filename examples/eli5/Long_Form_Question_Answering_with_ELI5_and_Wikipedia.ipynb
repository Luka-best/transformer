{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Form Question Answering with ELI5 and Wikipedia  \n",
    "\n",
    "---  \n",
    "\n",
    "### Table of Contents  \n",
    "\n",
    "1. [Introduction](#intro)  \n",
    "    a. [Preliminaries](#prelims)\n",
    "2. [Task and Data Description](#task_description)  \n",
    "    a. [Note on Data and Biases](#reddit_biases)\n",
    "3. [Retrieving Support Documents](#retrieval)  \n",
    "    a. [Sparse Retrieval with ElasticSearch](#elasticsearch)  \n",
    "    b. [Training a Dense Retriever with ELI5 and in-batch Negatives](#dense_train)  \n",
    "    c. [Using a Trained Dense Retriever](#dense_use)  \n",
    "    d. [Retriever Evaluation](#dense_eval)  \n",
    "4. [Answer Generation Model](#generation)  \n",
    "    a. [Conditional Generation with Seq2seq Models](#seq2seq_presentation)  \n",
    "    b. [Fine-Tuning Seq2seq Models](#seq2seq_train)  \n",
    "5. [Conclusion](#conclusion)  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"images/choco_bis.svg\" width=\"900\" align=\"center\"/>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "<a id='intro'></a>\n",
    "\n",
    "Imagine that you are taken with a sudden desire to understand **how the fruit of a tropical tree gets transformed into chocolate bars**, or want to understand **the role of fever in the human body's immune response**: how would you go about finding that information?\n",
    "\n",
    "If your specific question has already been asked and answered clearly and succintly on one of the many question answering platforms available on the Internet (such as [**Quora**](https://www.quora.com/How-is-chocolate-made), [**Reddit**](https://www.reddit.com/user/ex_5_libris/comments/9c8gb1/chocolate_how_chocolate_is_made/), or [**Yahoo Answers**](https://answers.yahoo.com/question/index?qid=20070615082202AArsYN1)), you're in luck: modern search engines will probably take you to that pre-existing answer pretty reliably in a matter of a few clicks.  \n",
    "\n",
    "Otherwise, the process will be a little more involved. You will likely have to collect relevant information from a variety of sources, figure out how these pieces of knowledge fit together in relation to your query, and synthetize a narrative that answers your initial question.\n",
    "\n",
    "Now, wouldn't it be great if your computer could do all of that for you: **gather** the right sources, **synthetize** the information, and **write up** an easy-to-read summary of the relevant points? Such a system isn't quite available yet, at least not one that can provide *reliable* information in its summary. However, a number of recent advances in natural language understanding and generation have made working toward solving this problem much easier! These advances include progress in the pre-training (e.g. [BART](https://arxiv.org/abs/1910.13461), [T5](https://arxiv.org/abs/1910.10683)) and evaluation (e.g. for [factuality](https://arxiv.org/abs/2004.04228)) of sequence-to-sequence models for conditional text generation, new ways to use language understanding models to find information in Wikipedia (e.g. [REALM](https://kentonl.com/pub/gltpc.2020.pdf), [DPR](https://arxiv.org/abs/2004.04906)), and new [training datasets](https://arxiv.org/abs/1907.09190).\n",
    "\n",
    "**In this notebook,** we show how we can take advantage of some of these recent works to train a **long form question answering** system which takes in a question, fetches 10 relevant passages from a [Wikipedia snapshot](https://www.aclweb.org/anthology/2020.lrec-1.297/), and writes a multi-sentence answer based on the question and retrieved passages. Follow along to learn about the steps involved and read some background on the state of the art for some related tasks, or go straight to the:  \n",
    "## [**Live Demo!**](http://35.226.96.115:8080/)  \n",
    "(And don't forget to scroll down on the left sidebar to show all of the generation options!)\n",
    "\n",
    "### Preliminaries  \n",
    "<a id='prelims'></a>\n",
    "\n",
    "The implementation presented here relies on the [HuggingFace](https://huggingface.co/) [ðŸ¤—transformers](https://github.com/huggingface/transformers) and [ðŸ¤—nlp](https://github.com/huggingface/nlp) libraries. Wikipedia indexing relies on [ElasticSearch](https://www.elastic.co/elasticsearch) with its [python bindings](https://github.com/elastic/elasticsearch-py) for the sparse version, and [faiss](https://github.com/facebookresearch/faiss/) for the dense version. You can get all of these by running:\n",
    "> pip install elasticsearch  \n",
    "> pip install faiss_gpu  \n",
    "> pip install nlp  \n",
    "> pip install transformers  \n",
    ">  \n",
    "> wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.7.1-linux-x86_64.tar.gz  \n",
    "> tar -xzvf elasticsearch-7.7.1-linux-x86_64.tar.gz  \n",
    "\n",
    "The training relies on two datasets: [ELI5](https://arxiv.org/abs/1907.09190), a processed version of the [r/explainlikeimfive](https://www.reddit.com/r/explainlikeimfive/) subreddit, and the [Wiki40b](https://www.aclweb.org/anthology/2020.lrec-1.297/) Wikipedia image.\n",
    "\n",
    "Downloading ELI5 can take up to 72 hours since we need to to filter through all of the Reddit dumps for 8 years, so we suggest that you do that first (you will need a good download speed and about 10GB of disk space):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlp\n",
    "eli5 = nlp.load_dataset('explainlikeimfive', name='LFQA_reddit', experimental=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is meant to be run from the `transformers/examples/eli5` folder in the [ðŸ¤—transformers](https://github.com/huggingface/transformers), as all of the useful methods called here are compiled in the [eli5_utils.py](https://github.com/yjernite/transformers/blob/eli5_examples/examples/eli5/eli5_utils.py) script located there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eli5_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task and Data Description\n",
    "<a id='task_description'></a>\n",
    "\n",
    "Let's recap: we are interested in the task of Long Form Question Answering. As in other Question Answering tasks, the model is presented with a question, and is required to generate a natural language answer. Whereas a majority of QA datasets contain mostly **factoid** questions, where the answer, such as a date or the name of a single entity, can be expressed in a few words or single sentence, Long Form QA focuses on questions which call for an **explanation** consisting of a few sentences or a few paragraphs.\n",
    "\n",
    "In order to teach a model to answer such questions, we use questions and answers written by Reddit users. Note that the `nlp.load_dataset` command above actually downloaded questions and their associated answers from the [r/explainlikeimfive](https://www.reddit.com/r/explainlikeimfive/), [r/askscience](https://www.reddit.com/r/askscience/), and [r/AskHistorians](https://www.reddit.com/r/AskHistorians/) subreddits. We focus here on the **ELI5/explainlikeimfive** part to train the system, as the examples there tend to be a little simpler.  \n",
    "\n",
    "Let's look at one item from the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q_id': '8houtx',\n",
       " 'title': 'Why does water heated to room temperature feel colder than the air around it?',\n",
       " 'selftext': '',\n",
       " 'document': '',\n",
       " 'subreddit': 'explainlikeimfive',\n",
       " 'answers': {'a_id': ['dylcnfk', 'dylcj49'],\n",
       "  'text': [\"Water transfers heat more efficiently than air. When something feels cold it's because heat is being transferred from your skin to whatever you're touching. Since water absorbs the heat more readily than air, it feels colder.\",\n",
       "   \"Air isn't as good at transferring heat compared to something like water or steel (sit on a room temperature steel bench vs. a room temperature wooden bench, and the steel one will feel more cold).\\n\\nWhen you feel cold, what you're feeling is heat being transferred out of you.  If there is no breeze, you feel a certain way.  If there's a breeze, you will get colder faster (because the moving air is pulling the heat away from you), and if you get into water, its quite good at pulling heat from you.   Get out of the water and have a breeze blow on you while you're wet, all of the water starts evaporating, pulling even more heat from you.\"],\n",
       "  'score': [5, 2]},\n",
       " 'title_urls': {'url': []},\n",
       " 'selftext_urls': {'url': []},\n",
       " 'answers_urls': {'url': []}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5['test_eli5'][12345]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to answer, we want info from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki40b_snippets = nlp.load_dataset('wiki_snippets', name='wiki40b_en_100_0', experimental=True)['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on Data and Biases\n",
    "<a id='reddit_biases'></a>\n",
    "\n",
    "PRoblems with reddit, hopefullu eli5/askscience is a bit better, still have much to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Support Documents\n",
    "<a id='retrieval'></a>\n",
    "\n",
    "The first question is...\n",
    "\n",
    "### Sparse Retrieval with ElasticSearch\n",
    "<a id='elasticsearch'></a>\n",
    "\n",
    "The traditional approach until...  \n",
    "\n",
    "First, let's create a dense index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Elasticsearch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-282c8211d7e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mes_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElasticsearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'host'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'localhost'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'9200'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mes_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wiki40b_snippets_100w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmake_es_index_snippets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mes_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwiki40b_snippets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'wiki40b_snippets_100w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Elasticsearch' is not defined"
     ]
    }
   ],
   "source": [
    "es_client = Elasticsearch([{'host': 'localhost', 'port': '9200'}])\n",
    "if not es_client.indices.exists('wiki40b_snippets_100w'):\n",
    "    make_es_index_snippets(es_client, wiki40b_snippets, index_name='wiki40b_snippets_100w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test for one of the ELI5 questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why does water heated to room temperature feel colder than the air around it?\n",
      "-----\n",
      "\n",
      "Salt fingering: \n",
      "  Salt fingering\n",
      "\n",
      "Solar water heating: \n",
      "  Flat plate & Evacuated tube\n",
      "\n",
      "Humidifier: \n",
      "  Fixed-installation humidifiers & Problems\n",
      "\n",
      "Drake Landing Solar Community: \n",
      "  How it works & Energy centre\n",
      "\n",
      "Diamond dust: \n",
      "  Characteristics & Formation\n",
      "\n",
      "Effects of global warming on oceans: \n",
      "  Ocean currents\n",
      "\n",
      "Mesoscale convective system: \n",
      "  Lake-effect snow\n",
      "\n",
      "Thermal comfort: \n",
      "  Interplay of temperature and humidity\n",
      "\n",
      "Honyaki: \n",
      "  Traditional process\n",
      "\n",
      "Greywell Tunnel: \n",
      "  SSSI\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = eli5['test_eli5'][12345]['title']\n",
    "doc, res_list = query_es_index(question, es_client, index_name='wiki40b_snippets_100w', n_results=10)\n",
    "\n",
    "print(question)\n",
    "print('-----\\n')\n",
    "for res in res_list:\n",
    "    print(\"{}: \\n  {}\\n\".format(\n",
    "        res['article_title'],\n",
    "        res['section_title'] if res['section_title'].strip() != '' else res['article_title']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Dense Retriever with ELI5 and in-batch Negatives\n",
    "<a id='dense_train'></a>\n",
    "\n",
    "Can we take advantage of our data to do better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "qar_tokenizer, qar_model = make_qa_retriever_model(\n",
    "    model_name=\"google/bert_uncased_L-8_H-768_A-12\",\n",
    "    from_file=None,\n",
    "    device=\"cuda:0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Trained Dense Retriever\n",
    "<a id='dense_use'></a>\n",
    "\n",
    "Can we take advantage of our data to do better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qar_tokenizer, qar_model = make_qa_retriever_model(\n",
    "    model_name=\"google/bert_uncased_L-8_H-768_A-12\",\n",
    "    from_file=\"retriever_models/eli5_retriever_model_l-8_h-768_b-512-512_9.pth\",\n",
    "    device=\"cuda:0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_res = faiss.StandardGpuResources()\n",
    "wiki40b_passage_reps = np.memmap(\n",
    "            'wiki40b_passages_reps_32_l-8_h-768_b-512-512.dat',\n",
    "            dtype='float32', mode='r',\n",
    "            shape=(wiki40b_snippets.num_rows, 128)\n",
    ")\n",
    "\n",
    "wiki40b_index_flat = faiss.IndexFlatIP(128)\n",
    "wiki40b_gpu_index = faiss.index_cpu_to_gpu(faiss_res, 1, wiki40b_index_flat)\n",
    "wiki40b_gpu_index.add(wiki40b_passage_reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why does water heated to room temperature feel colder than the air around it?\n",
      "-----\n",
      "\n",
      "Fugacity: \n",
      "  History\n",
      "\n",
      "Heat transfer: \n",
      "  Heat transfer in the human body & Evaporative cooling\n",
      "\n",
      "Johan SandstrÃ¶m: \n",
      "  SandstrÃ¶m  Theorem\n",
      "\n",
      "Thermal equilibrium: \n",
      "  Bodies prepared with separately uniform temperatures, then put into purely thermal communication with each other\n",
      "\n",
      "Evaporative cooler: \n",
      "  Physical principles\n",
      "\n",
      "Thermal contact conductance: \n",
      "  Factors influencing contact conductance & Contact pressure\n",
      "\n",
      "Thermodynamic temperature: \n",
      "  The heat of phase changes\n",
      "\n",
      "Temperature: \n",
      "  Local thermodynamic equilibrium & Bodies in thermodynamic equilibrium\n",
      "\n",
      "Tail flick test: \n",
      "  Limitations\n",
      "\n",
      "Latent heat: \n",
      "  Usage\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = eli5['test_eli5'][12345]['title']\n",
    "doc, res_list = query_qa_dense_index(\n",
    "    question,\n",
    "    qar_model, qar_tokenizer,\n",
    "    wiki40b_snippets, wiki40b_gpu_index,\n",
    "    n_results=10\n",
    ")\n",
    "\n",
    "print(question)\n",
    "print('-----\\n')\n",
    "for res in res_list:\n",
    "    print(\"{}: \\n  {}\\n\".format(\n",
    "        res['article_title'],\n",
    "        res['section_title'] if res['section_title'].strip() != '' else res['article_title']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever Evaluation\n",
    "<a id='dense_eval'></a>\n",
    "\n",
    "How can we evaluate the embedding model? Let's start by grabbing a couple of useful metrics from the `nlp` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "010 Sparse: RG-0.2652 BS-0.8053 | Dense: RG-0.2521 BS-0.8141 \t 103.34\n",
      "020 Sparse: RG-0.2657 BS-0.8068 | Dense: RG-0.2647 BS-0.8193 \t 174.52\n",
      "030 Sparse: RG-0.2631 BS-0.8052 | Dense: RG-0.2591 BS-0.8156 \t 261.19\n",
      "040 Sparse: RG-0.2623 BS-0.8049 | Dense: RG-0.2594 BS-0.8149 \t 352.42\n",
      "050 Sparse: RG-0.2660 BS-0.8060 | Dense: RG-0.2639 BS-0.8176 \t 457.43\n",
      "060 Sparse: RG-0.2698 BS-0.8053 | Dense: RG-0.2649 BS-0.8172 \t 540.86\n",
      "070 Sparse: RG-0.2684 BS-0.8058 | Dense: RG-0.2630 BS-0.8187 \t 602.46\n",
      "080 Sparse: RG-0.2671 BS-0.8062 | Dense: RG-0.2640 BS-0.8185 \t 694.04\n",
      "090 Sparse: RG-0.2646 BS-0.8063 | Dense: RG-0.2622 BS-0.8182 \t 763.54\n",
      "100 Sparse: RG-0.2627 BS-0.8058 | Dense: RG-0.2619 BS-0.8190 \t 822.09\n",
      "110 Sparse: RG-0.2646 BS-0.8056 | Dense: RG-0.2626 BS-0.8186 \t 900.97\n",
      "120 Sparse: RG-0.2673 BS-0.8055 | Dense: RG-0.2661 BS-0.8177 \t 1013.28\n",
      "130 Sparse: RG-0.2685 BS-0.8053 | Dense: RG-0.2678 BS-0.8175 \t 1080.84\n",
      "140 Sparse: RG-0.2660 BS-0.8050 | Dense: RG-0.2654 BS-0.8180 \t 1380.19\n",
      "150 Sparse: RG-0.2646 BS-0.8049 | Dense: RG-0.2639 BS-0.8172 \t 1466.71\n",
      "160 Sparse: RG-0.2639 BS-0.8051 | Dense: RG-0.2648 BS-0.8178 \t 1607.58\n",
      "170 Sparse: RG-0.2612 BS-0.8053 | Dense: RG-0.2618 BS-0.8174 \t 1677.37\n",
      "180 Sparse: RG-0.2616 BS-0.8056 | Dense: RG-0.2627 BS-0.8168 \t 1779.52\n",
      "190 Sparse: RG-0.2614 BS-0.8055 | Dense: RG-0.2626 BS-0.8166 \t 1850.76\n",
      "200 Sparse: RG-0.2610 BS-0.8056 | Dense: RG-0.2641 BS-0.8177 \t 1971.58\n",
      "210 Sparse: RG-0.2620 BS-0.8057 | Dense: RG-0.2649 BS-0.8175 \t 2082.52\n",
      "220 Sparse: RG-0.2620 BS-0.8058 | Dense: RG-0.2638 BS-0.8169 \t 2129.78\n",
      "230 Sparse: RG-0.2626 BS-0.8060 | Dense: RG-0.2639 BS-0.8168 \t 2187.62\n",
      "240 Sparse: RG-0.2625 BS-0.8063 | Dense: RG-0.2638 BS-0.8169 \t 2264.72\n",
      "250 Sparse: RG-0.2628 BS-0.8066 | Dense: RG-0.2634 BS-0.8167 \t 2366.96\n",
      "260 Sparse: RG-0.2632 BS-0.8064 | Dense: RG-0.2633 BS-0.8166 \t 2441.70\n",
      "270 Sparse: RG-0.2635 BS-0.8063 | Dense: RG-0.2635 BS-0.8164 \t 2536.18\n",
      "280 Sparse: RG-0.2648 BS-0.8064 | Dense: RG-0.2641 BS-0.8172 \t 2623.53\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-63b330ce8393>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mes_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'wiki40b_snippets_100w'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mn_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     )\n\u001b[1;32m     48\u001b[0m     \u001b[0msparse_passages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'passage_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msparse_res_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/transformers/examples/eli5/eli5_utils.py\u001b[0m in \u001b[0;36mquery_es_index\u001b[0;34m(question, es_client, index_name, n_results)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 }\n\u001b[1;32m     80\u001b[0m             },\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;34m\"size\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mn_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         }\n\u001b[1;32m     83\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/elasticsearch/client/utils.py\u001b[0m in \u001b[0;36m_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/elasticsearch/client/__init__.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, body, index, doc_type, params, headers)\u001b[0m\n\u001b[1;32m   1621\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m             \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1624\u001b[0m         )\n\u001b[1;32m   1625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/elasticsearch/transport.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    360\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                     \u001b[0mignore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m                 )\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/elasticsearch/connection/http_urllib3.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             response = self.pool.urlopen(\n\u001b[0;32m--> 229\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRetry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_headers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m             )\n\u001b[1;32m    231\u001b[0m             \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    670\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m             )\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    419\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    414\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1342\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "# load the ROUGE and BERTscore metrics from the nlp library\n",
    "nlp_rouge = nlp.load_metric('rouge')\n",
    "nlp_bertscore = nlp.load_metric('bertscore')\n",
    "\n",
    "# takes a list of retrieved documents and a list of possible answers\n",
    "# for a question and returns a measure of the lexical overlap between the\n",
    "# passages and answer\n",
    "def get_aggregate_rouge(res_list, answers):\n",
    "    res = np.zeros((len(res_list), len(answers), 3))\n",
    "    for i, hit in enumerate(res_list):\n",
    "        for j, a in enumerate(answers):\n",
    "            if len(hit.strip()) > 0 and len(a.strip()) > 0:\n",
    "                # get Rouge-1 P/R/F for each passage/answer pair\n",
    "                score = nlp_rouge.compute([hit], [a], rouge_types=['rouge1'])['rouge1'].mid\n",
    "                res[i,j] = np.array([score.precision, score.recall, score.fmeasure])\n",
    "    # average P/R/F rouge scores, then find best passage-answer match\n",
    "    return res.mean(axis=2).max()\n",
    "\n",
    "# Same with BERTscore metri which aligns contextual word embedings\n",
    "def get_aggregate_bertscore(res_list, answers):\n",
    "    res = np.zeros((len(res_list), len(answers), 3))\n",
    "    for i, hit in enumerate(res_list):\n",
    "        for j, a in enumerate(answers):\n",
    "            if len(hit.strip()) > 0 and len(a.strip()) > 0:\n",
    "                # get Rouge-1 P/R/F for each passage/answer pair\n",
    "                score = nlp_bertscore.compute([hit], [a], lang='en')\n",
    "                res[i,j] = np.array([score['precision'].item(), score['recall'].item(), score['f1'].item()])\n",
    "    # average P/R/F rouge scores, then find best passage-answer match\n",
    "    return res.mean(axis=2).max()\n",
    "\n",
    "# Compare which retriever finds passages that have the most\n",
    "# lexical overlap with the ELI5 answers\n",
    "st_time = time()\n",
    "tot_rg_sparse = 0.\n",
    "tot_bs_sparse = 0.\n",
    "tot_rg_dense = 0.\n",
    "tot_bs_dense = 0.\n",
    "valid_slice = eli5['validation_eli5'][:1000]\n",
    "for i, (question, answers) in enumerate(zip(valid_slice['title'], valid_slice['answers'])):\n",
    "    # get documents with sparse retriever\n",
    "    _, sparse_res_list = query_es_index(\n",
    "        question,\n",
    "        es_client, index_name='wiki40b_snippets_100w',\n",
    "        n_results=5\n",
    "    )\n",
    "    sparse_passages = [res['passage_text'] for res in sparse_res_list]\n",
    "    if len(sparse_passages) == 0:\n",
    "        sparse_passages = [question]\n",
    "    tot_rg_sparse += get_aggregate_rouge(sparse_passages, answers['text'])\n",
    "    tot_bs_sparse += get_aggregate_bertscore(sparse_passages, answers['text'])\n",
    "    # get documents with dense retriever\n",
    "    _, dense_res_list = query_qa_dense_index(\n",
    "        question,\n",
    "        qar_model, qar_tokenizer,\n",
    "        wiki40b_snippets, wiki40b_gpu_index,\n",
    "        n_results=5\n",
    "    )\n",
    "    dense_passages = [res['passage_text'] for res in dense_res_list]\n",
    "    tot_rg_dense += get_aggregate_rouge(dense_passages, answers['text'])\n",
    "    tot_bs_dense += get_aggregate_bertscore(dense_passages, answers['text'])\n",
    "    # show average scores side by side\n",
    "    if (i+1) % 10 == 0:\n",
    "        print(\"{:03d} Sparse: RG-{:.4f} BS-{:.4f} | Dense: RG-{:.4f} BS-{:.4f} \\t {:.2f}\".format(\n",
    "            i+1,\n",
    "            tot_rg_sparse / (i+1), tot_bs_sparse / (i+1),\n",
    "            tot_rg_dense / (i+1), tot_bs_dense / (i+1),\n",
    "            time() - st_time\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 Sparse: RG-0.2609 BS-0.8014 | Dense: RG-0.2634 BS-0.8135 \t 1923.04\n"
     ]
    }
   ],
   "source": [
    "print(\"{:03d} Sparse: RG-{:.4f} BS-{:.4f} | Dense: RG-{:.4f} BS-{:.4f} \\t {:.2f}\".format(\n",
    "            i+1,\n",
    "            tot_rg_sparse / (i+1), tot_bs_sparse / (i+1),\n",
    "            tot_rg_dense / (i+1), tot_bs_dense / (i+1),\n",
    "            time() - st_time\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer Generation Model\n",
    "<a id='generation'></a>\n",
    "\n",
    "Once we have a question and a document containing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgumentsS2S():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 16\n",
    "        self.backward_freq = 8\n",
    "        self.max_length = 1024\n",
    "        self.print_freq = 100\n",
    "        self.model_save_name = \"seq2seq_models/bart_model\"\n",
    "        self.learning_rate = 2e-4\n",
    "        self.num_epochs = 20\n",
    "\n",
    "s2s_args = ArgumentsS2S()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_s2s_tokenizer, pre_model = make_qa_s2s_model(\n",
    "    model_name=\"facebook/bart-large\",\n",
    "    from_file=None,\n",
    "    device=\"cuda:0\"\n",
    ")\n",
    "qa_s2s_model = torch.nn.DataParallel(pre_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5_train_docs = json.load(open('precomputed/eli5_train_precomputed_dense_docs.json'))\n",
    "eli5_valid_docs = json.load(open('precomputed/eli5_valid_precomputed_dense_docs.json'))\n",
    "\n",
    "s2s_train_dset = ELI5DatasetS2S(eli5['train_eli5'], document_cache=dict([(k, d) for k, d, src_ls in eli5_train_docs]))\n",
    "s2s_valid_dset = ELI5DatasetS2S(eli5['validation_eli5'], document_cache=dict([(k, d) for k, d, src_ls in eli5_valid_docs]), training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2s_optimizer = AdamW(qa_s2s_model.parameters(), lr=s2s_args.learning_rate, eps=1e-8)\n",
    "s2s_scheduler = get_linear_schedule_with_warmup(\n",
    "        s2s_optimizer,\n",
    "        num_warmup_steps=400,\n",
    "        num_training_steps=s2s_args.num_epochs * math.ceil(len(s2s_train_dset) / s2s_args.batch_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yacine/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0     0 of 36184 \t L: 4.835 \t -- 29.596\n",
      " 0     1 of 36184 \t L: 4.687 \t -- 31.556\n",
      " 0   100 of 36184 \t L: 4.478 \t -- 150.420\n",
      " 0   200 of 36184 \t L: 3.755 \t -- 269.327\n",
      " 0   300 of 36184 \t L: 3.469 \t -- 387.855\n",
      " 0   400 of 36184 \t L: 3.360 \t -- 505.592\n",
      " 0   500 of 36184 \t L: 3.311 \t -- 624.245\n",
      " 0   600 of 36184 \t L: 3.274 \t -- 741.951\n",
      " 0   700 of 36184 \t L: 3.242 \t -- 860.024\n",
      " 0   800 of 36184 \t L: 3.231 \t -- 977.969\n",
      " 0   900 of 36184 \t L: 3.214 \t -- 1096.494\n",
      " 0  1000 of 36184 \t L: 3.230 \t -- 1214.687\n",
      " 0  1100 of 36184 \t L: 3.227 \t -- 1332.183\n",
      " 0  1200 of 36184 \t L: 3.186 \t -- 1450.259\n",
      " 0  1300 of 36184 \t L: 3.206 \t -- 1568.458\n",
      " 0  1400 of 36184 \t L: 3.209 \t -- 1686.349\n",
      " 0  1500 of 36184 \t L: 3.184 \t -- 1804.035\n",
      " 0  1600 of 36184 \t L: 3.204 \t -- 1922.431\n",
      " 0  1700 of 36184 \t L: 3.190 \t -- 2040.502\n",
      " 0  1800 of 36184 \t L: 3.174 \t -- 2158.630\n",
      " 0  1900 of 36184 \t L: 3.181 \t -- 2276.222\n",
      " 0  2000 of 36184 \t L: 3.187 \t -- 2393.720\n",
      " 0  2100 of 36184 \t L: 3.192 \t -- 2511.511\n",
      " 0  2200 of 36184 \t L: 3.200 \t -- 2629.640\n",
      " 0  2300 of 36184 \t L: 3.221 \t -- 2747.249\n",
      " 0  2400 of 36184 \t L: 3.221 \t -- 2864.976\n",
      " 0  2500 of 36184 \t L: 3.197 \t -- 2982.432\n",
      " 0  2600 of 36184 \t L: 3.182 \t -- 3100.747\n",
      " 0  2700 of 36184 \t L: 3.196 \t -- 3218.734\n",
      " 0  2800 of 36184 \t L: 3.222 \t -- 3335.701\n",
      " 0  2900 of 36184 \t L: 3.221 \t -- 3453.762\n",
      " 0  3000 of 36184 \t L: 3.243 \t -- 3571.395\n",
      " 0  3100 of 36184 \t L: 3.205 \t -- 3690.055\n",
      " 0  3200 of 36184 \t L: 3.211 \t -- 3807.780\n",
      " 0  3300 of 36184 \t L: 3.229 \t -- 3924.843\n",
      " 0  3400 of 36184 \t L: 3.209 \t -- 4042.701\n",
      " 0  3500 of 36184 \t L: 3.208 \t -- 4160.961\n",
      " 0  3600 of 36184 \t L: 3.217 \t -- 4278.657\n",
      " 0  3700 of 36184 \t L: 3.228 \t -- 4396.737\n",
      " 0  3800 of 36184 \t L: 3.227 \t -- 4513.915\n",
      " 0  3900 of 36184 \t L: 3.198 \t -- 4632.379\n",
      " 0  4000 of 36184 \t L: 3.199 \t -- 4750.382\n",
      " 0  4100 of 36184 \t L: 3.214 \t -- 4867.639\n",
      " 0  4200 of 36184 \t L: 3.215 \t -- 4984.908\n",
      " 0  4300 of 36184 \t L: 3.207 \t -- 5102.258\n",
      " 0  4400 of 36184 \t L: 3.226 \t -- 5220.051\n",
      " 0  4500 of 36184 \t L: 3.239 \t -- 5337.905\n",
      " 0  4600 of 36184 \t L: 3.193 \t -- 5455.712\n",
      " 0  4700 of 36184 \t L: 3.203 \t -- 5573.452\n",
      " 0  4800 of 36184 \t L: 3.204 \t -- 5690.157\n",
      " 0  4900 of 36184 \t L: 3.208 \t -- 5808.033\n",
      " 0  5000 of 36184 \t L: 3.207 \t -- 5926.227\n"
     ]
    }
   ],
   "source": [
    "for e in range(s2s_args.num_epochs):\n",
    "    train_qa_s2s_epoch(\n",
    "        qa_s2s_model,\n",
    "        s2s_train_dset, qa_s2s_tokenizer,\n",
    "        s2s_optimizer, s2s_scheduler,\n",
    "        s2s_args, e\n",
    "    )\n",
    "    m_save_dict = {\n",
    "        'model': qa_s2s_model.state_dict(),\n",
    "        'optimizer': s2s_optimizer.state_dict(),\n",
    "        'scheduler': s2s_scheduler.state_dict(),\n",
    "    }\n",
    "    print(\"Saving model {}\".format(s2s_args.model_save_name))\n",
    "    torch.save(m_save_dict, '{}_{}.pth'.format(s2s_args.model_save_name, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 of  2453 \t L: 3.521 \t -- 0.315\n",
      " 1000 of  2453 \t L: 3.260 \t -- 319.746\n",
      " 2000 of  2453 \t L: 3.264 \t -- 638.111\n",
      "Total \t L: 3.265 \t -- 782.534\n"
     ]
    }
   ],
   "source": [
    "_ = qa_s2s_model.eval()\n",
    "s2s_args.print_freq = 100\n",
    "eval_qa_s2s_epoch(\n",
    "        qa_s2s_model,\n",
    "        s2s_valid_dset, qa_s2s_tokenizer,\n",
    "        s2s_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q_id': '20q8w1',\n",
       " 'title': 'How do apps like soundhound and shazam know what song is playing?',\n",
       " 'selftext': '',\n",
       " 'document': '',\n",
       " 'subreddit': 'explainlikeimfive',\n",
       " 'answers': {'a_id': ['cg5r130'],\n",
       "  'text': ['ELI5:\\n\\nThink about when you hear your parents, you can recognize their voice right? Or when you see a dog, you can recognize it\\'s a dog in general. Now what kind of dog? You can typically recognize it\\'s a chihuahua or, my fav, a golden retriever. How? Chihuahuas are small and annoying with short hair, whereas a golden retriever is cute, cuddly, friendly, with long hair (I may have some bias here).\\n\\nIn the same way, Shazam and Soundhound does that! They take a look at features of a song, like the pitch, tone, or waveform (the \"shape\" of the song) and try to match it to a song in their memory.'],\n",
       "  'score': [2]},\n",
       " 'title_urls': {'url': []},\n",
       " 'selftext_urls': {'url': []},\n",
       " 'answers_urls': {'url': []}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5['validation_eli5'][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soundhound and Shazam don't \"know\" what song is playing, but they do have a database of songs that they can look at to find out what song they're listening to. \n",
      "\n",
      "When you play a song, the app listens to the song and compares it to the database that it knows what song it's listening to, and if it finds a match, it knows it's playing the song.\n",
      "\n",
      "If it can't find the song, it doesn't know what's playing.\n"
     ]
    }
   ],
   "source": [
    "print(qa_s2s_generate(\n",
    "        s2s_valid_dset[11][0], qa_s2s_model.module, qa_s2s_tokenizer,\n",
    "        num_answers=1,\n",
    "        num_beams=8,\n",
    "        min_len=64,\n",
    "        max_len=256,\n",
    "        max_input_length=1024,\n",
    "        device=\"cuda:0\"\n",
    "    )[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = []\n",
    "st_time = time()\n",
    "for i in range(2000):\n",
    "    generated += [qa_s2s_generate(\n",
    "        s2s_valid_dset[i][0], qa_s2s_model.module, qa_s2s_tokenizer,\n",
    "        num_answers=1,\n",
    "        num_beams=8,\n",
    "        min_len=64,\n",
    "        max_len=256,\n",
    "        max_input_length=1024,\n",
    "        device=\"cuda:0\"\n",
    "    )[0]]\n",
    "    if i % 100 == 0:\n",
    "        print(eli5['validation_eli5'].num_rows, i, time() - st_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qda_difficulty(question_doc, answer):\n",
    "    qd_words = dict([(w, True) for w in question_doc.lower().split()])\n",
    "    recall = len([w for w in answer.lower().split() if w in qd_words]) / len(answer.split())\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('question: in football whats the point of wasting the first two plays with a rush - up the middle - not regular rush plays i get those context: <p> blitz count), so called because the blitzing player must insert the word \"mississippi\" between numbers so as not to allow the player to count ridiculously fast and effectively give the quarterback no time to throw. sometimes the two rules are combined, allowing one separate call of \"blitz!\" per set of 4 downs. the other option to handle a rush is to use an offensive lineman or center to block any pass rush. a line is rare in street, and the act of a center snapping to a quarterback is completely optional. most teams that use a line opt for 3 <p> of the increased appearance fees that such a bowl generates for the conference. jim vertuno of the associated press wrote \"leach was upset officials disallowed two tech touchdowns in the third quarter. the first was overruled when video replay clearly showed the receiver let the ball hit the ground. on the next play, a touchdown pass was negated by a holding penalty. leach also wanted, but didn\\'t get, a flag for roughing the quarterback.\" the \"lubbock avalanche-journal\" reported, \"big 12 policy prohibits coaches from commenting publicly about game officials, so leach\\'s actions leave him open to reprimand, fine or worse.\" <p> 7:26 â€“ 4-yard td run by cecil sapp (elam kick) (14â€“3 den)\\n - q2 â€“ den â€“ 14:42 â€“ 23-yard fg by elam (17â€“3 den)\\n - q3 â€“ oak â€“ 9:41 â€“ 46-yard td pass from josh mccown to jerry porter (janikowski kick) (17â€“10 den)\\n - q4 â€“ oak â€“ 0:45 â€“ safety, cutler sacked by gerard warren in end zone (17â€“12 den)\\n - q4 â€“ oak â€“ 6:05 â€“ 44-yard interception return by thomas howard (two-point conversion, josh mccown to ronald curry) (20â€“17 oak)\\n - q4 â€“ den â€“ 12:42 â€“ 20-yard fg by elam (20â€“20)\\n - ot â€“ <p> manager chuck dressen finally pulled the exhausted newcombe. in the bullpen, where branca and carl erskine were warming up, coach clyde sukeforth noticed that erskine â€” who had been troubled by arm problems all season â€” was bouncing his curve balls short of the plate, and advised dressen to use branca in relief. that decision has been continually second-guessed by fans, sportswriters, and baseball historians: branca had lost six of his last seven decisions, and gave up a game-winning home run to thomson in the first playoff game. dressen\\'s options, however, were severely limited: the only other available pitchers with <p> rushing play unless the rusher steps out of bounds) or one or more quarterback kneels. a team will often accept minimal prospect for a large gain in yardage (or even, particularly with quarterback kneels, a modest loss of yardage) in order to drain more time from the game clock, as time elapsed is considered more valuable than yardage to a team with the lead. passing plays are not typically used by a team running out the clock, as an incomplete pass will cause the game clock to stop. passing plays always carry the risk of interception, and spread the offense <p> this defense is used to discourage deeper passes, but often allows short yardage passes. a loose-man defense looks to create confusion for the quarterback by using blitzes. the idea is to disrupt the coordination necessary for short routes, which leads to drops or poorly thrown passes stalling the drive. however, accurate quarterbacks with a quick release of football can exploit this and routinely make 3 to 5 yard completions to receivers.\\n single/man-to-man coverage.:man up.\\n by far the most challenging, the man up technique grants the wide receiver a relatively free release as the corner shadows him stride for stride everywhere <p> the week. since the customary week off before the super bowl for this season was not on the schedule, parcells told the team prior to leaving for newark airport that they had two packing options: either pack just for the trip to san francisco, or pack for that trip and a second trip to tampa. he then showed the team he was packing for both trips as a motivational tactic.\\n in a mostly defensive battle, 49ers running back roger craig\\'s fumble with 2:36 left in the game led to giants kicker matt bahr\\'s 42-yard game-winning field goal as time ran <p> to put double-coverage on the olympic champion sprinter. it proved to be a good gamble, as herb adderley and bob jeter held hayes to only one reception for one yard. lombardi also installed a special offense for the game, knowing that the cowboys had spent time preparing to stop plays like the packers sweep.\\n green bay scored on their opening drive, with elijah pitts breaking free for a 32-yard run on the opening play - a misdirection play that was part of lombardi\\'s special game plan. later pitts took a circle route pass over the middle from bart starr at <p> halfback option play\\n the halfback option play is an unorthodox play in american and canadian football. it resembles a normal running play, but the running back has the option to throw a pass to another eligible receiver before crossing the line of scrimmage.\\n the key to the play is fooling the defensive players, primarily the defensive backs. if the linebackers and/or the defensive line are fooled and believe the ball carrier is attempting a run, they will pursue the runner, abandoning their pass defense responsibilities and thereby leaving pass receivers uncovered. if the defensive backs are not fooled, the running <p> is extremely rare for cfl passes to hit any part of the posts. when this occurs, a dead ball results. occasionally, receivers can use the post to good effect in a \\'rub\\' play to shed a defender. end zone passing becomes even more complicated when the corners of the end zone are truncated, as is the case at stadia where the field is bounded by a running track. however, the offensive team enjoys a counteracting advantage of end zones more than twice the size of those in american football (20 yards with a wider field), significantly expanding the area that',\n",
       " \"Keep the defense honest, get a feel for the pass rush, open up the passing game. An offense that's too one dimensional will fail. And those rushes up the middle can be busted wide open sometimes for big yardage.\")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s_train_dset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_diff = [(i, qda_difficulty(*s2s_train_dset[i])) for i in range(10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4885, 1.0),\n",
       " (4112, 0.9523809523809523),\n",
       " (8829, 0.9090909090909091),\n",
       " (9692, 0.9090909090909091),\n",
       " (3443, 0.9032258064516129),\n",
       " (2563, 0.9),\n",
       " (4930, 0.9),\n",
       " (6940, 0.9),\n",
       " (9267, 0.8928571428571429),\n",
       " (7644, 0.8888888888888888)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(recall_diff, key=lambda x:x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
