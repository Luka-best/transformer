{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cbbf9d6e0424dbaa29a2d75c046f392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# setup dataset + index\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import faiss\n",
    "retrieval_vector_size = 768\n",
    "\n",
    "dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"id\": [str(i) for i in range(10)],\n",
    "        \"text\": [\"My favourite number is 3455\", \"The secret word is FROG\"] * 5,\n",
    "        \"embeddings\": [\n",
    "            0.1 * np.ones(retrieval_vector_size),\n",
    "            0.9 * np.ones(retrieval_vector_size),\n",
    "        ] * 5,\n",
    "    }\n",
    ")\n",
    "\n",
    "dataset.add_faiss_index(\"embeddings\", metric_type=faiss.METRIC_INNER_PRODUCT)\n",
    "from src.transformers.models.atlas.retrieval_atlas import AtlasRetrieverIndex, AtlasConfig, AtlasTokenizer\n",
    "\n",
    "config = AtlasConfig.from_pretrained(\"./data/atlas-pretrained\")\n",
    "tokenizer = AtlasTokenizer.from_pretrained(\"./data/atlas-pretrained\", config=config)\n",
    "\n",
    "retriever_index = AtlasRetrieverIndex(config, tokenizer, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for some reason, src.transformers.models.atlas.modeling_atlas as import causes an error here\n",
    "# model doesn't load right?\n",
    "from transformers import AtlasModel\n",
    "\n",
    "atlas = AtlasModel.from_pretrained('data/atlas-pretrained', retriever_index=retriever_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635c2d64694442adbdd75b3eee73fa01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1646fb6ac087484586eea457dbff6e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  822,    10,   363,    19,    82,  3960,   381,    58,  1525,    10,\n",
      "             3, 32099,     1],\n",
      "        [  822,    10,   363,    19,     8,  2829,  1448,    58,  1525,    10,\n",
      "             3, 32099,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, tensor(3.6842, grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_index.reindex(atlas, batch_size=2)\n",
    "\n",
    "\n",
    "inputs_string = [\"What is my favourite number?\", \"What is the secret word?\"]\n",
    "target_string = [\"3455\", \"FROG\"]\n",
    "\n",
    "inputs_string = [f\"question: {question} answer: <extra_id_0>\" for question in inputs_string]\n",
    "target_string = [f\"<extra_id_0> {answer}\" for answer in target_string]\n",
    "\n",
    "tokens = tokenizer.generator(inputs_string, return_tensors=\"pt\", padding=True)\n",
    "labels = tokenizer.generator(target_string, return_tensors=\"pt\", padding=True)\n",
    "query_tokens = tokenizer.retriever(inputs_string, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "labels[labels == tokenizer.generator.pad_token_id] = -100\n",
    "\n",
    "\n",
    "print(tokens)\n",
    "atlas.forward(\n",
    "    input_ids=tokens.input_ids,\n",
    "    attention_mask=tokens.attention_mask,\n",
    "    labels=labels.input_ids,\n",
    "    query_input_ids=query_tokens.input_ids,\n",
    "    query_attention_mask=query_tokens.attention_mask,\n",
    "    top_k=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7413, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9912, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8226, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6037, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5496, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5985, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6549, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4596, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5749, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1252, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1941, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2186, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0727, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6765, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8882, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0279, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6901, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5259, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5870, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6608, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4602, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4556, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4338, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_s/gn_5k0b56g70414mq8rc3n040000gn/T/ipykernel_13018/3563642936.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     )[1]\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "atlas.train()\n",
    "import torch\n",
    "optimizer = torch.optim.Adam(atlas.parameters(), lr=1e-4)\n",
    "for i in range(30):\n",
    "    loss = atlas.forward(\n",
    "        input_ids=tokens.input_ids,\n",
    "        attention_mask=tokens.attention_mask,\n",
    "        labels=labels.input_ids,\n",
    "        query_input_ids=query_tokens.input_ids,\n",
    "        query_attention_mask=query_tokens.attention_mask,\n",
    "        top_k=2,\n",
    "    )[1]\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n",
    "    # zero out gradients\n",
    "    optimizer.zero_grad()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "472f3460692ba2c0861145e5e150d03c8a5c0e40e057944a047c431b9050b93d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
