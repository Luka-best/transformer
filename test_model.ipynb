{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0776305d4d4ddaac8196d6fb6caf8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# setup dataset + index\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import faiss\n",
    "retrieval_vector_size = 768\n",
    "\n",
    "dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"id\": [str(i) for i in range(10)],\n",
    "        \"text\": [\"My favourite number is 3455\", \"The secret word is FROG\"] * 5,\n",
    "        \"embeddings\": [\n",
    "            0.1 * np.ones(retrieval_vector_size),\n",
    "            0.9 * np.ones(retrieval_vector_size),\n",
    "        ] * 5,\n",
    "    }\n",
    ")\n",
    "\n",
    "dataset.add_faiss_index(\"embeddings\", metric_type=faiss.METRIC_INNER_PRODUCT)\n",
    "from src.transformers.models.atlas.retrieval_atlas import AtlasRetrieverIndex, AtlasConfig, AtlasTokenizer\n",
    "\n",
    "config = AtlasConfig.from_pretrained(\"./data/atlas-pretrained\")\n",
    "tokenizer = AtlasTokenizer.from_pretrained(\"./data/atlas-pretrained\", config=config)\n",
    "\n",
    "retriever_index = AtlasRetrieverIndex(config, tokenizer, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for some reason, src.transformers.models.atlas.modeling_atlas as import causes an error here\n",
    "# model doesn't load right?\n",
    "from transformers import AtlasModel\n",
    "\n",
    "atlas = AtlasModel.from_pretrained('data/atlas-pretrained', retriever_index=retriever_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb9ecb6648e47998efd7c4f3152cfd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aadfa1717194a529532a642b2057212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  822,    10,   363,    19,    82,  3960,   381,    58,  1525,    10,\n",
      "             3, 32099,     1],\n",
      "        [  822,    10,   363,    19,     8,  2829,  1448,    58,  1525,    10,\n",
      "             3, 32099,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/opt/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:2904: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AtlasModelOutput(generator_loss=tensor(3.7933, grad_fn=<NllLossBackward0>), retriever_loss=tensor(0.2630, grad_fn=<KlDivBackward0>), logits=tensor([[[-13.9893,  -4.8677,  -4.1102,  ..., -14.7916, -13.3198, -14.7123],\n",
       "         [-22.3417,  -4.3604,  -5.7955,  ..., -22.0388, -22.2972, -21.5707],\n",
       "         [-33.0299,  -7.8454, -10.1410,  ..., -32.7671, -33.2933, -32.7036],\n",
       "         [-33.9165,  -4.7252, -11.1489,  ..., -33.7144, -34.1410, -33.6054],\n",
       "         [-28.7629,  -5.0741,  -7.5760,  ..., -28.2001, -28.8387, -27.9074]],\n",
       "\n",
       "        [[-22.9633,  -9.1757,  -8.2084,  ..., -24.1951, -22.0178, -23.0390],\n",
       "         [-24.6265,  -2.8294,  -7.8373,  ..., -24.5500, -24.8253, -24.2540],\n",
       "         [-24.9997,  -5.5261,  -2.2094,  ..., -24.5674, -25.0943, -24.5938],\n",
       "         [-42.4483, -13.1286, -11.4029,  ..., -41.9430, -43.0953, -42.3096],\n",
       "         [-30.0594,  -1.1307,  -7.7721,  ..., -29.8447, -30.2589, -29.9028]]],\n",
       "       grad_fn=<UnsafeViewBackward0>), doc_scores=None, past_key_values=None, retrieved_doc_embeds=None, retrieved_doc_ids=None, context_input_ids=None, context_attention_mask=None, question_encoder_last_hidden_state=None, question_enc_hidden_states=None, question_enc_attentions=None, generator_enc_last_hidden_state=tensor([[[-0.1586,  0.2937, -0.0430,  ...,  0.1510, -0.2578, -0.2683],\n",
       "         [-0.0677,  0.0523, -0.0140,  ..., -0.0205,  0.0935,  0.0714],\n",
       "         [-0.0061,  0.0785, -0.1200,  ...,  0.0304, -0.1269, -0.0553],\n",
       "         ...,\n",
       "         [ 0.0041, -0.1382, -0.0575,  ...,  0.1147,  0.1007,  0.0310],\n",
       "         [ 0.0111, -0.0111, -0.0095,  ..., -0.0141, -0.0081, -0.0262],\n",
       "         [-0.0174,  0.1415, -0.0997,  ...,  0.1472, -0.2408,  0.2384]],\n",
       "\n",
       "        [[-0.2216,  0.0254, -0.0000,  ...,  0.1071, -0.2630, -0.0000],\n",
       "         [-0.0902, -0.1426,  0.1604,  ..., -0.0696, -0.0067,  0.0833],\n",
       "         [-0.2174,  0.1062, -0.0875,  ..., -0.0916, -0.2074, -0.0174],\n",
       "         ...,\n",
       "         [-0.0000,  0.1330, -0.0000,  ..., -0.0758,  0.0280, -0.0000],\n",
       "         [-0.0523,  0.0087,  0.1473,  ..., -0.1536,  0.1972, -0.0000],\n",
       "         [ 0.0152,  0.0100,  0.0241,  ...,  0.0005, -0.0083,  0.0025]]],\n",
       "       grad_fn=<ViewBackward0>), generator_enc_hidden_states=None, generator_enc_attentions=None, generator_dec_hidden_states=None, generator_dec_attentions=None, generator_cross_attentions=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_index.reindex(atlas, batch_size=2)\n",
    "\n",
    "\n",
    "inputs_string = [\"What is my favourite number?\", \"What is the secret word?\"]\n",
    "target_string = [\"3455\", \"FROG\"]\n",
    "\n",
    "inputs_string = [f\"question: {question} answer: <extra_id_0>\" for question in inputs_string]\n",
    "target_string = [f\"<extra_id_0> {answer}\" for answer in target_string]\n",
    "\n",
    "tokens = tokenizer.generator(inputs_string, return_tensors=\"pt\", padding=True)\n",
    "labels = tokenizer.generator(target_string, return_tensors=\"pt\", padding=True)\n",
    "query_tokens = tokenizer.retriever(inputs_string, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "labels[labels == tokenizer.generator.pad_token_id] = -100\n",
    "\n",
    "atlas.train()\n",
    "atlas.config.query_side_retriever_training = True\n",
    "\n",
    "print(tokens)\n",
    "atlas.forward(\n",
    "    input_ids=tokens.input_ids,\n",
    "    attention_mask=tokens.attention_mask,\n",
    "    labels=labels.input_ids,\n",
    "    query_input_ids=query_tokens.input_ids,\n",
    "    query_attention_mask=query_tokens.attention_mask,\n",
    "    top_k=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT: ['<pad><extra_id_0> 3455</s><pad>', '<pad><extra_id_0> FROG</s>']\n",
      "EXPECTED: ['<extra_id_0> 3455</s><pad>', '<extra_id_0> FROG</s>']\n"
     ]
    }
   ],
   "source": [
    "atlas.eval()\n",
    "generated = atlas.generate(\n",
    "    input_ids=tokens.input_ids,\n",
    "    attention_mask=tokens.attention_mask,\n",
    "    query_input_ids=query_tokens.input_ids,\n",
    "    query_attention_mask=query_tokens.attention_mask,\n",
    "    top_k=2,\n",
    ")\n",
    "\n",
    "decoded = tokenizer.generator.batch_decode(generated)\n",
    "print(\"OUTPUT:\", decoded)\n",
    "labels_decoded = tokenizer.generator.batch_decode(labels.input_ids)\n",
    "print(\"EXPECTED:\", labels_decoded)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6709, grad_fn=<NllLossBackward0>) tensor(0.0017, grad_fn=<KlDivBackward0>)\n",
      "tensor(2.7269, grad_fn=<NllLossBackward0>) tensor(0.0130, grad_fn=<KlDivBackward0>)\n",
      "tensor(2.5194, grad_fn=<NllLossBackward0>) tensor(0.0037, grad_fn=<KlDivBackward0>)\n",
      "tensor(2.8665, grad_fn=<NllLossBackward0>) tensor(0.0024, grad_fn=<KlDivBackward0>)\n",
      "tensor(2.5058, grad_fn=<NllLossBackward0>) tensor(0.0002, grad_fn=<KlDivBackward0>)\n",
      "tensor(2.5434, grad_fn=<NllLossBackward0>) tensor(0.0004, grad_fn=<KlDivBackward0>)\n",
      "tensor(2.6853, grad_fn=<NllLossBackward0>) tensor(0.0023, grad_fn=<KlDivBackward0>)\n",
      "tensor(2.7317, grad_fn=<NllLossBackward0>) tensor(0.0013, grad_fn=<KlDivBackward0>)\n",
      "tensor(2.4069, grad_fn=<NllLossBackward0>) tensor(3.0175e-05, grad_fn=<KlDivBackward0>)\n",
      "tensor(2.3856, grad_fn=<NllLossBackward0>) tensor(0.0140, grad_fn=<KlDivBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_s/gn_5k0b56g70414mq8rc3n040000gn/T/ipykernel_23222/3923238247.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# loss.retriever_loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;31m# zero out gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    155\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             adam(params_with_grad,\n\u001b[0m\u001b[1;32m    158\u001b[0m                  \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                  \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    214\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "atlas.train()\n",
    "import torch\n",
    "optimizer = torch.optim.Adam(atlas.parameters(), lr=1e-5)\n",
    "\n",
    "for i in range(10):\n",
    "    loss = atlas.forward(\n",
    "        input_ids=tokens.input_ids,\n",
    "        attention_mask=tokens.attention_mask,\n",
    "        labels=labels.input_ids,\n",
    "        query_input_ids=query_tokens.input_ids,\n",
    "        query_attention_mask=query_tokens.attention_mask,\n",
    "        top_k=2,\n",
    "    )\n",
    "    print(loss.generator_loss, loss.retriever_loss)\n",
    "    loss.generator_loss.backward()\n",
    "    # loss.retriever_loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    # zero out gradients\n",
    "    optimizer.zero_grad()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "472f3460692ba2c0861145e5e150d03c8a5c0e40e057944a047c431b9050b93d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
