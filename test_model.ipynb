{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b326e53d4d2044f58243b436b62674a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# setup dataset + index\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import faiss\n",
    "retrieval_vector_size = 768\n",
    "\n",
    "dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"id\": [str(i) for i in range(10)],\n",
    "        \"text\": [\"My favourite number is 3455\", \"The secret word is FROG\"] * 5,\n",
    "        \"embeddings\": [\n",
    "            0.1 * np.ones(retrieval_vector_size),\n",
    "            0.9 * np.ones(retrieval_vector_size),\n",
    "        ] * 5,\n",
    "    }\n",
    ")\n",
    "\n",
    "dataset.add_faiss_index(\"embeddings\", metric_type=faiss.METRIC_INNER_PRODUCT)\n",
    "from src.transformers.models.atlas.retrieval_atlas import AtlasRetrieverIndex, AtlasConfig, AtlasTokenizer\n",
    "\n",
    "config = AtlasConfig.from_pretrained(\"./data/atlas-pretrained\")\n",
    "tokenizer = AtlasTokenizer.from_pretrained(\"./data/atlas-pretrained\", config=config)\n",
    "\n",
    "retriever_index = AtlasRetrieverIndex(config, tokenizer, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for some reason, src.transformers.models.atlas.modeling_atlas as import causes an error here\n",
    "# model doesn't load right?\n",
    "from transformers import AtlasModel\n",
    "\n",
    "atlas = AtlasModel.from_pretrained('data/atlas-pretrained', retriever_index=retriever_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5dd97e4e59048aa9d33365568fa67ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324e69417a1449bf8972af06d200964a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  822,    10,   363,    19,    82,  3960,   381,    58,  1525,    10,\n",
      "             3, 32099,     1],\n",
      "        [  822,    10,   363,    19,     8,  2829,  1448,    58,  1525,    10,\n",
      "             3, 32099,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "repeat_interleave() received an invalid combination of arguments - got (NoneType, int, dim=int), but expected one of:\n * (Tensor input, Tensor repeats, int dim, *, int output_size)\n * (Tensor input, int repeats, int dim, *, int output_size)\n * (Tensor repeats, *, int output_size)\n      didn't match because some of the keywords were incorrect: dim\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_s/gn_5k0b56g70414mq8rc3n040000gn/T/ipykernel_15736/3673381353.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m atlas.forward(\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/transformers/src/transformers/models/atlas/modeling_atlas.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, labels, query_input_ids, query_attention_mask, decoder_input_ids, top_k)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mretriever_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"id, ijd->ij\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mquery_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassage_emb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0mgold_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperplexity_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0mretriever_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretriever_score\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mgold_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgold_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/transformers/src/transformers/models/atlas/modeling_atlas.py\u001b[0m in \u001b[0;36mperplexity_score\u001b[0;34m(self, reader_ids, reader_mask, decoder_input_ids, labels, cfg, bsz)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mreader_ids_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtotal_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mreader_mask_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtotal_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0mrepeated_decoder_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m             \u001b[0mrepeated_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             reader_output = self.generator(\n",
      "\u001b[0;31mTypeError\u001b[0m: repeat_interleave() received an invalid combination of arguments - got (NoneType, int, dim=int), but expected one of:\n * (Tensor input, Tensor repeats, int dim, *, int output_size)\n * (Tensor input, int repeats, int dim, *, int output_size)\n * (Tensor repeats, *, int output_size)\n      didn't match because some of the keywords were incorrect: dim\n"
     ]
    }
   ],
   "source": [
    "retriever_index.reindex(atlas, batch_size=2)\n",
    "\n",
    "\n",
    "inputs_string = [\"What is my favourite number?\", \"What is the secret word?\"]\n",
    "target_string = [\"3455\", \"FROG\"]\n",
    "\n",
    "inputs_string = [f\"question: {question} answer: <extra_id_0>\" for question in inputs_string]\n",
    "target_string = [f\"<extra_id_0> {answer}\" for answer in target_string]\n",
    "\n",
    "tokens = tokenizer.generator(inputs_string, return_tensors=\"pt\", padding=True)\n",
    "labels = tokenizer.generator(target_string, return_tensors=\"pt\", padding=True)\n",
    "query_tokens = tokenizer.retriever(inputs_string, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "labels[labels == tokenizer.generator.pad_token_id] = -100\n",
    "\n",
    "\n",
    "print(tokens)\n",
    "atlas.forward(\n",
    "    input_ids=tokens.input_ids,\n",
    "    attention_mask=tokens.attention_mask,\n",
    "    labels=labels.input_ids,\n",
    "    query_input_ids=query_tokens.input_ids,\n",
    "    query_attention_mask=query_tokens.attention_mask,\n",
    "    top_k=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7413, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9912, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8226, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6037, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5496, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5985, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6549, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4596, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5749, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1252, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1941, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2186, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0727, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6765, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8882, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0279, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6901, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5259, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5870, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6608, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4602, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4556, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4338, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_s/gn_5k0b56g70414mq8rc3n040000gn/T/ipykernel_13018/3563642936.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     )[1]\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "atlas.train()\n",
    "import torch\n",
    "optimizer = torch.optim.Adam(atlas.parameters(), lr=1e-4)\n",
    "for i in range(30):\n",
    "    loss = atlas.forward(\n",
    "        input_ids=tokens.input_ids,\n",
    "        attention_mask=tokens.attention_mask,\n",
    "        labels=labels.input_ids,\n",
    "        query_input_ids=query_tokens.input_ids,\n",
    "        query_attention_mask=query_tokens.attention_mask,\n",
    "        top_k=2,\n",
    "    )[1]\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n",
    "    # zero out gradients\n",
    "    optimizer.zero_grad()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "472f3460692ba2c0861145e5e150d03c8a5c0e40e057944a047c431b9050b93d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
