{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd007c4df7ea0886a603057dcbd29d886eaa26a0122c4b0c39e2937eba8f7497417",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BigBirdForPreTraining, FlaxBigBirdForPreTraining\n",
    "import numpy as np\n",
    "import jax\n",
    "import torch\n",
    "import jax.numpy as jnp\n",
    "\n",
    "MODEL_ID = \"google/bigbird-roberta-base\"\n",
    "\n",
    "def get_difference(torch_array, jx_array):\n",
    "    torch_array = torch_array.detach().numpy()\n",
    "    jx_array = np.array(jx_array)\n",
    "    return np.max(torch_array - jx_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing FlaxBigBirdForPreTraining: {('cls', 'predictions', 'decoder', 'kernel'), ('cls', 'predictions', 'decoder', 'bias'), ('bert', 'embeddings', 'position_ids')}\n",
      "- This IS expected if you are initializing FlaxBigBirdForPreTraining from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaxBigBirdForPreTraining from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "fx_model = FlaxBigBirdForPreTraining.from_pretrained(MODEL_ID, from_pt=True)\n",
    "model = BigBirdForPreTraining.from_pretrained(MODEL_ID, attention_type=\"original_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(DeviceArray([[173,  48, 118, ..., 491,  54, 305],\n",
       "              [ 95,  60, 337, ...,  51, 243, 359]], dtype=int32),\n",
       " tensor([[173,  48, 118,  ..., 491,  54, 305],\n",
       "         [ 95,  60, 337,  ...,  51, 243, 359]]))"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "array = np.random.randint(1, 512, size=(2, 512))\n",
    "\n",
    "jx_array = jnp.array(array)\n",
    "torch_array = torch.tensor(array, dtype=torch.long)\n",
    "\n",
    "jx_array, torch_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DeviceArray([[[-4.9603143 , -6.466676  , -4.6835575 , ..., -4.8491845 ,\n",
       "               -3.3872652 , -2.416497  ],\n",
       "              [-4.8720617 , -6.6423264 , -5.374215  , ..., -6.417832  ,\n",
       "               -2.9115303 , -4.7255917 ],\n",
       "              [ 0.7174561 , -0.50911397,  3.9928522 , ..., -7.978772  ,\n",
       "               -7.620496  ,  4.976294  ],\n",
       "              ...,\n",
       "              [-5.566427  , -7.214348  , -4.3618603 , ..., -5.987189  ,\n",
       "               -4.2361917 , -3.9470434 ],\n",
       "              [-4.689574  , -7.061965  , -4.666668  , ..., -4.087977  ,\n",
       "               -2.3270102 , -4.136928  ],\n",
       "              [-5.369287  , -6.8011727 , -4.333805  , ..., -4.2402    ,\n",
       "               -2.8998585 , -3.902777  ]],\n",
       "\n",
       "             [[-4.069118  , -6.0870595 , -4.890304  , ..., -6.692041  ,\n",
       "               -3.4898877 , -1.5123243 ],\n",
       "              [-3.883913  , -6.4441943 , -4.5847635 , ..., -4.6294613 ,\n",
       "               -2.660959  , -2.9854906 ],\n",
       "              [-4.6196632 , -6.3770995 , -3.9329724 , ..., -4.7168756 ,\n",
       "               -2.1265676 , -2.8034263 ],\n",
       "              ...,\n",
       "              [-3.6946473 , -5.783889  , -4.104965  , ..., -3.6338584 ,\n",
       "               -3.081688  , -2.761352  ],\n",
       "              [-3.5685773 , -5.4104095 , -3.5696626 , ..., -4.865243  ,\n",
       "               -2.6639493 , -2.2419584 ],\n",
       "              [-2.2415357 , -4.970186  , -3.0008483 , ..., -5.3959765 ,\n",
       "               -2.223445  , -1.151835  ]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "fx_out = fx_model(jx_array)[0]\n",
    "fx_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[-4.9603, -6.4667, -4.6836,  ..., -4.8492, -3.3873, -2.4165],\n",
       "         [-4.8721, -6.6423, -5.3742,  ..., -6.4178, -2.9115, -4.7256],\n",
       "         [ 0.7175, -0.5091,  3.9928,  ..., -7.9788, -7.6205,  4.9763],\n",
       "         ...,\n",
       "         [-5.5664, -7.2143, -4.3619,  ..., -5.9872, -4.2362, -3.9470],\n",
       "         [-4.6896, -7.0620, -4.6667,  ..., -4.0880, -2.3270, -4.1369],\n",
       "         [-5.3693, -6.8012, -4.3338,  ..., -4.2402, -2.8999, -3.9028]],\n",
       "\n",
       "        [[-4.0691, -6.0871, -4.8903,  ..., -6.6920, -3.4899, -1.5123],\n",
       "         [-3.8839, -6.4442, -4.5848,  ..., -4.6295, -2.6610, -2.9855],\n",
       "         [-4.6197, -6.3771, -3.9330,  ..., -4.7169, -2.1266, -2.8034],\n",
       "         ...,\n",
       "         [-3.6946, -5.7839, -4.1050,  ..., -3.6339, -3.0817, -2.7614],\n",
       "         [-3.5686, -5.4104, -3.5697,  ..., -4.8652, -2.6640, -2.2420],\n",
       "         [-2.2415, -4.9702, -3.0008,  ..., -5.3960, -2.2235, -1.1518]]])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    torch_out = model(torch_array)[0]\n",
    "torch_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "difference in inputs: 0\n",
      "difference in logits: 6.771088e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"difference in inputs:\", get_difference(torch_array, jx_array))\n",
    "print(\"difference in logits:\", get_difference(torch_out, fx_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}