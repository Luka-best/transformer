{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.3'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import argparse\n",
    "import torch\n",
    "from transformers import MraConfig, MraForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_key(orig_key):\n",
    "    if \"model\" in orig_key:\n",
    "        orig_key = orig_key.replace(\"model.\", \"\")\n",
    "    if \"norm1\" in orig_key:\n",
    "        orig_key = orig_key.replace(\"norm1\", \"attention.output.LayerNorm\")\n",
    "    if \"norm2\" in orig_key:\n",
    "        orig_key = orig_key.replace(\"norm2\", \"output.LayerNorm\")\n",
    "    if \"norm\" in orig_key:\n",
    "        orig_key = orig_key.replace(\"norm\", \"LayerNorm\")\n",
    "    if \"transformer\" in orig_key:\n",
    "        layer_num = orig_key.split(\".\")[0].split(\"_\")[-1]\n",
    "        orig_key = orig_key.replace(f\"transformer_{layer_num}\", f\"encoder.layer.{layer_num}\")\n",
    "    if \"mha.attn\" in orig_key:\n",
    "        orig_key = orig_key.replace(\"mha.attn\", \"attention.self\")\n",
    "    if \"mha\" in orig_key:\n",
    "        orig_key = orig_key.replace(\"mha\", \"attention\")\n",
    "    if \"W_q\" in orig_key:\n",
    "        orig_key = orig_key.replace(\"W_q\", \"self.query\")\n",
    "    if \"W_k\" in orig_key:\n",
    "        orig_key = orig_key.replace(\"W_k\", \"self.key\")\n",
    "    if \"W_v\" in orig_key:\n",
    "        orig_key = orig_key.replace(\"W_v\", \"self.value\")\n",
    "    if \"ff.0\" in orig_key:\n",
    "        orig_key = orig_key.replace(\"ff.0\", \"intermediate.dense\")\n",
    "    if \"ff.2\" in orig_key:\n",
    "        orig_key = orig_key.replace(\"ff.2\", \"output.dense\")\n",
    "    if \"ff\" in orig_key:\n",
    "        orig_key = orig_key.replace(\"ff\", \"output.dense\")\n",
    "    if \"mlm_class\" in orig_key:\n",
    "        orig_key = orig_key.replace(\"mlm.mlm_class\", \"cls.predictions.decoder\")\n",
    "    if \"mlm\" in orig_key:\n",
    "        orig_key = orig_key.replace(\"mlm\", \"cls.predictions.transform\")\n",
    "    if \"backbone.backbone.encoders\" in orig_key:\n",
    "        orig_key = orig_key.replace(\"backbone.backbone.encoders\", \"encoder.layer\")\n",
    "    if \"cls\" not in orig_key:\n",
    "        orig_key = \"mra.\" + orig_key\n",
    "\n",
    "    return orig_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_checkpoint_helper(max_position_embeddings, orig_state_dict):\n",
    "    for key in orig_state_dict.copy().keys():\n",
    "        val = orig_state_dict.pop(key)\n",
    "\n",
    "        if (\"pooler\" in key) or (\"sen_class\" in key):\n",
    "            continue\n",
    "        else:\n",
    "            orig_state_dict[rename_key(key)] = val\n",
    "\n",
    "    orig_state_dict[\"cls.predictions.bias\"] = orig_state_dict[\"cls.predictions.decoder.bias\"]\n",
    "    orig_state_dict[\"mra.embeddings.position_ids\"] = torch.arange(max_position_embeddings).expand((1, -1)) + 2\n",
    "\n",
    "    return orig_state_dict\n",
    "\n",
    "\n",
    "def convert_mra_checkpoint(checkpoint_path, mra_config_file, pytorch_dump_path):\n",
    "    orig_state_dict = torch.load(checkpoint_path, map_location=\"cpu\")[\"model_state_dict\"]\n",
    "    \n",
    "    with open(mra_config_file) as file:\n",
    "        config_dict = json.load(file)['model']\n",
    "        \n",
    "    config_dict['max_position_embeddings'] = config_dict.pop('max_seq_len')\n",
    "    \n",
    "    config = MraConfig.from_dict(config_dict)\n",
    "    print(config)\n",
    "    model = MraForMaskedLM(config)\n",
    "\n",
    "    new_state_dict = convert_checkpoint_helper(config.max_position_embeddings, orig_state_dict)\n",
    "\n",
    "    print(model.load_state_dict(new_state_dict))\n",
    "    model.eval()\n",
    "    model.save_pretrained(pytorch_dump_path)\n",
    "\n",
    "    print(f\"Checkpoint successfuly converted. Model saved at {pytorch_dump_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmp = \"D:/mra-2-4096-8-d3.model\"\n",
    "cfg = \"D:/config_4096.json\"\n",
    "pdp = \"C:/Users/prana/Desktop/mra-base-4096-8-d3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MraConfig {\n",
      "  \"approx_mode\": \"full\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"block_per_row\": 8,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"dim\": 768,\n",
      "  \"dropout_prob\": 0.1,\n",
      "  \"embedding_dim\": 768,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initial_prior_diagonal_n_blocks\": 1,\n",
      "  \"initial_prior_first_n_blocks\": 3,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"mixed_precision\": true,\n",
      "  \"model_type\": \"mra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_head\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"num_sen_type\": 1,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"shared_weight\": false,\n",
      "  \"transformers_version\": \"4.31.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "<All keys matched successfully>\n",
      "Checkpoint successfuly converted. Model saved at C:/Users/prana/Desktop/mra-base-4096-8-d3\n"
     ]
    }
   ],
   "source": [
    "convert_mra_checkpoint(pmp, cfg, pdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
