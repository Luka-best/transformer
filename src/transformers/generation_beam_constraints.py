from abc import ABC, abstractmethod
from typing import List, Optional, Union

import torch

from .file_utils import add_start_docstrings


TOKEN_CONSTRAINT_DOCSTRING = r"""
    [`Constraint`] enforcing that a specific token is included in the output.

    Args:
        token_ids (`torch.LongTensor`):
            The sequence of tokens that must be generated by the output.
"""

PHRASAL_CONSTRAINT_DOCSTRING = r"""
    [`Constraint`] enforcing that an ordered sequence of tokens is included in the output.

    Args:
        token_id (`int`):
            The id of the token that must be generated by the output.
"""


class Constraint(ABC):
    r"""Abstract base class for all constraints that can be applied during generation.
    It must define how the constraint can be satisfied.

    All classes that inherit Constraint must follow the requirement that

    ```
    completed = False
    while(not completed):
        _, completed = constraint.update(constraint.advance())
    ```

    will always terminate (halt).
    """

    def __init__(self):
        # test for the above condition
        self.test()

    def test(self):
        """
        Tests whether this constraint has been properly defined.
        """
        counter = 0
        completed = False
        while not completed:
            if counter == 1:
                self.reset()
            advance = self.advance()
            assert self.does_advance(advance)
            stepped, completed, reset = self.update(advance)
            counter += 1

            if counter > 10000:
                raise Exception("update() does not fulfill the constraint.")

        assert self.remaining() == 0

    @abstractmethod
    def advance(self):
        """
        When called, returns the token that would take this constraint one step closer to being fulfilled.

        returns:
            token_ids(`torch.tensor`): Must be a tensor of a list of indexable tokens, not some integer.
        """
        raise NotImplementedError(
            f"{self.__class__} is an abstract class. Only classes inheriting this class can be called."
        )

    @abstractmethod
    def does_advance(self, token_id: int):
        """
        Reads in a token and returns whether it creates progress.
        """
        raise NotImplementedError(
            f"{self.__class__} is an abstract class. Only classes inheriting this class can be called."
        )

    @abstractmethod
    def update(self, token_id: int):
        """
        Reads in a token and returns booleans that indicate the progress made by it. This function will update the
        state of this object unlikes `does_advance(self, token_id: int)`.

        This isn't to test whether a certain token will advance the progress; it's to update its state as if it has
        been generated. This becomes important if token_id != desired token (refer to else statement in
        PhrasalConstraint)

        Args:
            token_id(`int`):
                The id of a newly generated token in the beam search.
        returns:
            stepped(`boolean`):
                Whether this constraint has become one step closer to being fulfuilled.
            completed(`boolean`):
                Whether this constraint has been completely fulfilled by this token being generated.
            reset (`boolean`):
                Whether this constraint has reset its progress by this token being generated.
        """
        raise NotImplementedError(
            f"{self.__class__} is an abstract class. Only classes inheriting this class can be called."
        )

    @abstractmethod
    def reset(self):
        """
        Resets the state of this constraint to its initialization. We would call this in cases where the fulfillment of
        a constraint is abrupted by an unwanted token.
        """
        raise NotImplementedError(
            f"{self.__class__} is an abstract class. Only classes inheriting this class can be called."
        )

    @abstractmethod
    def remaining(self):
        """
        Returns the number of remaining steps of `advance()` in order to complete this constraint.
        """
        raise NotImplementedError(
            f"{self.__class__} is an abstract class. Only classes inheriting this class can be called."
        )

    @abstractmethod
    def copy(self, stateful=False):
        """
        Creates a new instance of this constraint.

        Args:
            stateful(`boolean`): Whether to not only copy the constraint for new instance, but also its state.
        Returns:
            constraint(`Constraint`): The same constraint as the one being called from.
        """
        raise NotImplementedError(
            f"{self.__class__} is an abstract class. Only classes inheriting this class can be called."
        )


class TokenConstraint(Constraint):
    r"""
    [`Constraint`] enforcing that a specific token is generated.

    Args:
        token_id (`int`):
            The token that must be generated by the output.
    """

    @add_start_docstrings(TOKEN_CONSTRAINT_DOCSTRING)
    def __init__(self, token_id: int):
        super(Constraint, self).__init__()
        if not (isinstance(token_id, int) or isinstance(token_id, torch.LongTensor)) or token_id < 0:
            raise ValueError(
                f"`token_id` has to be a positive integer or a `torch.LongTensor` with one positive integer, but is {token_id}"
            )
        else:
            if isinstance(token_id, torch.LongTensor) and token_id.size(0) > 1:
                raise ValueError(
                    f"`token_id` has to be a positive integer or a `torch.LongTensor` with one integer, but is {token_id}."
                    "For sequential constraints for multiple tokens, refer to `PhrasalConstraint`."
                )

        self.token_id = token_id
        self.token_ids = token_id  # for compatibility reasons
        self.completed = False

    def advance(self):
        return self.token_id

    def does_advance(self, token_id: Union[int, torch.LongTensor]):
        return token_id == self.token_id

    def update(self, token_id: Union[int, torch.LongTensor]):
        if not isinstance(token_id, int) or token_id < 0:
            raise ValueError(f"`token_id` has to be a positive integer, but is {token_id}")

        if self.does_advance(token_id):
            self.completed = True
            return True, True, True  # stepped, completed, reset
        else:
            return False, False, False

    def reset(self):
        self.completed = False

    def remaining(self):
        return 0 if self.completed else 1

    def copy(self, stateful=False):
        constraint = TokenConstraint(self.token_id)
        if stateful:
            constraint.completed = self.completed
        return constraint


class PhrasalConstraint(Constraint):
    @add_start_docstrings(PHRASAL_CONSTRAINT_DOCSTRING)
    def __init__(self, token_ids: Union[List[int], torch.LongTensor]):
        super(Constraint, self).__init__()

        is_int_list = isinstance(token_ids, List) and isinstance(token_ids[0], int)
        is_long_tensor = isinstance(token_ids, torch.LongTensor) and len(token_ids.size()) == 1
        if not (is_int_list or is_long_tensor) or torch.any(token_ids < 0):
            raise ValueError(
                f"`token_ids` has to be a single list of positive integers or a `torch.LongTensor` but is {token_ids}"
            )
        else:
            if (is_int_list or is_long_tensor) and token_ids.size(0) == 1:
                raise ValueError(
                    f"`token_ids` has to be list of positive integers or a `torch.LongTensor` but is {token_ids}"
                    "For single token constraints, refer to `TokenConstraint`."
                )

        self.token_ids = token_ids

        self.seqlen = self.token_ids.size(0)
        self.fulfilled_idx = -1  # the index of the currently fulfilled step
        self.completed = False

    def advance(self):
        return self.token_ids[self.fulfilled_idx + 1]

    def does_advance(self, token_id: int):
        if self.completed:
            return False
        return token_id.cpu() == self.token_ids[self.fulfilled_idx + 1]

    def update(self, token_id: int):
        stepped = False
        completed = False
        reset = False

        if self.does_advance(token_id):
            self.fulfilled_idx += 1
            stepped = True
            if self.fulfilled_idx == (self.seqlen - 1):
                completed = True
            self.completed = completed
        else:
            # failed to make progress.
            reset = True
            self.reset()
        return stepped, completed, reset

    def reset(self):
        self.completed = False
        self.fulfilled_idx = 0

    def remaining(self):
        return self.seqlen - (self.fulfilled_idx + 1)

    def copy(self, stateful=False):
        new_constraint = PhrasalConstraint(self.token_ids)

        if stateful:
            new_constraint.seq_len = self.seqlen
            new_constraint.fulfilled_idx = self.fulfilled_idx
            new_constraint.completed = self.completed

        return new_constraint


# For beam scorers to track its progress through a list of constraints.
class ConstraintListState:
    def __init__(self, constraints: List[Constraint]):
        self.constraints = constraints

        # max # of steps required to fulfill a given constraint
        self.max_seqlen = max([c.seqlen for c in constraints])
        self.n_constraints = len(constraints)
        self.completed = False

        self.init_state()

    def init_state(self):
        self.complete_constraints = []
        self.inprogress_constraint = None
        self.pending_constraints = [constraint.copy(stateful=False) for constraint in self.constraints]

    def get_bank(self):
        add = 0
        if self.inprogress_constraint:
            # extra points for having a constraint mid-fulfilled
            add += self.max_seqlen - self.inprogress_constraint.remaining()

        return (len(self.complete_constraints) * self.max_seqlen) + add

    def advance(self):
        """The list of tokens to generate such that we can make progress.
        By "list" we don't mean the list of token that will fully fulfill a constraint.

        Given constraints c_i = {t_ij | j == # of tokens}, If we're not in the middle of progressing through a specific
        constraint c_i, we return:

            [t_k1 for k in indices of unfulfilled constraints]

        If we are in the middle of a constraint, then we return:
            [t_ij], where i == index of the inprogress constraint, j == the next step for the constraint.

        Though we don't care which constraint is fulfilled first, if we are in the progress of fulfilling a constraint,
        that's the only one we'll return.
        """
        if self.inprogress_constraint is None:
            token_list = []
            for constraint in self.pending_constraints:  # "pending" == "unfulfilled yet"
                advance = constraint.advance()
                token_list.append(advance)
        else:
            token_list = [self.inprogress_constraint.advance()]

        if len(token_list) == 0:
            return None
        else:
            return torch.stack(token_list)

    def reset(self, token_ids: Optional[torch.LongTensor]):
        """
        token_ids: the tokens generated thus far to reset the state of the progress through constraints.
        """
        self.init_state()

        if token_ids is not None and token_ids.size(0) > 0:
            for token in token_ids:
                complete, stepped = self.add(token)
                if complete:
                    break

        return self

    def add(self, token_id: Union[int, torch.LongTensor]):
        complete, stepped = False, False

        # if isinstance(token_id, torch.LongTensor):
        #     if (token_id.size(0)) > 1:
        #         raise ValueError(
        #             f"`token_id` has to be a positive integer or a `torch.LongTensor` with one integer, but is {token_id}."
        #             "It must have length 1."
        #         )
        #     else:
        #         token_id = token_id[0]

        if self.completed:
            complete = True
            stepped = False
            return complete, stepped

        if self.inprogress_constraint is not None:
            """
            In the middle of fulfilling a constraint. If the `token_id` *does* makes an incremental progress to current
            job, simply update the state
            """
            stepped, complete, reset = self.inprogress_constraint.update(token_id)
            if reset:
                """
                1. If the next token breaks the progress, then we must restart.
                    e.g. constraint = "I love pies" and sequence so far is "I love" but `token_id` == "books".

                    But that doesn't mean we self.init_state(), since we only reset the state for this particular
                    constraint, not the full list of constraints.
                """
                self.pending_constraints.append(self.inprogress_constraint.copy(stateful=False))
                self.inprogress_constraint = None

            if complete:
                """
                2. If the next token completes the constraint, move it to completed list, set
                    inprogress to None. If there are no pending constraints either, then this full list of constraints
                    is complete.
                """
                self.complete_constraints.append(self.inprogress_constraint)
                self.inprogress_constraint = None

                if len(self.pending_constraints) == 0:
                    # we're done!
                    self.completed = True

        else:
            """
            Not in the middle of fulfilling a constraint. So does this `token_id` helps us step towards any of our list
            of constraints?
            """
            for cidx, pending_constraint in enumerate(self.pending_constraints):
                if pending_constraint.does_advance(token_id):
                    stepped, complete, reset = pending_constraint.update(token_id)

                    if not stepped:
                        raise Exception(
                            "constraint.update(token_id) is not yielding incremental progress, "
                            "even though constraint.does_advance(token_id) is true."
                        )

                    if complete:
                        self.complete_constraints.append(pending_constraint)
                        self.inprogress_constraint = None

                    if not complete and stepped:
                        self.inprogress_constraint = pending_constraint

                    if complete or stepped:
                        """
                        If we made any progress at all, then it's at least not a "pending constraint".
                        """
                        self.pending_constraints = (
                            self.pending_constraints[:cidx] + self.pending_constraints[cidx + 1 :]
                        )

                        if len(self.pending_constraints) == 0 and self.inprogress_constraint is None:
                            """
                            If there's no longer any pending after this and no inprogress either, then we must be
                            complete.
                            """
                            self.completed = True

                        break  # prevent accidentally stepping through multiple constraints with just one token.

        return complete, stepped

    def copy(self, stateful=True):
        new_state = ConstraintListState(self.constraints)  # we actually never though self.constraints objects
        # throughout this process. So it's at initialization state.

        if stateful:
            new_state.complete_constraints = [
                constraint.copy(stateful=True) for constraint in self.complete_constraints
            ]
            if self.inprogress_constraint is not None:
                new_state.inprogress_constraint = self.inprogress_constraint.copy(stateful=True)
            new_state.pending_constraints = [constraint.copy() for constraint in self.pending_constraints]

        return new_state
