<!--Copyright 2020 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

# 🤗 Transformers

Υπερσύγχρονο Machine Learning για [PyTorch](https://pytorch.org/), [TensorFlow](https://www.tensorflow.org/), and [JAX](https://jax.readthedocs.io/en/latest/).

🤗 Το Transformers παρέχει APIs και εργαλεία για να κατεβάσετε και να εκπαιδεύσετε υπερσύγχρονα προ-εκπαιδευμένα μοντέλα. Η χρήση προ-εκπαιδευμένων μοντέλων μπορεί να μειώσει το υπολογιστικό σας κόστος, το αποτύπωμα διοξεδίου του άνθρακα, και να σας γλιτώσει τους πόρους και τον χρόνο που απαιτείται για την εκπαίδευση ενός μοντέλου από μηδέν. Τα μοντέλα αυτά υποστηρίζουν συνηθισμένα καθήκοντα(tasks) με διαφορετικούς τρόπους, όπως:

📝 **Επεξεργασία Φυσικής Γλώσσας**: κατηγοριοποίηση κειμένου, ονομαστική αναγνώριση οντοτήτων, απάντηση σε ερωτήσεις, γλωσσική μοντελοποίηση, περίληψη, μετάφραση, πολλαπλή επιλογή, και παραγωγή κειμένου.</br>
🖼️ **Όραση Υπολογιστή**: κατηγοριοποίηση εικόνας, αναγνώριση αντικειμένων, και κατάτμηση.<br>
🗣️ **Ήχος**: αυτόματη αναγνώριση ομιλίας και κατηγοριοποίηση ήχου.<br>
🐙 **Πολυτροπικά**: απάντηση ερωτήσεων από πίνακες, οπτική αναγνώριση χαρακτήρων, εξαγωγή πληροφορίας από σκαναρισμένα έγγραφα, κατηγοριοποίηση βίντεο, και οπτική απάντηση σε ερωτήσεις.<br>

🤗 Το Transformers υποστηρίζει διαλειτουργικότητα framework ανάμεσα στα PyTorch, TensorFlow, and JAX. Αυτό μας δίνει την ελευθερία της χρήσης διαφορετικού framework σε κάθε στάδιο της "ζωής" ενός μοντέλου; Εκπαιδεύστε ένα μοντέλο με τρείς γραμμές κώδικα σε ένα framework και φορτώστε το για συμπεράσματα σε ένα άλλο. Τα μοντέλα μπορούν επίσης να εξαχθούν σε format όπως ONNX και TorchScript για deployment σε περιβάλλοντα production.

Γίνε μέλος της συνεχώς αυξανόμενης κοινότητας στό [Hub](https://huggingface.co/models), [forum](https://discuss.huggingface.co/), ή [Discord](https://discord.com/invite/JfAtkvEtRb) σήμερα!

## Αν ψάχνεις εξατομικευμένη υποστίριξη απο την ομάδα του Hugging Face

<a target="_blank" href="https://huggingface.co/support">
    <img alt="HuggingFace Expert Acceleration Program" src="https://cdn-media.huggingface.co/marketing/transformers/new-support-improved.png" style="max-width: 600px; border: 1px solid #eee; border-radius: 4px; box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.05);">
</a>
</br>

## Περιεχόμενα

Η τεκμηρίωση είναι οργανωμένη σε πέντε ενότητες:

- **ΞΕΚΙΝΩΝΤΑΣ** παρέχει μια γρήγορη περιήγηση της βιβλιοθήκης καθώς και οδηγίες εγκατάστασης για την εκτέλεση της.
- **TUTORIALS** είναι το καλύτερο μέρος να ξεκινήσεις ώς αρχάριος. Αυτή η ενότητα θα σε βοηθήσει να πάρεις τις βασικές δεξιότητες που χρειάζονται για να αρχίσεις να χρησιμοποιείς την βιβλιοθήκη.
- **ΟΔΗΓΟΙ HOW-TO** σου δείχνουν πως μπορείς να πετύχεις έναν συγκεκριμένο στόχο, όπως η προσαρμογή ενός προ-εκπαιδευμένου μοντέλου για μοντελοποίηση γλώσσας ή το πώς να γράψεις και να μοιραστείς ένα custom μοντέλο.
- **ΕΝΝΟΙΟΛΟΓΙΚΟΣ ΟΔΗΓΟΣ** προσφέρει μεγαλύτερη εξήγηση των υποκείμενων εννοιών και ιδεών πίσω από τα μοντέλα, tasks, και την φιλοσοφία σχεδιασμού του 🤗 Transformers.
- **API** describes all classes and functions:

  - **ΒΑΣΙΚΕΣ ΚΛΑΣΕΙΣ** περιγράφει με λεπτομέρια τις πιο σημαντικές κλάσεις του συστήματος όπως configuration, model, tokenizer, και pipeline.
  - **ΜΟΝΤΕΛΑ** περιγράφει τις κλάσεις και τις λειτουργίες που σχετίζονται με κάθε μοντέλο που υλοποιήται στην βιβλιοθήκη.
  - **ΕΣΩΤΕΡΙΚΟΙ ΒΟΗΘΟΙ** περιγράφει τις εσωτερικές κλάσεις και μεθόδους χρηστικότητας.

### Υποστηριζόμενα Μοντέλα

<!--This list is updated automatically from the README with _make fix-copies_. Do not update manually! -->

1. **[ALBERT](model_doc/albert)** (από Google Research και την Toyota Technological Institute στο Σικάγο) κυκλοφόρησε με την εργασία [ALBERT: A Lite BERT for Self-supervised Learning of Language Representations](https://arxiv.org/abs/1909.11942), από τους Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut.
1. **[BART](model_doc/bart)** (από Facebook) κυκλοφόρησε με την εργασία [BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension](https://arxiv.org/abs/1910.13461) από τους Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov and Luke Zettlemoyer.
1. **[BARThez](model_doc/barthez)** (από École polytechnique) κυκλοφόρησε με την εργασία [BARThez: a Skilled Pretrained French Sequence-to-Sequence Model](https://arxiv.org/abs/2010.12321) από τους Moussa Kamal Eddine, Antoine J.-P. Tixier, Michalis Vazirgiannis.
1. **[BARTpho](model_doc/bartpho)** (από VinAI Research) κυκλοφόρησε με την εργασία [BARTpho: Pre-trained Sequence-to-Sequence Models for Vietnamese](https://arxiv.org/abs/2109.09701) από τους Nguyen Luong Tran, Duong Minh Le and Dat Quoc Nguyen.
1. **[BEiT](model_doc/beit)** (από Microsoft) κυκλοφόρησε με την εργασία [BEiT: BERT Pre-Training of Image Transformers](https://arxiv.org/abs/2106.08254) από τους Hangbo Bao, Li Dong, Furu Wei.
1. **[BERT](model_doc/bert)** (από Google) κυκλοφόρησε με την εργασία [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805) από τους Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova.
1. **[BERT For Sequence Generation](model_doc/bert-generation)** (από Google) κυκλοφόρησε με την εργασία [Leveraging Pre-trained Checkpoints for Sequence Generation Tasks](https://arxiv.org/abs/1907.12461) από τους Sascha Rothe, Shashi Narayan, Aliaksei Severyn.
1. **[BERTweet](model_doc/bertweet)** (από VinAI Research) κυκλοφόρησε με την εργασία [BERTweet: A pre-trained language model for English Tweets](https://aclanthology.org/2020.emnlp-demos.2/) από τους Dat Quoc Nguyen, Thanh Vu and Anh Tuan Nguyen.
1. **[BigBird-Pegasus](model_doc/bigbird_pegasus)** (από Google Research) κυκλοφόρησε με την εργασία [Big Bird: Transformers for Longer Sequences](https://arxiv.org/abs/2007.14062) από τους Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.
1. **[BigBird-RoBERTa](model_doc/big_bird)** (από Google Research) κυκλοφόρησε με την εργασία [Big Bird: Transformers for Longer Sequences](https://arxiv.org/abs/2007.14062) από τους Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.
1. **[Blenderbot](model_doc/blenderbot)** (από Facebook) κυκλοφόρησε με την εργασία [Recipes for building an open-domain chatbot](https://arxiv.org/abs/2004.13637) από τους Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.
1. **[BlenderbotSmall](model_doc/blenderbot-small)** (από Facebook) κυκλοφόρησε με την εργασία [Recipes for building an open-domain chatbot](https://arxiv.org/abs/2004.13637) από τους Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.
1. **[BLOOM](model_doc/bloom)** (από BigScience workshop) κυκλοφόρησε από το [BigSicence Workshop](https://bigscience.huggingface.co/).
1. **[BORT](model_doc/bort)** (από Alexa) κυκλοφόρησε με την εργασία [Optimal Subarchitecture Extraction For BERT](https://arxiv.org/abs/2010.10499) από τους Adrian de Wynter and Daniel J. Perry.
1. **[ByT5](model_doc/byt5)** (από Google Research) κυκλοφόρησε με την εργασία [ByT5: Towards a token-free future with pre-trained byte-to-byte models](https://arxiv.org/abs/2105.13626) από τους Linting Xue, Aditya Barua, Noah Constant, Rami Al-Rfou, Sharan Narang, Mihir Kale, Adam Roberts, Colin Raffel.
1. **[CamemBERT](model_doc/camembert)** (από Inria/Facebook/Sorbonne) κυκλοφόρησε με την εργασία [CamemBERT: a Tasty French Language Model](https://arxiv.org/abs/1911.03894) από τους Louis Martin*, Benjamin Muller*, Pedro Javier Ortiz Suárez*, Yoann Dupont, Laurent Romary, Éric Villemonte de la Clergerie, Djamé Seddah and Benoît Sagot.
1. **[CANINE](model_doc/canine)** (από Google Research) κυκλοφόρησε με την εργασία [CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation](https://arxiv.org/abs/2103.06874) από τους Jonathan H. Clark, Dan Garrette, Iulia Turc, John Wieting.
1. **[CLIP](model_doc/clip)** (από OpenAI) κυκλοφόρησε με την εργασία [Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/abs/2103.00020) από τους Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever.
1. **[CodeGen](model_doc/codegen)** (από Salesforce) κυκλοφόρησε με την εργασία [A Conversational Paradigm for Program Synthesis](https://arxiv.org/abs/2203.13474) από τους Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, Caiming Xiong.
1. **[Conditional DETR](model_doc/conditional_detr)** (από Microsoft Research Ασία) κυκλοφόρησε με την εργασία [Conditional DETR for Fast Training Convergence](https://arxiv.org/abs/2108.06152) από τους Depu Meng, Xiaokang Chen, Zejia Fan, Gang Zeng, Houqiang Li, Yuhui Yuan, Lei Sun, Jingdong Wang.
1. **[ConvBERT](model_doc/convbert)** (από YituTech) κυκλοφόρησε με την εργασία [ConvBERT: Improving BERT with Span-based Dynamic Convolution](https://arxiv.org/abs/2008.02496) από τους Zihang Jiang, Weihao Yu, Daquan Zhou, Yunpeng Chen, Jiashi Feng, Shuicheng Yan.
1. **[ConvNeXT](model_doc/convnext)** (από Facebook AI) κυκλοφόρησε με την εργασία [A ConvNet for the 2020s](https://arxiv.org/abs/2201.03545) από τους Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, Saining Xie.
1. **[CPM](model_doc/cpm)** (από Tsinghua University) κυκλοφόρησε με την εργασία [CPM: A Large-scale Generative Chinese Pre-trained Language Model](https://arxiv.org/abs/2012.00413) από τους Zhengyan Zhang, Xu Han, Hao Zhou, Pei Ke, Yuxian Gu, Deming Ye, Yujia Qin, Yusheng Su, Haozhe Ji, Jian Guan, Fanchao Qi, Xiaozhi Wang, Yanan Zheng, Guoyang Zeng, Huanqi Cao, Shengqi Chen, Daixuan Li, Zhenbo Sun, Zhiyuan Liu, Minlie Huang, Wentao Han, Jie Tang, Juanzi Li, Xiaoyan Zhu, Maosong Sun.
1. **[CTRL](model_doc/ctrl)** (από Salesforce) κυκλοφόρησε με την εργασία [CTRL: A Conditional Transformer Language Model for Controllable Generation](https://arxiv.org/abs/1909.05858) από τους Nitish Shirish Keskar*, Bryan McCann*, Lav R. Varshney, Caiming Xiong and Richard Socher.
1. **[CvT](model_doc/cvt)** (από Microsoft) κυκλοφόρησε με την εργασία [CvT: Introducing Convolutions to Vision Transformers](https://arxiv.org/abs/2103.15808) από τους Haiping Wu, Bin Xiao, Noel Codella, Mengchen Liu, Xiyang Dai, Lu Yuan, Lei Zhang.
1. **[Data2Vec](model_doc/data2vec)** (από Facebook) κυκλοφόρησε με την εργασία [Data2Vec:  A General Framework for Self-supervised Learning in Speech, Vision and Language](https://arxiv.org/abs/2202.03555) από τους Alexei Baevski, Wei-Ning Hsu, Qiantong Xu, Arun Babu, Jiatao Gu, Michael Auli.
1. **[DeBERTa](model_doc/deberta)** (από Microsoft) κυκλοφόρησε με την εργασία [DeBERTa: Decoding-enhanced BERT with Disentangled Attention](https://arxiv.org/abs/2006.03654) από τους Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.
1. **[DeBERTa-v2](model_doc/deberta-v2)** (από Microsoft) κυκλοφόρησε με την εργασία [DeBERTa: Decoding-enhanced BERT with Disentangled Attention](https://arxiv.org/abs/2006.03654) από τους Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.
1. **[Decision Transformer](model_doc/decision_transformer)** (από Berkeley/Facebook/Google) κυκλοφόρησε με την εργασία [Decision Transformer: Reinforcement Learning via Sequence Modeling](https://arxiv.org/abs/2106.01345) από τους Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Michael Laskin, Pieter Abbeel, Aravind Srinivas, Igor Mordatch.
1. **[Deformable DETR](model_doc/deformable_detr)** (από SenseTime Research) κυκλοφόρησε με την εργασία [Deformable DETR: Deformable Transformers for End-to-End Object Detection](https://arxiv.org/abs/2010.04159) από τους Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, Jifeng Dai.
1. **[DeiT](model_doc/deit)** (από Facebook) κυκλοφόρησε με την εργασία [Training data-efficient image transformers & distillation through attention](https://arxiv.org/abs/2012.12877) από τους Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, Hervé Jégou.
1. **[DETR](model_doc/detr)** (από Facebook) κυκλοφόρησε με την εργασία [End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872) από τους Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko.
1. **[DialoGPT](model_doc/dialogpt)** (από Microsoft Research) κυκλοφόρησε με την εργασία [DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation](https://arxiv.org/abs/1911.00536) από τους Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, Bill Dolan.
1. **[DistilBERT](model_doc/distilbert)** (από HuggingFace), κυκλοφόρησε μαζί με την εργασία [DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter](https://arxiv.org/abs/1910.01108) από τους Victor Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied to compress GPT2 into [DistilGPT2](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation), RoBERTa into [DistilRoBERTa](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation), Multilingual BERT into [DistilmBERT](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation) and a German version of DistilBERT.
1. **[DiT](model_doc/dit)** (από Microsoft Research) κυκλοφόρησε με την εργασία [DiT: Self-supervised Pre-training for Document Image Transformer](https://arxiv.org/abs/2203.02378) από τους Junlong Li, Yiheng Xu, Tengchao Lv, Lei Cui, Cha Zhang, Furu Wei.
1. **[Donut](model_doc/donut)** (από NAVER), κυκλοφόρησε μαζί με την εργασία [OCR-free Document Understanding Transformer](https://arxiv.org/abs/2111.15664) από τους Geewook Kim, Teakgyu Hong, Moonbin Yim, Jeongyeon Nam, Jinyoung Park, Jinyeong Yim, Wonseok Hwang, Sangdoo Yun, Dongyoon Han, Seunghyun Park.
1. **[DPR](model_doc/dpr)** (από Facebook) κυκλοφόρησε με την εργασία [Dense Passage Retrieval for Open-Domain Question Answering](https://arxiv.org/abs/2004.04906) από τους Vladimir Karpukhin, Barlas Oğuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.
1. **[DPT](master/model_doc/dpt)** (από Intel Labs) κυκλοφόρησε με την εργασία [Vision Transformers for Dense Prediction](https://arxiv.org/abs/2103.13413) από τους René Ranftl, Alexey Bochkovskiy, Vladlen Koltun.
1. **[ELECTRA](model_doc/electra)** (από Google Research/Stanford University) κυκλοφόρησε με την εργασία [ELECTRA: Pre-training text encoders as discriminators rather than generators](https://arxiv.org/abs/2003.10555) από τους Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning.
1. **[EncoderDecoder](model_doc/encoder-decoder)** (από Google Research) κυκλοφόρησε με την εργασία [Leveraging Pre-trained Checkpoints for Sequence Generation Tasks](https://arxiv.org/abs/1907.12461) από τους Sascha Rothe, Shashi Narayan, Aliaksei Severyn.
1. **[ERNIE](model_doc/ernie)** (από Baidu) κυκλοφόρησε με την εργασία [ERNIE: Enhanced Representation through Knowledge Integration](https://arxiv.org/abs/1904.09223) από τους Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen, Han Zhang, Xin Tian, Danxiang Zhu, Hao Tian, Hua Wu.
1. **[ESM](model_doc/esm)** (από Meta AI) are transformer protein language models.  **ESM-1b** was κυκλοφόρησε με την εργασία [Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences](https://www.pnas.org/content/118/15/e2016239118) από τους Alexander Rives, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, Myle Ott, C. Lawrence Zitnick, Jerry Ma, and Rob Fergus. **ESM-1v** was κυκλοφόρησε με την εργασία [Language models enable zero-shot prediction of the effects of mutations on protein function](https://doi.org/10.1101/2021.07.09.450648) από τους Joshua Meier, Roshan Rao, Robert Verkuil, Jason Liu, Tom Sercu and Alexander Rives. **ESM-2** was κυκλοφόρησε με την εργασία [Language models of protein sequences at the scale of evolution enable accurate structure prediction](https://doi.org/10.1101/2022.07.20.500902) από τους Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan dos Santos Costa, Maryam Fazel-Zarandi, Tom Sercu, Sal Candido, Alexander Rives.
1. **[FlauBERT](model_doc/flaubert)** (από CNRS) κυκλοφόρησε με την εργασία [FlauBERT: Unsupervised Language Model Pre-training for French](https://arxiv.org/abs/1912.05372) από τους Hang Le, Loïc Vial, Jibril Frej, Vincent Segonne, Maximin Coavoux, Benjamin Lecouteux, Alexandre Allauzen, Benoît Crabbé, Laurent Besacier, Didier Schwab.
1. **[FLAVA](model_doc/flava)** (από Facebook AI) κυκλοφόρησε με την εργασία [FLAVA: A Foundational Language And Vision Alignment Model](https://arxiv.org/abs/2112.04482) από τους Amanpreet Singh, Ronghang Hu, Vedanuj Goswami, Guillaume Couairon, Wojciech Galuba, Marcus Rohrbach, and Douwe Kiela.
1. **[FNet](model_doc/fnet)** (από Google Research) κυκλοφόρησε με την εργασία [FNet: Mixing Tokens with Fourier Transforms](https://arxiv.org/abs/2105.03824) από τους James Lee-Thorp, Joshua Ainslie, Ilya Eckstein, Santiago Ontanon.
1. **[Funnel Transformer](model_doc/funnel)** (από CMU/Google Brain) κυκλοφόρησε με την εργασία [Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing](https://arxiv.org/abs/2006.03236) από τους Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le.
1. **[GLPN](model_doc/glpn)** (από KAIST) κυκλοφόρησε με την εργασία [Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth](https://arxiv.org/abs/2201.07436) από τους Doyeon Kim, Woonghyun Ga, Pyungwhan Ahn, Donggyu Joo, Sehwan Chun, Junmo Kim.
1. **[GPT](model_doc/openai-gpt)** (από OpenAI) κυκλοφόρησε με την εργασία [Improving Language Understanding by Generative Pre-Training](https://blog.openai.com/language-unsupervised/) από τους Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever.
1. **[GPT Neo](model_doc/gpt_neo)** (από EleutherAI) κυκλοφόρησε στο αποθετήριο [EleutherAI/gpt-neo](https://github.com/EleutherAI/gpt-neo) από τους Sid Black, Stella Biderman, Leo Gao, Phil Wang and Connor Leahy.
1. **[GPT NeoX](model_doc/gpt_neox)** (από EleutherAI) κυκλοφόρησε με την εργασία [GPT-NeoX-20B: An Open-Source Autoregressive Language Model](https://arxiv.org/abs/2204.06745) από τους Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, Michael Pieler, USVSN Sai Prashanth, Shivanshu Purohit, Laria Reynolds, Jonathan Tow, Ben Wang, Samuel Weinbach
1. **[GPT NeoX Japanese](model_doc/gpt_neox_japanese)** (από ABEJA) κυκλοφόρησε από τους Shinya Otani, Takayoshi Makabe, Anuj Arora, and Kyo Hattori.
1. **[GPT-2](model_doc/gpt2)** (από OpenAI) κυκλοφόρησε με την εργασία [Language Models are Unsupervised Multitask Learners](https://blog.openai.com/better-language-models/) από τους Alec Radford*, Jeffrey Wu*, Rewon Child, David Luan, Dario Amodei** and Ilya Sutskever**.
1. **[GPT-J](model_doc/gptj)** (από EleutherAI) κυκλοφόρησε στο αποθετήριο [kingoflolz/mesh-transformer-jax](https://github.com/kingoflolz/mesh-transformer-jax/) από τους Ben Wang and Aran Komatsuzaki.
1. **[GroupViT](model_doc/groupvit)** (από UCSD, NVIDIA) κυκλοφόρησε με την εργασία [GroupViT: Semantic Segmentation Emerges from Text Supervision](https://arxiv.org/abs/2202.11094) από τους Jiarui Xu, Shalini De Mello, Sifei Liu, Wonmin Byeon, Thomas Breuel, Jan Kautz, Xiaolong Wang.
1. **[Hubert](model_doc/hubert)** (από Facebook) κυκλοφόρησε με την εργασία [HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units](https://arxiv.org/abs/2106.07447) από τους Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, Abdelrahman Mohamed.
1. **[I-BERT](model_doc/ibert)** (από Berkeley) κυκλοφόρησε με την εργασία [I-BERT: Integer-only BERT Quantization](https://arxiv.org/abs/2101.01321) από τους Sehoon Kim, Amir Gholami, Zhewei Yao, Michael W. Mahoney, Kurt Keutzer.
1. **[ImageGPT](model_doc/imagegpt)** (από OpenAI) κυκλοφόρησε με την εργασία [Generative Pretraining from Pixels](https://openai.com/blog/image-gpt/) από τους Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, Ilya Sutskever.
1. **[LayoutLM](model_doc/layoutlm)** (από Microsoft Research Asia) κυκλοφόρησε με την εργασία [LayoutLM: Pre-training of Text and Layout for Document Image Understanding](https://arxiv.org/abs/1912.13318) από τους Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, Ming Zhou.
1. **[LayoutLMv2](model_doc/layoutlmv2)** (από Microsoft Research Asia) κυκλοφόρησε με την εργασία [LayoutLMv2: Multi-modal Pre-training for Visually-Rich Document Understanding](https://arxiv.org/abs/2012.14740) από τους Yang Xu, Yiheng Xu, Tengchao Lv, Lei Cui, Furu Wei, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Wanxiang Che, Min Zhang, Lidong Zhou.
1. **[LayoutLMv3](model_doc/layoutlmv3)** (από Microsoft Research Asia) κυκλοφόρησε με την εργασία [LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking](https://arxiv.org/abs/2204.08387) από τους Yupan Huang, Tengchao Lv, Lei Cui, Yutong Lu, Furu Wei.
1. **[LayoutXLM](model_doc/layoutxlm)** (από Microsoft Research Asia) κυκλοφόρησε με την εργασία [LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich Document Understanding](https://arxiv.org/abs/2104.08836) από τους Yiheng Xu, Tengchao Lv, Lei Cui, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Furu Wei.
1. **[LED](model_doc/led)** (από AllenAI) κυκλοφόρησε με την εργασία [Longformer: The Long-Document Transformer](https://arxiv.org/abs/2004.05150) από τους Iz Beltagy, Matthew E. Peters, Arman Cohan.
1. **[LeViT](model_doc/levit)** (από Meta AI) κυκλοφόρησε με την εργασία [LeViT: A Vision Transformer in ConvNet's Clothing for Faster Inference](https://arxiv.org/abs/2104.01136) από τους Ben Graham, Alaaeldin El-Nouby, Hugo Touvron, Pierre Stock, Armand Joulin, Hervé Jégou, Matthijs Douze.
1. **[LiLT](model_doc/lilt)** (από South China University of Technology) κυκλοφόρησε με την εργασία [LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding](https://arxiv.org/abs/2202.13669) από τους Jiapeng Wang, Lianwen Jin, Kai Ding.
1. **[Longformer](model_doc/longformer)** (από AllenAI) κυκλοφόρησε με την εργασία [Longformer: The Long-Document Transformer](https://arxiv.org/abs/2004.05150) από τους Iz Beltagy, Matthew E. Peters, Arman Cohan.
1. **[LongT5](model_doc/longt5)** (από Google AI) κυκλοφόρησε με την εργασία [LongT5: Efficient Text-To-Text Transformer for Long Sequences](https://arxiv.org/abs/2112.07916) από τους Mandy Guo, Joshua Ainslie, David Uthus, Santiago Ontanon, Jianmo Ni, Yun-Hsuan Sung, Yinfei Yang.
1. **[LUKE](model_doc/luke)** (από Studio Ousia) κυκλοφόρησε με την εργασία [LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention](https://arxiv.org/abs/2010.01057) από τους Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, Yuji Matsumoto.
1. **[LXMERT](model_doc/lxmert)** (από UNC Chapel Hill) κυκλοφόρησε με την εργασία [LXMERT: Learning Cross-Modality Encoder Representations from Transformers for Open-Domain Question Answering](https://arxiv.org/abs/1908.07490) από τους Hao Tan and Mohit Bansal.
1. **[M-CTC-T](model_doc/mctct)** (από Facebook) κυκλοφόρησε με την εργασία [Pseudo-Labeling For Massively Multilingual Speech Recognition](https://arxiv.org/abs/2111.00161) από τους Loren Lugosch, Tatiana Likhomanenko, Gabriel Synnaeve, and Ronan Collobert.
1. **[M2M100](model_doc/m2m_100)** (από Facebook) κυκλοφόρησε με την εργασία [Beyond English-Centric Multilingual Machine Translation](https://arxiv.org/abs/2010.11125) από τους Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov, Edouard Grave, Michael Auli, Armand Joulin.
1. **[MarianMT](model_doc/marian)** Machine translation models trained using [OPUS](http://opus.nlpl.eu/) δεδομένα από Jörg Tiedemann. The [Marian Framework](https://marian-nmt.github.io/) is being developed από τους the Microsoft Translator Team.
1. **[MarkupLM](model_doc/markuplm)** (από Microsoft Research Asia) κυκλοφόρησε με την εργασία [MarkupLM: Pre-training of Text and Markup Language for Visually-rich Document Understanding](https://arxiv.org/abs/2110.08518) από τους Junlong Li, Yiheng Xu, Lei Cui, Furu Wei.
1. **[MaskFormer](model_doc/maskformer)** (από Meta and UIUC) κυκλοφόρησε με την εργασία [Per-Pixel Classification is Not All You Need for Semantic Segmentation](https://arxiv.org/abs/2107.06278) από τους Bowen Cheng, Alexander G. Schwing, Alexander Kirillov.
1. **[mBART](model_doc/mbart)** (από Facebook) κυκλοφόρησε με την εργασία [Multilingual Denoising Pre-training for Neural Machine Translation](https://arxiv.org/abs/2001.08210) από τους Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer.
1. **[mBART-50](model_doc/mbart)** (από Facebook) κυκλοφόρησε με την εργασία [Multilingual Translation with Extensible Multilingual Pretraining and Finetuning](https://arxiv.org/abs/2008.00401) από τους Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu, Angela Fan.
1. **[Megatron-BERT](model_doc/megatron-bert)** (από NVIDIA) κυκλοφόρησε με την εργασία [Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism](https://arxiv.org/abs/1909.08053) από τους Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.
1. **[Megatron-GPT2](model_doc/megatron_gpt2)** (από NVIDIA) κυκλοφόρησε με την εργασία [Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism](https://arxiv.org/abs/1909.08053) από τους Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.
1. **[mLUKE](model_doc/mluke)** (από Studio Ousia) κυκλοφόρησε με την εργασία [mLUKE: The Power of Entity Representations in Multilingual Pretrained Language Models](https://arxiv.org/abs/2110.08151) από τους Ryokan Ri, Ikuya Yamada, and Yoshimasa Tsuruoka.
1. **[MobileBERT](model_doc/mobilebert)** (από CMU/Google Brain) κυκλοφόρησε με την εργασία [MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices](https://arxiv.org/abs/2004.02984) από τους Zhiqing Sun, Hongkun Yu, Xiaodan Song, Renjie Liu, Yiming Yang, and Denny Zhou.
1. **[MobileViT](model_doc/mobilevit)** (από Apple) κυκλοφόρησε με την εργασία [MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer](https://arxiv.org/abs/2110.02178) από τους Sachin Mehta and Mohammad Rastegari.
1. **[MPNet](model_doc/mpnet)** (από Microsoft Research) κυκλοφόρησε με την εργασία [MPNet: Masked and Permuted Pre-training for Language Understanding](https://arxiv.org/abs/2004.09297) από τους Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu.
1. **[MT5](model_doc/mt5)** (από Google AI) κυκλοφόρησε με την εργασία [mT5: A massively multilingual pre-trained text-to-text transformer](https://arxiv.org/abs/2010.11934) από τους Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, Colin Raffel.
1. **[MVP](model_doc/mvp)** (από RUC AI Box) κυκλοφόρησε με την εργασία [MVP: Multi-task Supervised Pre-training for Natural Language Generation](https://arxiv.org/abs/2206.12131) από τους Tianyi Tang, Junyi Li, Wayne Xin Zhao and Ji-Rong Wen.
1. **[Nezha](model_doc/nezha)** (από Huawei Noah’s Ark Lab) κυκλοφόρησε με την εργασία [NEZHA: Neural Contextualized Representation for Chinese Language Understanding](https://arxiv.org/abs/1909.00204) από τους Junqiu Wei, Xiaozhe Ren, Xiaoguang Li, Wenyong Huang, Yi Liao, Yasheng Wang, Jiashu Lin, Xin Jiang, Xiao Chen and Qun Liu.
1. **[NLLB](model_doc/nllb)** (από Meta) κυκλοφόρησε με την εργασία [No Language Left Behind: Scaling Human-Centered Machine Translation](https://arxiv.org/abs/2207.04672) από τους the NLLB team.
1. **[Nyströmformer](model_doc/nystromformer)** (από the University of Wisconsin - Madison) κυκλοφόρησε με την εργασία [Nyströmformer: A Nyström-Based Algorithm for Approximating Self-Attention](https://arxiv.org/abs/2102.03902) από τους Yunyang Xiong, Zhanpeng Zeng, Rudrasis Chakraborty, Mingxing Tan, Glenn Fung, Yin Li, Vikas Singh.
1. **[OPT](master/model_doc/opt)** (από Meta AI) κυκλοφόρησε με την εργασία [OPT: Open Pre-trained Transformer Language Models](https://arxiv.org/abs/2205.01068) από τους Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen et al.
1. **[OWL-ViT](model_doc/owlvit)** (από Google AI) κυκλοφόρησε με την εργασία [Simple Open-Vocabulary Object Detection with Vision Transformers](https://arxiv.org/abs/2205.06230) από τους Matthias Minderer, Alexey Gritsenko, Austin Stone, Maxim Neumann, Dirk Weissenborn, Alexey Dosovitskiy, Aravindh Mahendran, Anurag Arnab, Mostafa Dehghani, Zhuoran Shen, Xiao Wang, Xiaohua Zhai, Thomas Kipf, and Neil Houlsby.
1. **[Pegasus](model_doc/pegasus)** (από Google) κυκλοφόρησε με την εργασία [PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization](https://arxiv.org/abs/1912.08777) από τους Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu.
1. **[PEGASUS-X](model_doc/pegasus_x)** (από Google) κυκλοφόρησε με την εργασία [Investigating Efficiently Extending Transformers for Long Input Summarization](https://arxiv.org/abs/2208.04347) από τους Jason Phang, Yao Zhao, and Peter J. Liu.
1. **[Perceiver IO](model_doc/perceiver)** (από Deepmind) κυκλοφόρησε με την εργασία [Perceiver IO: A General Architecture for Structured Inputs & Outputs](https://arxiv.org/abs/2107.14795) από τους Andrew Jaegle, Sebastian Borgeaud, Jean-Baptiste Alayrac, Carl Doersch, Catalin Ionescu, David Ding, Skanda Koppula, Daniel Zoran, Andrew Brock, Evan Shelhamer, Olivier Hénaff, Matthew M. Botvinick, Andrew Zisserman, Oriol Vinyals, João Carreira.
1. **[PhoBERT](model_doc/phobert)** (από VinAI Research) κυκλοφόρησε με την εργασία [PhoBERT: Pre-trained language models for Vietnamese](https://www.aclweb.org/anthology/2020.findings-emnlp.92/) από τους Dat Quoc Nguyen and Anh Tuan Nguyen.
1. **[PLBart](model_doc/plbart)** (από UCLA NLP) κυκλοφόρησε με την εργασία [Unified Pre-training for Program Understanding and Generation](https://arxiv.org/abs/2103.06333) από τους Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, Kai-Wei Chang.
1. **[PoolFormer](model_doc/poolformer)** (από Sea AI Labs) κυκλοφόρησε με την εργασία [MetaFormer is Actually What You Need for Vision](https://arxiv.org/abs/2111.11418) από τους Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng.
1. **[ProphetNet](model_doc/prophetnet)** (από Microsoft Research) κυκλοφόρησε με την εργασία [ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training](https://arxiv.org/abs/2001.04063) από τους Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.
1. **[QDQBert](model_doc/qdqbert)** (από NVIDIA) κυκλοφόρησε με την εργασία [Integer Quantization for Deep Learning Inference: Principles and Empirical Evaluation](https://arxiv.org/abs/2004.09602) από τους Hao Wu, Patrick Judd, Xiaojie Zhang, Mikhail Isaev and Paulius Micikevicius.
1. **[RAG](model_doc/rag)** (από Facebook) κυκλοφόρησε με την εργασία [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401) από τους Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, Douwe Kiela.
1. **[REALM](model_doc/realm.html)** (από Google Research) κυκλοφόρησε με την εργασία [REALM: Retrieval-Augmented Language Model Pre-Training](https://arxiv.org/abs/2002.08909) από τους Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat and Ming-Wei Chang.
1. **[Reformer](model_doc/reformer)** (από Google Research) κυκλοφόρησε με την εργασία [Reformer: The Efficient Transformer](https://arxiv.org/abs/2001.04451) από τους Nikita Kitaev, Łukasz Kaiser, Anselm Levskaya.
1. **[RegNet](model_doc/regnet)** (από META Platforms) κυκλοφόρησε με την εργασία [Designing Network Design Space](https://arxiv.org/abs/2003.13678) από τους Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick, Kaiming He, Piotr Dollár.
1. **[RemBERT](model_doc/rembert)** (από Google Research) κυκλοφόρησε με την εργασία [Rethinking embedding coupling in pre-trained language models](https://arxiv.org/abs/2010.12821) από τους Hyung Won Chung, Thibault Févry, Henry Tsai, M. Johnson, Sebastian Ruder.
1. **[ResNet](model_doc/resnet)** (από Microsoft Research) κυκλοφόρησε με την εργασία [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) από τους Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun.
1. **[RoBERTa](model_doc/roberta)** (από Facebook), κυκλοφόρησε με την εργασία [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692) από τους Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.
1. **[RoFormer](model_doc/roformer)** (από ZhuiyiTechnology), κυκλοφόρησε με την εργασία [RoFormer: Enhanced Transformer with Rotary Position Embedding](https://arxiv.org/abs/2104.09864) από τους Jianlin Su and Yu Lu and Shengfeng Pan and Bo Wen and Yunfeng Liu.
1. **[SegFormer](model_doc/segformer)** (από NVIDIA) κυκλοφόρησε με την εργασία [SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers](https://arxiv.org/abs/2105.15203) από τους Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, Ping Luo.
1. **[SEW](model_doc/sew)** (από ASAPP) κυκλοφόρησε με την εργασία [Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition](https://arxiv.org/abs/2109.06870) από τους Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.
1. **[SEW-D](model_doc/sew_d)** (από ASAPP) κυκλοφόρησε με την εργασία [Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition](https://arxiv.org/abs/2109.06870) από τους Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.
1. **[SpeechToTextTransformer](model_doc/speech_to_text)** (από Facebook), κυκλοφόρησε με την εργασία [fairseq S2T: Fast Speech-to-Text Modeling with fairseq](https://arxiv.org/abs/2010.05171) από τους Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Dmytro Okhonko, Juan Pino.
1. **[SpeechToTextTransformer2](model_doc/speech_to_text_2)** (από Facebook), κυκλοφόρησε με την εργασία [Large-Scale Self- and Semi-Supervised Learning for Speech Translation](https://arxiv.org/abs/2104.06678) από τους Changhan Wang, Anne Wu, Juan Pino, Alexei Baevski, Michael Auli, Alexis Conneau.
1. **[Splinter](model_doc/splinter)** (από Tel Aviv University), κυκλοφόρησε με την εργασία [Few-Shot Question Answering by Pretraining Span Selection](https://arxiv.org/abs/2101.00438) από τους Ori Ram, Yuval Kirstain, Jonathan Berant, Amir Globerson, Omer Levy.
1. **[SqueezeBERT](model_doc/squeezebert)** (από Berkeley) κυκλοφόρησε με την εργασία [SqueezeBERT: What can computer vision teach NLP about efficient neural networks?](https://arxiv.org/abs/2006.11316) από τους Forrest N. Iandola, Albert E. Shaw, Ravi Krishna, and Kurt W. Keutzer.
1. **[Swin Transformer](model_doc/swin)** (από Microsoft) κυκλοφόρησε με την εργασία [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/abs/2103.14030) από τους Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo.
1. **[Swin Transformer V2](model_doc/swinv2)** (από Microsoft) κυκλοφόρησε με την εργασία [Swin Transformer V2: Scaling Up Capacity and Resolution](https://arxiv.org/abs/2111.09883) από τους Ze Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, Yue Cao, Zheng Zhang, Li Dong, Furu Wei, Baining Guo.
1. **[T5](model_doc/t5)** (από Google AI) κυκλοφόρησε με την εργασία [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683) από τους Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.
1. **[T5v1.1](model_doc/t5v1.1)** (από Google AI) κυκλοφόρησε στο αποθετήριο [google-research/text-to-text-transfer-transformer](https://github.com/google-research/text-to-text-transfer-transformer/blob/main/released_checkpoints.md#t511) από τους Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.
1. **[Table Transformer](model_doc/table-transformer)** (από Microsoft Research) κυκλοφόρησε με την εργασία [PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents](https://arxiv.org/abs/2110.00061) από τους Brandon Smock, Rohith Pesala, Robin Abraham.
1. **[TAPAS](model_doc/tapas)** (από Google AI) κυκλοφόρησε με την εργασία [TAPAS: Weakly Supervised Table Parsing via Pre-training](https://arxiv.org/abs/2004.02349) από τους Jonathan Herzig, Paweł Krzysztof Nowak, Thomas Müller, Francesco Piccinno and Julian Martin Eisenschlos.
1. **[TAPEX](model_doc/tapex)** (από Microsoft Research) κυκλοφόρησε με την εργασία [TAPEX: Table Pre-training via Learning a Neural SQL Executor](https://arxiv.org/abs/2107.07653) από τους Qian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi Lin, Weizhu Chen, Jian-Guang Lou.
1. **[Time Series Transformer](model_doc/time_series_transformer)**  (από HuggingFace).
1. **[Trajectory Transformer](model_doc/trajectory_transformers)** (από the University of California at Berkeley) κυκλοφόρησε με την εργασία [Offline Reinforcement Learning as One Big Sequence Modeling Problem](https://arxiv.org/abs/2106.02039) από τους Michael Janner, Qiyang Li, Sergey Levine
1. **[Transformer-XL](model_doc/transfo-xl)** (από Google/CMU) κυκλοφόρησε με την εργασία [Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context](https://arxiv.org/abs/1901.02860) από τους Zihang Dai*, Zhilin Yang*, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov.
1. **[TrOCR](model_doc/trocr)** (από Microsoft), κυκλοφόρησε με την εργασία [TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models](https://arxiv.org/abs/2109.10282) από τους Minghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li, Furu Wei.
1. **[UL2](model_doc/ul2)** (από Google Research) κυκλοφόρησε με την εργασία [Unifying Language Learning Paradigms](https://arxiv.org/abs/2205.05131v1) από τους Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Dara Bahri, Tal Schuster, Huaixiu Steven Zheng, Neil Houlsby, Donald Metzler
1. **[UniSpeech](model_doc/unispeech)** (από Microsoft Research) κυκλοφόρησε με την εργασία [UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data](https://arxiv.org/abs/2101.07597) από τους Chengyi Wang, Yu Wu, Yao Qian, Kenichi Kumatani, Shujie Liu, Furu Wei, Michael Zeng, Xuedong Huang.
1. **[UniSpeechSat](model_doc/unispeech-sat)** (από Microsoft Research) κυκλοφόρησε με την εργασία [UNISPEECH-SAT: UNIVERSAL SPEECH REPRESENTATION LEARNING WITH SPEAKER AWARE PRE-TRAINING](https://arxiv.org/abs/2110.05752) από τους Sanyuan Chen, Yu Wu, Chengyi Wang, Zhengyang Chen, Zhuo Chen, Shujie Liu, Jian Wu, Yao Qian, Furu Wei, Jinyu Li, Xiangzhan Yu.
1. **[VAN](model_doc/van)** (από Tsinghua University and Nankai University) κυκλοφόρησε με την εργασία [Visual Attention Network](https://arxiv.org/abs/2202.09741) από τους Meng-Hao Guo, Cheng-Ze Lu, Zheng-Ning Liu, Ming-Ming Cheng, Shi-Min Hu.
1. **[VideoMAE](model_doc/videomae)** (από Multimedia Computing Group, Nanjing University) κυκλοφόρησε με την εργασία [VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training](https://arxiv.org/abs/2203.12602) από τους Zhan Tong, Yibing Song, Jue Wang, Limin Wang.
1. **[ViLT](model_doc/vilt)** (από NAVER AI Lab/Kakao Enterprise/Kakao Brain) κυκλοφόρησε με την εργασία [ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision](https://arxiv.org/abs/2102.03334) από τους Wonjae Kim, Bokyung Son, Ildoo Kim.
1. **[Vision Transformer (ViT)](model_doc/vit)** (από Google AI) κυκλοφόρησε με την εργασία [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929) από τους Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.
1. **[VisualBERT](model_doc/visual_bert)** (από UCLA NLP) κυκλοφόρησε με την εργασία [VisualBERT: A Simple and Performant Baseline for Vision and Language](https://arxiv.org/pdf/1908.03557) από τους Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, Kai-Wei Chang.
1. **[ViTMAE](model_doc/vit_mae)** (από Meta AI) κυκλοφόρησε με την εργασία [Masked Autoencoders Are Scalable Vision Learners](https://arxiv.org/abs/2111.06377) από τους Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollár, Ross Girshick.
1. **[ViTMSN](model_doc/vit_msn)** (από Meta AI) κυκλοφόρησε με την εργασία [Masked Siamese Networks for Label-Efficient Learning](https://arxiv.org/abs/2204.07141) από τους Mahmoud Assran, Mathilde Caron, Ishan Misra, Piotr Bojanowski, Florian Bordes, Pascal Vincent, Armand Joulin, Michael Rabbat, Nicolas Ballas.
1. **[Wav2Vec2](model_doc/wav2vec2)** (από Facebook AI) κυκλοφόρησε με την εργασία [wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations](https://arxiv.org/abs/2006.11477) από τους Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli.
1. **[Wav2Vec2-Conformer](model_doc/wav2vec2-conformer)** (από Facebook AI) κυκλοφόρησε με την εργασία [FAIRSEQ S2T: Fast Speech-to-Text Modeling with FAIRSEQ](https://arxiv.org/abs/2010.05171) από τους Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Sravya Popuri, Dmytro Okhonko, Juan Pino.
1. **[Wav2Vec2Phoneme](model_doc/wav2vec2_phoneme)** (από Facebook AI) κυκλοφόρησε με την εργασία [Simple and Effective Zero-shot Cross-lingual Phoneme Recognition](https://arxiv.org/abs/2109.11680) από τους Qiantong Xu, Alexei Baevski, Michael Auli.
1. **[WavLM](model_doc/wavlm)** (από Microsoft Research) κυκλοφόρησε με την εργασία [WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing](https://arxiv.org/abs/2110.13900) από τους Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie Liu, Zhuo Chen, Jinyu Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, Jian Wu, Long Zhou, Shuo Ren, Yanmin Qian, Yao Qian, Jian Wu, Michael Zeng, Furu Wei.
1. **[Whisper](model_doc/whisper)** (από OpenAI) κυκλοφόρησε με την εργασία [Robust Speech Recognition via Large-Scale Weak Supervision](https://cdn.openai.com/papers/whisper.pdf) από τους Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, Ilya Sutskever.
1. **[X-CLIP](model_doc/xclip)** (από Microsoft Research) κυκλοφόρησε με την εργασία [Expanding Language-Image Pretrained Models for General Video Recognition](https://arxiv.org/abs/2208.02816) από τους Bolin Ni, Houwen Peng, Minghao Chen, Songyang Zhang, Gaofeng Meng, Jianlong Fu, Shiming Xiang, Haibin Ling.
1. **[XGLM](model_doc/xglm)** (από Facebook AI) κυκλοφόρησε με την εργασία [Few-shot Learning with Multilingual Language Models](https://arxiv.org/abs/2112.10668) από τους Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian O'Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoyanov, Xian Li.
1. **[XLM](model_doc/xlm)** (από Facebook) κυκλοφόρησε με την εργασία [Cross-lingual Language Model Pretraining](https://arxiv.org/abs/1901.07291) από τους Guillaume Lample και Alexis Conneau.
1. **[XLM-ProphetNet](model_doc/xlm-prophetnet)** (από Microsoft Research) κυκλοφόρησε με την εργασία [ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training](https://arxiv.org/abs/2001.04063) από τους Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.
1. **[XLM-RoBERTa](model_doc/xlm-roberta)** (από Facebook AI), κυκλοφόρησε με την εργασία [Unsupervised Cross-lingual Representation Learning at Scale](https://arxiv.org/abs/1911.02116) από τους Alexis Conneau*, Kartikay Khandelwal*, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov.
1. **[XLM-RoBERTa-XL](model_doc/xlm-roberta-xl)** (από Facebook AI), κυκλοφόρησε με την εργασία [Larger-Scale Transformers for Multilingual Masked Language Modeling](https://arxiv.org/abs/2105.00572) από τους Naman Goyal, Jingfei Du, Myle Ott, Giri Anantharaman, Alexis Conneau.
1. **[XLNet](model_doc/xlnet)** (από Google/CMU) κυκλοφόρησε με την εργασία [​XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://arxiv.org/abs/1906.08237) από τους Zhilin Yang*, Zihang Dai*, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.
1. **[XLS-R](model_doc/xls_r)** (από Facebook AI) κυκλοφόρησε με την εργασία [XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale](https://arxiv.org/abs/2111.09296) από τους Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei Baevski, Alexis Conneau, Michael Auli.
1. **[XLSR-Wav2Vec2](model_doc/xlsr_wav2vec2)** (από Facebook AI) κυκλοφόρησε με την εργασία [Unsupervised Cross-Lingual Representation Learning For Speech Recognition](https://arxiv.org/abs/2006.13979) από τους Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, Michael Auli.
1. **[YOLOS](model_doc/yolos)** (από Huazhong University of Science & Technology) κυκλοφόρησε με την εργασία [You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection](https://arxiv.org/abs/2106.00666) από τους Yuxin Fang, Bencheng Liao, Xinggang Wang, Jiemin Fang, Jiyang Qi, Rui Wu, Jianwei Niu, Wenyu Liu.
1. **[YOSO](model_doc/yoso)** (από the University of Wisconsin - Madison) κυκλοφόρησε με την εργασία [You Only Sample (Almost) Once: Linear Cost Self-Attention Via Bernoulli Sampling](https://arxiv.org/abs/2111.09714) από τους Zhanpeng Zeng, Yunyang Xiong, Sathya N. Ravi, Shailesh Acharya, Glenn Fung, Vikas Singh.


### Υποστηριζόμενα frameworks

Ο παρακάτω πίνακας δείχνει την τωρινή υποστήριξη της βιβλιοθήκης για κάθε μοντέλο, άν έχουν ένα Python Tokenizer (λέγεται slow). Ένα "Fast" Tokenizer 
The table below represents the current support in the library for each of those models, whether they have a Python
tokenizer (called "slow"). A "fast" tokenizer υποστηριζόμενο από την βιβλιοθήκη 🤗 Tokenizers, άν έχουν υποστήριξη σε Jax (μέσω
Flax), PyTorch, και/ή TensorFlow.

<!--This table is updated automatically from the auto modules with _make fix-copies_. Do not update manually!-->

|            Μοντέλο            | Tokenizer slow | Tokenizer fast | Υποστήριξη PyTorch | Υποστήριξη TensorFlow | Υποστήριξη Flax |
|:---------------------------:|:--------------:|:--------------:|:---------------:|:------------------:|:------------:|
|           ALBERT            |       ✅       |       ✅       |       ✅        |         ✅         |      ✅      |
|            BART             |       ✅       |       ✅       |       ✅        |         ✅         |      ✅      |
|            BEiT             |       ❌       |       ❌       |       ✅        |         ❌         |      ✅      |
|            BERT             |       ✅       |       ✅       |       ✅        |         ✅         |      ✅      |
|       Bert Generation       |       ✅       |       ❌       |       ✅        |         ❌         |      ❌      |
|           BigBird           |       ✅       |       ✅       |       ✅        |         ❌         |      ✅      |
|       BigBird-Pegasus       |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|         Blenderbot          |       ✅       |       ✅       |       ✅        |         ✅         |      ✅      |
|       BlenderbotSmall       |       ✅       |       ✅       |       ✅        |         ✅         |      ✅      |
|            BLOOM            |       ❌       |       ✅       |       ✅        |         ❌         |      ❌      |
|          CamemBERT          |       ✅       |       ✅       |       ✅        |         ✅         |      ❌      |
|           CANINE            |       ✅       |       ❌       |       ✅        |         ❌         |      ❌      |
|            CLIP             |       ✅       |       ✅       |       ✅        |         ✅         |      ✅      |
|           CodeGen           |       ✅       |       ✅       |       ✅        |         ❌         |      ❌      |
|      Conditional DETR       |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|          ConvBERT           |       ✅       |       ✅       |       ✅        |         ✅         |      ❌      |
|          ConvNeXT           |       ❌       |       ❌       |       ✅        |         ✅         |      ❌      |
|            CTRL             |       ✅       |       ❌       |       ✅        |         ✅         |      ❌      |
|             CvT             |       ❌       |       ❌       |       ✅        |         ✅         |      ❌      |
|        Data2VecAudio        |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|        Data2VecText         |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|       Data2VecVision        |       ❌       |       ❌       |       ✅        |         ✅         |      ❌      |
|           DeBERTa           |       ✅       |       ✅       |       ✅        |         ✅         |      ❌      |
|         DeBERTa-v2          |       ✅       |       ✅       |       ✅        |         ✅         |      ❌      |
|    Decision Transformer     |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|       Deformable DETR       |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|            DeiT             |       ❌       |       ❌       |       ✅        |         ✅         |      ❌      |
|            DETR             |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|         DistilBERT          |       ✅       |       ✅       |       ✅        |         ✅         |      ✅      |
|          DonutSwin          |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|             DPR             |       ✅       |       ✅       |       ✅        |         ✅         |      ❌      |
|             DPT             |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|           ELECTRA           |       ✅       |       ✅       |       ✅        |         ✅         |      ✅      |
|       Encoder decoder       |       ❌       |       ❌       |       ✅        |         ✅         |      ✅      |
|            ERNIE            |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|             ESM             |       ✅       |       ❌       |       ✅        |         ✅         |      ❌      |
| FairSeq Machine-Translation |       ✅       |       ❌       |       ✅        |         ❌         |      ❌      |
|          FlauBERT           |       ✅       |       ❌       |       ✅        |         ✅         |      ❌      |
|            FLAVA            |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|            FNet             |       ✅       |       ✅       |       ✅        |         ❌         |      ❌      |
|     Funnel Transformer      |       ✅       |       ✅       |       ✅        |         ✅         |      ❌      |
|            GLPN             |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|           GPT Neo           |       ❌       |       ❌       |       ✅        |         ❌         |      ✅      |
|          GPT NeoX           |       ❌       |       ✅       |       ✅        |         ❌         |      ❌      |
|      GPT NeoX Japanese      |       ✅       |       ❌       |       ✅        |         ❌         |      ❌      |
|            GPT-J            |       ❌       |       ❌       |       ✅        |         ✅         |      ✅      |
|          GroupViT           |       ❌       |       ❌       |       ✅        |         ✅         |      ❌      |
|           Hubert            |       ❌       |       ❌       |       ✅        |         ✅         |      ❌      |
|           I-BERT            |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|          ImageGPT           |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|          LayoutLM           |       ✅       |       ✅       |       ✅        |         ✅         |      ❌      |
|         LayoutLMv2          |       ✅       |       ✅       |       ✅        |         ❌         |      ❌      |
|         LayoutLMv3          |       ✅       |       ✅       |       ✅        |         ✅         |      ❌      |
|             LED             |       ✅       |       ✅       |       ✅        |         ✅         |      ❌      |
|            LeViT            |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|            LiLT             |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|         Longformer          |       ✅       |       ✅       |       ✅        |         ✅         |      ❌      |
|           LongT5            |       ❌       |       ❌       |       ✅        |         ❌         |      ✅      |
|            LUKE             |       ✅       |       ❌       |       ✅        |         ❌         |      ❌      |
|           LXMERT            |       ✅       |       ✅       |       ✅        |         ✅         |      ❌      |
|           M-CTC-T           |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|           M2M100            |       ✅       |       ❌       |       ✅        |         ❌         |      ❌      |
|           Marian            |       ✅       |       ❌       |       ✅        |         ✅         |      ✅      |
|          MarkupLM           |       ✅       |       ✅       |       ✅        |         ❌         |      ❌      |
|         MaskFormer          |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|            mBART            |       ✅       |       ✅       |       ✅        |         ✅         |      ✅      |
|        Megatron-BERT        |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|         MobileBERT          |       ✅       |       ✅       |       ✅        |         ✅         |      ❌      |
|          MobileViT          |       ❌       |       ❌       |       ✅        |         ✅         |      ❌      |
|            MPNet            |       ✅       |       ✅       |       ✅        |         ✅         |      ❌      |
|             MT5             |       ✅       |       ✅       |       ✅        |         ✅         |      ✅      |
|             MVP             |       ✅       |       ✅       |       ✅        |         ❌         |      ❌      |
|            Nezha            |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|        Nyströmformer        |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|         OpenAI GPT          |       ✅       |       ✅       |       ✅        |         ✅         |      ❌      |
|        OpenAI GPT-2         |       ✅       |       ✅       |       ✅        |         ✅         |      ✅      |
|             OPT             |       ❌       |       ❌       |       ✅        |         ✅         |      ✅      |
|           OWL-ViT           |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|           Pegasus           |       ✅       |       ✅       |       ✅        |         ✅         |      ✅      |
|          PEGASUS-X          |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|          Perceiver          |       ✅       |       ❌       |       ✅        |         ❌         |      ❌      |
|           PLBart            |       ✅       |       ❌       |       ✅        |         ❌         |      ❌      |
|         PoolFormer          |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|         ProphetNet          |       ✅       |       ❌       |       ✅        |         ❌         |      ❌      |
|           QDQBert           |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|             RAG             |       ✅       |       ❌       |       ✅        |         ✅         |      ❌      |
|            REALM            |       ✅       |       ✅       |       ✅        |         ❌         |      ❌      |
|          Reformer           |       ✅       |       ✅       |       ✅        |         ❌         |      ❌      |
|           RegNet            |       ❌       |       ❌       |       ✅        |         ✅         |      ❌      |
|           RemBERT           |       ✅       |       ✅       |       ✅        |         ✅         |      ❌      |
|           ResNet            |       ❌       |       ❌       |       ✅        |         ✅         |      ❌      |
|          RetriBERT          |       ✅       |       ✅       |       ✅        |         ❌         |      ❌      |
|           RoBERTa           |       ✅       |       ✅       |       ✅        |         ✅         |      ✅      |
|          RoFormer           |       ✅       |       ✅       |       ✅        |         ✅         |      ✅      |
|          SegFormer          |       ❌       |       ❌       |       ✅        |         ✅         |      ❌      |
|             SEW             |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|            SEW-D            |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|   Speech Encoder decoder    |       ❌       |       ❌       |       ✅        |         ❌         |      ✅      |
|         Speech2Text         |       ✅       |       ❌       |       ✅        |         ✅         |      ❌      |
|        Speech2Text2         |       ✅       |       ❌       |       ❌        |         ❌         |      ❌      |
|          Splinter           |       ✅       |       ✅       |       ✅        |         ❌         |      ❌      |
|         SqueezeBERT         |       ✅       |       ✅       |       ✅        |         ❌         |      ❌      |
|      Swin Transformer       |       ❌       |       ❌       |       ✅        |         ✅         |      ❌      |
|     Swin Transformer V2     |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|             T5              |       ✅       |       ✅       |       ✅        |         ✅         |      ✅      |
|      Table Transformer      |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|            TAPAS            |       ✅       |       ❌       |       ✅        |         ✅         |      ❌      |
|   Time Series Transformer   |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|   Trajectory Transformer    |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|       Transformer-XL        |       ✅       |       ❌       |       ✅        |         ✅         |      ❌      |
|            TrOCR            |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|          UniSpeech          |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|        UniSpeechSat         |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|             VAN             |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|          VideoMAE           |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|            ViLT             |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|   Vision Encoder decoder    |       ❌       |       ❌       |       ✅        |         ✅         |      ✅      |
|    VisionTextDualEncoder    |       ❌       |       ❌       |       ✅        |         ❌         |      ✅      |
|         VisualBERT          |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|             ViT             |       ❌       |       ❌       |       ✅        |         ✅         |      ✅      |
|           ViTMAE            |       ❌       |       ❌       |       ✅        |         ✅         |      ❌      |
|           ViTMSN            |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|          Wav2Vec2           |       ✅       |       ❌       |       ✅        |         ✅         |      ✅      |
|     Wav2Vec2-Conformer      |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|            WavLM            |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|           Whisper           |       ✅       |       ❌       |       ✅        |         ✅         |      ❌      |
|           X-CLIP            |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|            XGLM             |       ✅       |       ✅       |       ✅        |         ✅         |      ✅      |
|             XLM             |       ✅       |       ❌       |       ✅        |         ✅         |      ❌      |
|       XLM-ProphetNet        |       ✅       |       ❌       |       ✅        |         ❌         |      ❌      |
|         XLM-RoBERTa         |       ✅       |       ✅       |       ✅        |         ✅         |      ✅      |
|       XLM-RoBERTa-XL        |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|            XLNet            |       ✅       |       ✅       |       ✅        |         ✅         |      ❌      |
|            YOLOS            |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |
|            YOSO             |       ❌       |       ❌       |       ✅        |         ❌         |      ❌      |

<!-- End table-->
