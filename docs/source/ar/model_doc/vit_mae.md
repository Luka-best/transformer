# ViTMAE

## ูุธุฑุฉ ุนุงูุฉ

ุงูุชุฑุญ ูููุฐุฌ ViTMAE ูู [Masked Autoencoders Are Scalable Vision Learners](https://arxiv.org/abs/2111.06377v2) ุจูุงุณุทุฉ Kaiming He ูุขุฎุฑูู. ุชูุถุญ ุงููุฑูุฉ ุฃูู ูู ุฎูุงู ุงูุชุฏุฑูุจ ุงููุณุจู ูู Vision Transformer (ViT) ูุฅุนุงุฏุฉ ุจูุงุก ููู ุงูุจูุณู ููุฑูุน ุงูููููุนุฉุ ูููู ุงูุญุตูู ุนูู ูุชุงุฆุฌ ุจุนุฏ ุงูุถุจุท ุงูุฏููู ุชุชููู ุนูู ุงูุชุฏุฑูุจ ุงูููุดุฑู.

ุงูููุฎุต ูู ุงููุฑูุฉ ูู ููุง ููู:

*ุชูุถุญ ูุฐู ุงููุฑูุฉ ุฃู ุจุฑุงูุฌ ุงูุชุฑููุฒ ุงูุชููุงุฆู ุงููููุนุฉ (MAE) ูู ูุชุนููุงุช ุฑุคูุฉ ุฐุงุชูุฉ ุงูุฅุดุฑุงู ูุงุจูุฉ ููุชุทููุฑ. ุฅู ููุฌูุง MAE ุจุณูุท: ูููู ุจุฅุฎูุงุก ุฑูุน ุนุดูุงุฆูุฉ ูู ุตูุฑุฉ ุงูุฅุฏุฎุงู ูุฅุนุงุฏุฉ ุจูุงุก ุจูุณูุงุช ุงูุตูุฑุฉ ุงููุงูุตุฉ. ููุณุชูุฏ ุฅูู ุชุตููููู ุฃุณุงุณููู. ุฃููุงูุ ูููู ุจุชุทููุฑ ุจููุฉ ุชุฑููุฒ ูู ุชุฑููุฒ ุบูุฑ ูุชูุงุซูุฉุ ูุน ุชุฑููุฒ ูุนูู ููุท ุนูู ุงููุฌููุนุฉ ุงููุฑุฆูุฉ ูู ุงูุฑูุน (ุฏูู ุฑููุฒ ุงูููุงุน)ุ ุฅูู ุฌุงูุจ ูู ุชุดููุฑ ุฎููู ุงููุฒู ูููู ุจุฅุนุงุฏุฉ ุจูุงุก ุงูุตูุฑุฉ ุงูุฃุตููุฉ ูู ุงูุชูุซูู ุงููุฎูู ูุฑููุฒ ุงูููุงุน. ุซุงูููุงุ ูุฌุฏูุง ุฃู ุฅุฎูุงุก ูุณุจุฉ ุนุงููุฉ ูู ุตูุฑุฉ ุงูุฅุฏุฎุงูุ ุนูู ุณุจูู ุงููุซุงู 75%ุ ููุชุฌ ุนูู ูููุฉ ุฐุงุชูุฉ ุงูุฅุดุฑุงู ุบูุฑ ุชุงููุฉ ูุฐุงุช ูุนูู. ููููููุง ุงูุฌูุน ุจูู ูุฐูู ุงูุชุตููููู ูู ุชุฏุฑูุจ ููุงุฐุฌ ูุจูุฑุฉ ุจููุงุกุฉ ููุนุงููุฉ: ููุญู ูุณุฑุน ุงูุชุฏุฑูุจ (ุจูุนุฏู 3 ูุฑุงุช ุฃู ุฃูุซุฑ) ููุญุณู ุงูุฏูุฉ. ูุณูุญ ููุง ููุฌูุง ุงููุงุจู ููุชุทููุฑ ุจุชุนูู ููุงุฐุฌ ุนุงููุฉ ุงูุณุนุฉ ูุงูุชู ูุชู ุชุนููููุง ุจุดูู ุฌูุฏ: ุนูู ุณุจูู ุงููุซุงูุ ูุญูู ูููุฐุฌ ViT-Huge ุงูุฃุณุงุณู ุฃูุถู ุฏูุฉ (87.8%) ุจูู ุงูุทุฑู ุงูุชู ุชุณุชุฎุฏู ุจูุงูุงุช ImageNet-1K ููุท. ููุชููู ุงูุฃุฏุงุก ุงูููููู ูู ุงูููุงู ุงููุงุญูุฉ ุนูู ุงูุชุฏุฑูุจ ุงูููุดุฑู ููุธูุฑ ุณููููุง ูุงุนุฏูุง ูู ุงููุทุงู.*

<img src="https://user-images.githubusercontent.com/11435359/146857310-f258c86c-fde6-48e8-9cee-badd2b21bd2c.png"
alt="drawing" width="600"/>

<small>ุจููุฉ MAE. ูุฃุฎูุฐุฉ ูู <a href="https://arxiv.org/abs/2111.06377">ุงููุฑูุฉ ุงูุฃุตููุฉ.</a> </small>

ุชูุช ุงููุณุงููุฉ ุจูุฐุง ุงููููุฐุฌ ุจูุงุณุทุฉ [nielsr](https://huggingface.co/nielsr). ุชูุช ุงููุณุงููุฉ ูู ุฅุตุฏุงุฑ TensorFlow ูู ุงููููุฐุฌ ุจูุงุณุทุฉ [sayakpaul](https://github.com/sayakpaul) ู [ariG23498](https://github.com/ariG23498) (ูุณุงููุฉ ูุชุณุงููุฉ). ูููู ุงูุนุซูุฑ ุนูู ุงูููุฏ ุงูุฃุตูู [ููุง](https://github.com/facebookresearch/mae).

## ูุตุงุฆุญ ุงูุงุณุชุฎุฏุงู

- MAE (ุงูุชุฑููุฒ ุงูุชููุงุฆู ุงููููุน) ูู ุทุฑููุฉ ููุชุนูู ุงูุฐุงุชู ุงููุณุจู ูู Vision Transformers (ViTs). ูุฏู ุงูุชุฏุฑูุจ ุงููุณุจู ุจุณูุท ูุณุจููุง: ูู ุฎูุงู ุฅุฎูุงุก ุฌุฒุก ูุจูุฑ (75%) ูู ุฑูุน ุงูุตูุฑุฉุ ูุฌุจ ุนูู ุงููููุฐุฌ ุฅุนุงุฏุฉ ุจูุงุก ููู ุงูุจูุณู ุงูุฎุงู. ูููู ุงุณุชุฎุฏุงู [`ViTMAEForPreTraining`] ููุฐุง ุงูุบุฑุถ.

- ุจุนุฏ ุงูุชุฏุฑูุจ ุงููุณุจูุ ูุชู "ุฅููุงุก" ูู ุงูุชุดููุฑ ุงููุณุชุฎุฏู ูุฅุนุงุฏุฉ ุจูุงุก ุงูุจูุณูุงุชุ ููุชู ุงุณุชุฎุฏุงู ุงูุชุฑููุฒ ููุถุจุท ุงูุฏููู/ุงููุญุต ุงูุฎุทู. ููุฐุง ูุนูู ุฃูู ุจุนุฏ ุงูุถุจุท ุงูุฏูููุ ููููู ุชูุตูู ุงูุฃูุฒุงู ูุจุงุดุฑุฉ ูู [`ViTForImageClassification`].

- ูููู ุงุณุชุฎุฏุงู [`ViTImageProcessor`] ูุฅุนุฏุงุฏ ุงูุตูุฑ ูููููุฐุฌ. ุฑุงุฌุน ุฃูุซูุฉ ุงูููุฏ ููุฒูุฏ ูู ุงููุนูููุงุช.

- ูุงุญุธ ุฃู ุชุฑููุฒ MAE ูุณุชุฎุฏู ููุท ูุชุฑููุฒ ุงูุฑูุน ุงููุฑุฆูุฉ. ุซู ูุชู ุฏูุฌ ุงูุฑูุน ุงููุดูุฑุฉ ูุน ุฑููุฒ ุงูููุงุนุ ูุงูุชู ูุฃุฎุฐูุง ูู ุงูุชุดููุฑ (ุงูุฐู ูุชููู ุฃูุถูุง ูู ูุชู ุงููุญูู) ูุฅุฏุฎุงู. ูู ุฑูุฒ ููุงุน ูู ูุชุฌู ูุดุชุฑู ูููุชุนูู ูุดูุฑ ุฅูู ูุฌูุฏ ุฑูุนุฉ ููููุฏุฉ ูุฌุจ ุงูุชูุจุค ุจูุง. ุชุชู ุฅุถุงูุฉ ุชุถูููุงุช ุงูููุถุน sin/cos ุงูุซุงุจุชุฉ ููู ูู ุฅุฏุฎุงู ุงูุชุฑููุฒ ููู ุงูุชุดููุฑ.

- ููุญุตูู ุนูู ููู ูุฑุฆู ูููููุฉ ุนูู MAEsุ ููููู ุงูุงุทูุงุน ุนูู ูุฐุง [ุงูููุดูุฑ](https://keras.io/examples/vision/masked_image_modeling/).

### ุงุณุชุฎุฏุงู Scaled Dot Product Attention (SDPA)

ุชุชุถูู PyTorch ูุดุบู ุงูุชูุงู ุงูููุชุฌ ุงูููุทู ุงูููุฏุฑุฌ ุจุดูู ุทุจูุนู ูุฌุฒุก ูู `torch.nn.functional`. ุชุดูู ูุฐู ุงูุฏุงูุฉ ุนุฏุฉ ุชูููุฐุงุช ูููู ุชุทุจูููุง ุงุนุชูุงุฏูุง ุนูู ุงููุฏุฎูุงุช ูุงูุฃุฌูุฒุฉ ุงููุณุชุฎุฏูุฉ. ุฑุงุฌุน [ุงููุซุงุฆู ุงูุฑุณููุฉ](https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html)
ุฃู [ุตูุญุฉ ุงูุงุณุชุฏูุงู GPU](https://huggingface.co/docs/transformers/main/en/perf_infer_gpu_one#pytorch-scaled-dot-product-attention)
ููุฒูุฏ ูู ุงููุนูููุงุช.

ูุชู ุงุณุชุฎุฏุงู SDPA ุจุดูู ุงูุชุฑุงุถู ูู `torch>=2.1.1` ุนูุฏูุง ูููู ุงูุชูููุฐ ูุชุงุญูุงุ ูููู ููููู ุฃูุถูุง ุชุนููู `attn_implementation="sdpa"` ูู `from_pretrained()` ูุทูุจ ุงุณุชุฎุฏุงู SDPA ุจุดูู ุตุฑูุญ.

```py
from transformers import ViTMAEModel
model = ViTMAEModel.from_pretrained("facebook/vit-mae-base", attn_implementation="sdpa", torch_dtype=torch.float16)
...
```

ููุญุตูู ุนูู ุฃูุถู ุณุฑุนุงุชุ ููุตู ุจุชุญููู ุงููููุฐุฌ ุจูุตู ุงูุฏูุฉ (ุนูู ุณุจูู ุงููุซุงู `torch.float16` ุฃู `torch.bfloat16`).

ุนูู ูุนูุงุฑ ูุญูู (A100-40GBุ PyTorch 2.3.0ุ ูุธุงู ุงูุชุดุบูู Ubuntu 22.04) ูุน `float32` ููููุฐุฌ `facebook/vit-mae-base`ุ ุฑุฃููุง ุณุฑุนุงุช ุงูุชุงููุฉ ุฎูุงู ุงูุงุณุชุฏูุงู.

| ุญุฌู ุงูุฏูุนุฉ | ูุชูุณุท ููุช ุงูุงุณุชุฏูุงู (ูููู ุซุงููุฉ)ุ ูุถุน Eager | ูุชูุณุท ููุช ุงูุงุณุชุฏูุงู (ูููู ุซุงููุฉ)ุ ูููุฐุฌ SDPA | ุชุณุฑูุนุ SDPA / Eager (x) |
|--------------|-------------------------------------------|-------------------------------------------|------------------------------|
| 1 | 11 | 6 | 1.83 |
| 2 | 8 | 6 | 1.33 |
| 4 | 8 | 6 | 1.33 |
| 8 | 8 | 6 | 1.33 |

## ุงูููุงุฑุฏ

ูุงุฆูุฉ ุจููุงุฑุฏ Hugging Face ุงูุฑุณููุฉ ูููุงุฑุฏ ุงููุฌุชูุน (ูุดุงุฑ ุฅูููุง ุจู ๐) ููุณุงุนุฏุชู ูู ุงูุจุฏุก ุจุงุณุชุฎุฏุงู ViTMAE.

- [`ViTMAEForPreTraining`] ูุฏุนูู ุจูุงุณุทุฉ [ูุต ุจุฑูุฌู ุชูุถูุญู](https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-pretraining)ุ ููุง ูุชูุญ ูู ุชุฏุฑูุจ ุงููููุฐุฌ ูู ุงูุตูุฑ/ููุงุตูุฉ ุชุฏุฑูุจ ุงููููุฐุฌ ุนูู ุจูุงูุงุช ูุฎุตุตุฉ.

- ูููู ุงูุนุซูุฑ ุนูู ุฏูุชุฑ ููุงุญุธุงุช ููุถุญ ููููุฉ ุชุตูุฑ ููู ุงูุจูุณู ุงููุนุงุฏ ุจูุงุคูุง ูุน [`ViTMAEForPreTraining`] [ููุง](https://github.com/NielsRogge/Transformers-Tutorials/blob/master/ViTMAE/ViT_MAE_visualization_demo.ipynb).

ุฅุฐุง ููุช ููุชููุง ุจุชูุฏูู ููุฑุฏ ูุฅุฏุฑุงุฌู ููุงุ ูุงูุฑุฌุงุก ูุชุญ ุทูุจ ุณุญุจ ูุณูุฑุงุฌุนู! ูุฌุจ ุฃู ููุถุญ ุงูููุฑุฏ ุจุดูู ูุซุงูู ุดูุฆูุง ุฌุฏูุฏูุง ุจุฏูุงู ูู ุชูุฑุงุฑ ููุฑุฏ ููุฌูุฏ.

## ViTMAEConfig

[[autodoc]] ViTMAEConfig

<frameworkcontent>
<pt>

## ViTMAEModel

[[autodoc]] ViTMAEModel

- forward

## ViTMAEForPreTraining

[[autodoc]] transformers.ViTMAEForPreTraining

- forward

</pt>
<tf>

## TFViTMAEModel

[[autodoc]] TFViTMAEModel

- call

## TFViTMAEForPreTraining

[[autodoc]] transformers.TFViTMAEForPreTraining

- call

</tf>
</frameworkcontent>