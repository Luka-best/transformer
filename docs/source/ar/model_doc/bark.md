# Bark

## ูุธุฑุฉ ุนุงูุฉ

Bark ุนุจุงุฑุฉ ุนู ูููุฐุฌ ุชุญููู ูุต ุฅูู ููุงู ูุนุชูุฏ ุนูู ุงููุต ุงูุฐู ุงูุชุฑุญุชู Suno AI ูู [suno-ai/bark](https://github.com/suno-ai/bark).
ูุชููู Bark ูู 4 ููุงุฐุฌ ุฑุฆูุณูุฉ:

- [`BarkSemanticModel`] (ููุดุงุฑ ุฅููู ุฃูุถูุง ุจุงุณู ูููุฐุฌ "ุงููุต"): ูููุฐุฌ ูุญูู ุฐุงุชู ุงูุงูุญุฏุงุฑ ุงูุณุจุจู ุงูุฐู ูุฃุฎุฐ ููุฏุฎูุงุช ูุตูุง ูููุฒูุงุ ููุชููุน ุฑููุฒ ูุตูุฉ ุฏูุงููุฉ ุชูุชูุท ูุนูู ุงููุต.
- [`BarkCoarseModel`] (ููุดุงุฑ ุฅููู ุฃูุถูุง ุจุงุณู ูููุฐุฌ "ุงูุตูุชูุงุช ุงูุฎุดูุฉ"): ูุญูู ุฐุงุชู ุงูุงูุญุฏุงุฑ ุงูุณุจุจูุ ูุฃุฎุฐ ููุฏุฎูุงุช ูุชุงุฆุฌ ูููุฐุฌ [`BarkSemanticModel`]. ูููุฏู ุฅูู ุงูุชูุจุค ุจุฃูู ูุชุงุจูู ุตูุชููู ุถุฑูุฑููู ูู EnCodec.
- [`BarkFineModel`] (ูููุฐุฌ "ุงูุตูุชูุงุช ุงูุฏูููุฉ")ุ ูุฐู ุงููุฑุฉ ูุญูู ุชุดููุฑ ุฐุงุชู ุบูุฑ ุณุจุจูุ ูุงูุฐู ูุชูุจุฃ ุจุดูู ุชูุฑุงุฑู ุจูุชุจ ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ ุงูุฃุฎูุฑุฉ ุจูุงุกู ุนูู ูุฌููุน ุชุถูููุงุช ูุชุจ ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ ุงูุณุงุจูุฉ.
- ุจุนุฏ ุงูุชูุจุค ุจุฌููุน ูููุงุช ูุชุงุจ ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ ูู [`EncodecModel`]ุ ูุณุชุฎุฏู Bark ูุชุฑููุฒ ุตููู ุงูุฅุฎุฑุงุฌ ุงูุตูุชู.

ุชุฌุฏุฑ ุงูุฅุดุงุฑุฉ ุฅูู ุฃู ูู ูุญุฏุฉ ูู ุงููุญุฏุงุช ุงูููุทูุฉ ุงูุซูุงุซ ุงูุฃููู ูููู ุฃู ุชุฏุนู ุชุถูููุงุช ุงููุชุญุฏุซ ุงูุดุฑุทูุฉ ูุดุฑุท ุฅุฎุฑุงุฌ ุงูุตูุช ููููุง ูุตูุช ูุญุฏุฏ ูุณุจููุง.

ุชูุช ุงููุณุงููุฉ ุจูุฐุง ุงููููุฐุฌ ูู ูุจู [Yoach Lacombe (ylacombe)](https://huggingface.co/ylacombe) ู [Sanchit Gandhi (sanchit-gandhi)](https://github.com/sanchit-gandhi).
ูููู ุงูุนุซูุฑ ุนูู ุงูููุฏ ุงูุฃุตูู [ููุง](https://github.com/suno-ai/bark).

### ุชุญุณูู Bark

ูููู ุชุญุณูู Bark ุจุจุถุน ุฃุณุทุฑ ุฅุถุงููุฉ ูู ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉุ ูุงูุชู **ุชุฎูุถ ุจุดูู ูุจูุฑ ูู ุจุตูุฉ ุฐุงูุฑุชู** ู**ุชุณุฑุน ุงูุงุณุชุฏูุงู**.

#### ุงุณุชุฎุฏุงู ูุตู ุงูุฏูุฉ

ููููู ุชุณุฑูุน ุงูุงุณุชุฏูุงู ูุชูููู ุงุณุชุฎุฏุงู ุงูุฐุงูุฑุฉ ุจูุณุจุฉ 50% ุจุจุณุงุทุฉ ุนู ุทุฑูู ุชุญููู ุงููููุฐุฌ ุจูุตู ุงูุฏูุฉ.

```python
from transformers import BarkModel
import torch

device = "cuda" if torch.cuda.is_available() else "cpu"
model = BarkModel.from_pretrained("suno/bark-small", torch_dtype=torch.float16).to(device)
```

#### ุงุณุชุฎุฏุงู ุชูุฑูุบ ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ

ููุง ุฐูุฑูุง ุณุงุจููุงุ ูุชููู Bark ูู 4 ููุงุฐุฌ ูุฑุนูุฉุ ูุชู ุงุณุชุฏุนุงุคูุง ุจุงูุชุชุงุจุน ุฃุซูุงุก ุฅูุดุงุก ุงูุตูุช. ูุจุนุจุงุฑุฉ ุฃุฎุฑูุ ุฃุซูุงุก ุงุณุชุฎุฏุงู ูููุฐุฌ ูุฑุนู ูุงุญุฏุ ุชููู ุงูููุงุฐุฌ ุงููุฑุนูุฉ ุงูุฃุฎุฑู ุฎุงููุฉ.

ุฅุฐุง ููุช ุชุณุชุฎุฏู ุฌูุงุฒ CUDAุ ูุฅู ุงูุญู ุงูุจุณูุท ููุงุณุชูุงุฏุฉ ูู ุงูุฎูุงุถ ุจูุณุจุฉ 80% ูู ุจุตูุฉ ุงูุฐุงูุฑุฉ ูู ุชูุฑูุบ ุงูููุงุฐุฌ ุงููุฑุนูุฉ ูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณููุงุช (GPU) ุฅูู ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ (CPU) ุนูุฏูุง ุชููู ุฎุงููุฉ. ููุทูู ุนูู ูุฐู ุงูุนูููุฉ ุงุณู *ุชูุฑูุบ ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ*. ููููู ุงุณุชุฎุฏุงูู ุจุฃุณุทุฑ ุจุฑูุฌูุฉ ูุงุญุฏุฉ ุนูู ุงููุญู ุงูุชุงูู:

```python
model.enable_cpu_offload()
```

ูุงุญุธ ุฃูู ูุฌุจ ุชุซุจูุช ๐ค Accelerate ูุจู ุงุณุชุฎุฏุงู ูุฐู ุงูููุฒุฉ. [ููุง ููููุฉ ุชุซุจูุชู.](Https://huggingface.co/docs/accelerate/basic_tutorials/install)

#### ุงุณุชุฎุฏุงู ูุญูู ุฃูุถู

ูุญูู ุฃูุถู ูู ููุฒุฉ ๐ค Optimum ุงูุชู ุชููู ุจุฏูุฌ ุงูููุงุฉ ุชุญุช ุงูุบุทุงุก. ููููู ุชุญููู ููุงุณุจ ุชุชุฑุงูุญ ุจูู 20% ู 30% ูู ุงูุณุฑุนุฉ ุฏูู ุฃู ุชุฏููุฑ ูู ุงูุฃุฏุงุก. ููู ูุชุทูุจ ุณุทุฑ ุจุฑูุฌูุฉ ูุงุญุฏ ููุท ูุชุตุฏูุฑ ุงููููุฐุฌ ุฅูู ูุญูู ุฃูุถู:

```python
model = model.to_bettertransformer()
```

ูุงุญุธ ุฃูู ูุฌุจ ุชุซุจูุช ๐ค Optimum ูุจู ุงุณุชุฎุฏุงู ูุฐู ุงูููุฒุฉ. [ููุง ููููุฉ ุชุซุจูุชู.](Https://huggingface.co/docs/optimum/installation)

#### ุงุณุชุฎุฏุงู Flash Attention 2

Flash Attention 2 ูู ุฅุตุฏุงุฑ ูุญุณูู ุฃุณุฑุน ูู ุงูุชุญุณูู ุงูุณุงุจู.

##### ุงูุชุซุจูุช

ุฃููุงูุ ุชุญูู ููุง ุฅุฐุง ูุงู ุงูุฃุฌูุฒุฉ ุงูุฎุงุตุฉ ุจู ูุชูุงููุฉ ูุน Flash Attention 2. ูููู ุงูุนุซูุฑ ุนูู ุฃุญุฏุซ ูุงุฆูุฉ ูู ุงูุฃุฌูุฒุฉ ุงููุชูุงููุฉ ูู [ุงููุซุงุฆู ุงูุฑุณููุฉ](https://github.com/Dao-AILab/flash-attention#installation-and-features). ุฅุฐุง ูู ููู ุงูุฃุฌูุฒุฉ ุงูุฎุงุต ุจู ูุชูุงูููุง ูุน Flash Attention 2ุ ูููููู ุงูุงุณุชูุงุฏุฉ ูู ุชุญุณูู ููุงุฉ ุงูุงูุชูุงู ูู ุฎูุงู ุฏุนู ูุญูู ุฃูุถู ุงููุดููู [ุฃุนูุงู](https://huggingface.co/docs/transformers/main/en/model_doc/bark#using-better-transformer).

ุจุนุฏ ุฐููุ ูู ุจุชุซุจูุช ุฃุญุฏุซ ุฅุตุฏุงุฑ ูู Flash Attention 2:

```bash
pip install -U flash-attn --no-build-isolation
```

##### ุงูุงุณุชุฎุฏุงู

ูุชุญููู ูููุฐุฌ ุจุงุณุชุฎุฏุงู Flash Attention 2ุ ูููููุง ุชูุฑูุฑ `attn_implementation="flash_attention_2"` ุงูุนูู ุฅูู [`.from_pretrained`](Https://huggingface.co/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained). ุณูููู ุฃูุถูุง ุจุชุญููู ุงููููุฐุฌ ุจูุตู ุงูุฏูุฉ (ุนูู ุณุจูู ุงููุซุงู `torch.float16`)ุ ุญูุซ ูุคุฏู ุฐูู ุฅูู ุชุฏููุฑ ุฌูุฏุฉ ุงูุตูุช ุจุดูู ุถุฆูู ุฌุฏูุง ููููู ูููู ุจุดูู ูุจูุฑ ูู ุงุณุชุฎุฏุงู ุงูุฐุงูุฑุฉ ูููุณุฑุน ุงูุงุณุชุฏูุงู:

```python
model = BarkModel.from_pretrained("suno/bark-small"ุ torch_dtype=torch.float16ุ attn_implementation="flash_attention_2").to(device)
```

##### ููุงุฑูุฉ ุงูุฃุฏุงุก

ููุถุญ ุงูุฑุณู ุงูุจูุงูู ุงูุชุงูู ุงููููู ูุชูููุฐ ุงูุงูุชูุงู ุงูุฃุตูู (ุจุฏูู ุชุญุณูู) ููุงุจู ูุญูู ุฃูุถู ูFlash Attention 2. ูู ุฌููุน ุงูุญุงูุงุชุ ูููู ุจุชูููุฏ 400 ุฑูุฒูุง ุฏูุงูููุง ุนูู GPU A100 ุจุณุนุฉ 40 ุฌูุฌุงุจุงูุช ุจุงุณุชุฎุฏุงู PyTorch 2.1. Flash Attention 2 ุฃุณุฑุน ุฃูุถูุง ูู ูุญูู ุฃูุถูุ ููุชุญุณู ุฃุฏุงุคู ุจุดูู ุฃูุจุฑ ูุน ุฒูุงุฏุฉ ุฃุญุฌุงู ุงูุฏููุนุงุช:

<div style="text-align: center">
<img src="https://huggingface.co/datasets/ylacombe/benchmark-comparison/resolve/main/Bark%20Optimization%20Benchmark.png">
</div>

ููุถุน ุฐูู ูู ุงูููุธูุฑุ ุนูู NVIDIA A100 ูุนูุฏ ุฅูุดุงุก 400 ุฑูุฒูุง ุฏูุงูููุง ุจุญุฌู ุฏูุนุฉ ูุจูุบ 16ุ ููููู ุงูุญุตูู ุนูู 17 ุถุนู [ุงูุณุฑุนุฉ](https://huggingface.co/blog/optimizing-bark#throughput) ููุง ุฒูุช ุฃุณุฑุน ูู ุฅูุดุงุก ุงูุฌูู ูุงุญุฏุฉ ุชูู ุงูุฃุฎุฑู ุจุงุณุชุฎุฏุงู ุชูููุฐ ุงููููุฐุฌ ุงูุฃุตูู. ูุจุนุจุงุฑุฉ ุฃุฎุฑูุ ุณูุชู ุฅูุดุงุก ุฌููุน ุงูุนููุงุช ุฃุณุฑุน 17 ูุฑุฉ.

ุจุญุฌู ุฏูุนุฉ ูุจูุบ 8ุ ุนูู NVIDIA A100ุ Flash Attention 2 ุฃุณุฑุน ุจูุณุจุฉ 10% ูู ูุญูู ุฃูุถูุ ูุจุญุฌู ุฏูุนุฉ ูุจูุบ 16ุ ุฃุณุฑุน ุจูุณุจุฉ 25%.

#### ุงูุฌูุน ุจูู ุชูููุงุช ุงูุชุญุณูู

ููููู ุงูุฌูุน ุจูู ุชูููุงุช ุงูุชุญุณููุ ูุงุณุชุฎุฏุงู ุชูุฑูุบ ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ ููุตู ุงูุฏูุฉ ูFlash Attention 2 (ุฃู ๐ค ูุญูู ุฃูุถู) ูู ููุช ูุงุญุฏ.

```python
from transformers import BarkModel
import torch

device = "cuda" if torch.cuda.is_available() else "cpu"

# ุชุญููู ูู fp16 ูุงุณุชุฎุฏุงู Flash Attention 2
model = BarkModel.from_pretrained("suno/bark-small", torch_dtype=torch.float16, attn_implementation="flash_attention_2").to(device)

# ุชูููู ุชูุฑูุบ ูุญุฏุฉ ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ
model.enable_cpu_offload()
```

ุงุนุฑู ุงููุฒูุฏ ุญูู ุชูููุงุช ุชุญุณูู ุงูุงุณุชุฏูุงู [ููุง](https://huggingface.co/docs/transformers/perf_infer_gpu_one).

### ูุตุงุฆุญ ุงูุงุณุชุฎุฏุงู

ุชูุฏู Suno ููุชุจุฉ ูู ุฅุนุฏุงุฏุงุช ุงูุตูุช ุจุนุฏุฏ ูู ุงููุบุงุช [ููุง](https://suno-ai.notion.site/8b8e8749ed514b0cbf3f699013548683?v=bc67cff786b04b50b3ceb756fd05f68c).
ุชู ุฃูุถูุง ุชุญููู ูุฐู ุงูุฅุนุฏุงุฏุงุช ุงููุณุจูุฉ ูู ุงููุฑูุฒ [ููุง](https://huggingface.co/suno/bark-small/tree/main/speaker_embeddings) ุฃู [ููุง](https://huggingface.co/suno/bark/tree/main/speaker_embeddings).

```python
>>> from transformers import AutoProcessor, BarkModel

>>> processor = AutoProcessor.from_pretrained("suno/bark")
>>> model = BarkModel.from_pretrained("suno/bark")

>>> voice_preset = "v2/en_speaker_6"

>>> inputs = processor("Hello, my dog is cute", voice_preset=voice_preset)

>>> audio_array = model.generate(**inputs)
>>> audio_array = audio_array.cpu().numpy().squeeze()
```

ูููู ูู Bark ุฅูุดุงุก ููุงู **ูุชุนุฏุฏ ุงููุบุงุช** ูุงูุนู ููุบุงูุฉ ุจุงูุฅุถุงูุฉ ุฅูู ุฃุตูุงุช ุฃุฎุฑู - ุจูุง ูู ุฐูู ุงูููุณููู ูุถุฌูุฌ ุงูุฎูููุฉ ูุงููุคุซุฑุงุช ุงูุตูุชูุฉ ุงูุจุณูุทุฉ.

```py
>>> # Multilingual speech - simplified Chinese
>>> inputs = processor("ๆไบบ็๏ผๆไผ่ฏดไธญๆ")

>>> # Multilingual speech - French - let's use a voice_preset as well
>>> inputs = processor("Incroyable! Je peux gรฉnรฉrer du son.", voice_preset="fr_speaker_5")

>>> # Bark can also generate music. You can help it out by adding music notes around your lyrics.
>>> inputs = processor("โช Hello, my dog is cute โช")

>>> audio_array = model.generate(**inputs)
>>> audio_array = audio_array.cpu().numpy().squeeze()
```

ูููู ูููููุฐุฌ ุฃูุถูุง ุฅูุชุงุฌ ุงุชุตุงูุงุช **ุบูุฑ ููุธูุฉ** ูุซู ุงูุถุญู ูุงูุชููุฏ ูุงูุจูุงุก.

```python
>>> # Adding non-speech cues to the input text
>>> inputs = processor("Hello uh ... [clears throat], my dog is cute [laughter]")

>>> audio_array = model.generate(**inputs)
>>> audio_array = audio_array.cpu().numpy().squeeze()
```

ูุญูุธ ุงูุตูุชุ ูุง ุนููู ุณูู ุฃุฎุฐ ูุนุฏู ุงูุนููุฉ ูู ุชูููู ุงููููุฐุฌ ูุจุนุถ ุจุฑุงูุฌ ูุณุงุนุฏุฉ SciPy:

```python
>>> from scipy.io.wavfile import write as write_wav

>>> # ุญูุธ ุงูุตูุช ุนูู ุงููุฑุตุ ูููู ุฃููุงู ุฎุฐ ูุนุฏู ุงูุนููุฉ ูู ุชูููู ุงููููุฐุฌ
>>> sample_rate = model.generation_config.sample_rate
>>> write_wav("bark_generation.wav", sample_rate, audio_array)
```

## BarkConfig

[[autodoc]] BarkConfig
- all

## BarkProcessor

[[autodoc]] BarkProcessor
- all
- __call__

## BarkModel

[[autodoc]] BarkModel
- generate
- enable_cpu_offload

## BarkSemanticModel

[[autodoc]] BarkSemanticModel
- forward

## BarkCoarseModel

[[autodoc]] BarkCoarseModel
- forward

## BarkFineModel

[[autodoc]] BarkFineModel
- forward

## BarkCausalModel

[[autodoc]] BarkCausalModel
- forward

## BarkCoarseConfig

[[autodoc]] BarkCoarseConfig
- all

## BarkFineConfig

[[autodoc]] BarkFineConfig
- all

## BarkSemanticConfig

[[autodoc]] BarkSemanticConfig
- all