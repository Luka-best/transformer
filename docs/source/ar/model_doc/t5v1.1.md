# T5v1.1

## نظرة عامة
تم إصدار T5v1.1 في مستودع [google-research/text-to-text-transfer-transformer](https://github.com/google-research/text-to-text-transfer-transformer/blob/main/released_checkpoints.md#t511) بواسطة Colin Raffel وآخرين. إنه نسخة محسنة من نموذج T5 الأصلي.
تمت المساهمة بهذا النموذج من قبل [patrickvonplaten](https://huggingface.co/patrickvonplaten). يمكن العثور على الكود الأصلي [هنا](https://github.com/google-research/text-to-text-transfer-transformer/blob/main/released_checkpoints.md#t511).

## نصائح الاستخدام
يمكنك توصيل أوزان T5v1.1 مباشرة في نموذج T5، كما هو موضح أدناه:

```python
>>> from transformers import T5ForConditionalGeneration

>>> model = T5ForConditionalGeneration.from_pretrained("google/t5-v1_1-base")
```

تتضمن نسخة T5 1.1 التحسينات التالية مقارنة بنموذج T5 الأصلي:

- تنشيط GEGLU في الطبقة المخفية للأمامي، بدلاً من ReLU. راجع [هذه الورقة](https://arxiv.org/abs/2002.05202).
- تم إيقاف تشغيل Dropout أثناء التدريب المسبق (تحسين الجودة). يجب إعادة تمكين Dropout أثناء الضبط الدقيق.
- تم التدريب المسبق على C4 فقط دون مزج المهام النهائية.
- لا يوجد مشاركة للثوابت بين طبقة التضمين وطبقة التصنيف.
- يستبدل "xl" و "xxl" "3B" و "11B". تختلف أشكال النموذج قليلاً - `d_model` أكبر و `num_heads` و `d_ff` أصغر.

ملاحظة: تم التدريب المسبق لنسخة T5 1.1 فقط على [C4](https://huggingface.co/datasets/c4) مع استبعاد أي تدريب إشرافي. لذلك، يجب ضبط هذا النموذج بشكل دقيق قبل استخدامه في مهمة نهائية، على عكس نموذج T5 الأصلي. نظرًا لأن t5v1.1 تم تدريبه بدون إشراف، فلا توجد ميزة حقيقية لاستخدام بادئة المهمة أثناء الضبط الدقيق الأحادي. إذا كنت تقوم بالضبط الدقيق متعدد المهام، فيجب عليك استخدام بادئة.

أصدرت Google المتغيرات التالية:

- [google/t5-v1_1-small](https://huggingface.co/google/t5-v1_1-small)
- [google/t5-v1_1-base](https://huggingface.co/google/t5-v1_1-base)
- [google/t5-v1_1-large](https://huggingface.co/google/t5-v1_1-large)
- [google/t5-v1_1-xl](https://huggingface.co/google/t5-v1_1-xl)
- [google/t5-v1_1-xxl](https://huggingface.co/google/t5-v1_1-xxl).

<Tip>
راجع [صفحة وثائق T5](t5) للحصول على جميع المراجع API والنصائح وأمثلة التعليمات البرمجية والمفكرات.
</Tip>

ترجمة الأجزاء المطلوبة:

# T5v1.1

## نظرة عامة
أطلق كولين رافيل وآخرون إصدار T5v1.1 في مستودع [google-research/text-to-text-transfer-transformer](https://github.com/google-research/text-to-text-transfer-transformer/blob/main/released_checkpoints.md#t511). إنه نسخة محسنة من نموذج T5 الأصلي.
ساهم في هذا النموذج [باتريك فون بلاتين](https://huggingface.co/patrickvonplaten). ويمكن الاطلاع على الكود الأصلي [هنا](https://github.com/google-research/text-to-text-transfer-transformer/blob/main/released_checkpoints.md#t511).

## نصائح الاستخدام
يمكنك استخدام أوزان T5v1.1 مباشرة في نموذج T5، كما يلي:

```python
>>> from transformers import T5ForConditionalGeneration

>>> model = T5ForConditionalGeneration.from_pretrained("google/t5-v1_1-base")
```

تتضمن نسخة T5 1.1 التحسينات التالية مقارنة بنموذج T5 الأصلي:

- تنشيط GEGLU في الطبقة المخفية للأمامي، بدلاً من ReLU. راجع [هذه الورقة](https://arxiv.org/abs/2002.05202).
- تم إيقاف تشغيل Dropout أثناء التدريب المسبق (تحسين الجودة). يجب إعادة تشغيل Dropout أثناء الضبط الدقيق.
- تم التدريب المسبق على C4 فقط دون مزج المهام النهائية.
- لا توجد مشاركة للثوابت بين طبقة التضمين وطبقة التصنيف.
- يستبدل "xl" و "xxl" "3B" و "11B". تختلف أشكال النموذج قليلاً - `d_model` أكبر و `num_heads` و `d_ff` أصغر.

ملاحظة: تم التدريب المسبق لنسخة T5 1.1 فقط على [C4](https://huggingface.co/datasets/c4) مع استبعاد أي تدريب إشرافي. لذلك، يجب ضبط هذا النموذج بشكل دقيق قبل استخدامه في مهمة نهائية، على عكس نموذج T5 الأصلي. نظرًا لأن T5v1.1 تم تدريبه بدون إشراف، فلا توجد فائدة حقيقية من استخدام بادئة المهمة أثناء الضبط الدقيق الأحادي. إذا كنت تقوم بالضبط الدقيق متعدد المهام، فيجب عليك استخدام بادئة.

أصدرت جوجل المتغيرات التالية:

- [google/t5-v1_1-small](https://huggingface.co/google/t5-v1_1-small)
- [google/t5-v1_1-base](https://huggingface.co/google/t5-v1_1-base)
- [google/t5-v1_1-large](https://huggingface.co/google/t5-v1_1-large)
- [google/t5-v1_1-xl](https://huggingface.co/google/t5-v1_1-xl)
- [google/t5-v1_1-xxl](https://huggingface.co/google/t5-v1_1-xxl).

<Tip>
راجع [صفحة وثائق T5](t5) للحصول على جميع مراجع API والنصائح وأمثلة التعليمات البرمجية والمفكرات.
</Tip>