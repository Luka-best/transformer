# Wav2Vec2

## ูุธุฑุฉ ุนุงูุฉ
ุชู ุงูุชุฑุงุญ ูููุฐุฌ Wav2Vec2 ูู [wav2vec 2.0: ุฅุทุงุฑ ููุชุนูู ุงูุฐุงุชู ูุชูุซููุงุช ุงูููุงู](https://arxiv.org/abs/2006.11477) ุจูุงุณุทุฉ Alexei Baevski ูHenry Zhou ูAbdelrahman Mohamed ูMichael Auli.

ุงูููุฎุต ูู ุงููุฑูุฉ ูู ูุง ููู:

> ููุธูุฑ ูููุฑุฉ ุงูุฃููู ุฃู ุชุนูู ุงูุชูุซููุงุช ุงููููุฉ ูู ุตูุช ุงูููุงู ูุญุฏูุ ุซู ุงูุถุจุท ุงูุฏููู ุนูู ุงูููุงู ุงููููููุ ูููู ุฃู ูุชููู ุนูู ุฃูุถู ุงูุทุฑู ุดุจู ุงูููุดุฑู ุนูููุง ูุน ููููุง ุฃุจุณุท ูู ุงููุงุญูุฉ ุงูููุงููููุฉ. ูููู Wav2Vec 2.0 ุจููุงุน ุฅุฏุฎุงู ุงูููุงู ูู ุงููุถุงุก ุงููุงูู ููุญู ูููุฉ ุงูุชุจุงูู ุงููุญุฏุฏุฉ ุนูู ููููุฉ ูู ุงูุชูุซููุงุช ุงููุงููุฉ ุงูุชู ูุชู ุชุนูููุง ุจุดูู ูุดุชุฑู. ุชุญูู ุงูุชุฌุงุฑุจ ุงูุชู ุชุณุชุฎุฏู ุฌููุน ุงูุจูุงูุงุช ุงููููุณููุฉ ูู Librispeech ูุณุจุฉ ุฎุทุฃ ูููุฉ ุชุจูุบ 1.8/3.3% ุนูู ูุฌููุนุงุช ุงูุงุฎุชุจุงุฑ ุงููุธููุฉ/ุงูุฃุฎุฑู. ุนูุฏูุง ูุชู ุชูููู ูููุฉ ุงูุจูุงูุงุช ุงูููุณููุฉ ุฅูู ุณุงุนุฉ ูุงุญุฏุฉุ ูุชููู Wav2Vec 2.0 ุนูู ุงูุญุงูุฉ ุงูุณุงุจูุฉ ูููู ูู ุงููุฌููุนุฉ ุงููุฑุนูุฉ ุงูุชู ุชุจูุบ 100 ุณุงุนุฉ ูุน ุงุณุชุฎุฏุงู 100 ุถุนู ุงูุจูุงูุงุช ุงูููุณููุฉ. ูุง ูุฒุงู ุงุณุชุฎุฏุงู 10 ุฏูุงุฆู ููุท ูู ุงูุจูุงูุงุช ุงูููุณููุฉ ูุงูุชุนูู ุงููุณุจู ุนูู 53000 ุณุงุนุฉ ูู ุงูุจูุงูุงุช ุบูุฑ ุงูููุณููุฉ ูุญูู ูุณุจุฉ 4.8/8.2% ูู ุฎุทุฃ ุงููููุฉ. ูุซุจุช ูุฐุง ุฌุฏูู ุงูุชุนุฑู ุนูู ุงูููุงู ุจูููุงุช ูุญุฏูุฏุฉ ูู ุงูุจูุงูุงุช ุงูููุณููุฉ.

ุชูุช ุงููุณุงููุฉ ุจูุฐุง ุงููููุฐุฌ ูู ูุจู [patrickvonplaten](https://huggingface.co/patrickvonplaten).

ููุงุญุธุฉ: ุฃุตุฏุฑุช Meta (FAIR) ุฅุตุฏุงุฑูุง ุฌุฏูุฏูุง ูู [Wav2Vec2-BERT 2.0](https://huggingface.co/docs/transformers/en/model_doc/wav2vec2-bert) - ููู ููุนูู ูุณุจููุง ุนูู 4.5 ููููู ุณุงุนุฉ ูู ุงูุตูุช. ููุตู ุจุดูู ุฎุงุต ุจุงุณุชุฎุฏุงูู ูููุงู ุงูุถุจุท ุงูุฏูููุ ุนูู ุณุจูู ุงููุซุงู ููุง ูู ููุถุญ ูู [ูุฐุง ุงูุฏููู](https://huggingface.co/blog/fine-tune-w2v2-bert).

## ูุตุงุฆุญ ุงูุงุณุชุฎุฏุงู

- Wav2Vec2 ูู ูููุฐุฌ ููุงู ููุจู ูุตูููุฉ ุนุงุฆูุฉ ุชุชูุงูู ูุน ุงูุดูู ุงูููุฌู ุงูุฎุงู ูุฅุดุงุฑุฉ ุงูููุงู.

- ุชู ุชุฏุฑูุจ ูููุฐุฌ Wav2Vec2 ุจุงุณุชุฎุฏุงู ุงูุชุตููู ุงูุฒููู ููุงุชุตุงู (CTC)ุ ูุฐูู ูุฌุจ ูู ุชุดููุฑ ุฅุฎุฑุงุฌ ุงููููุฐุฌ ุจุงุณุชุฎุฏุงู [`Wav2Vec2CTCTokenizer`].

## ุงุณุชุฎุฏุงู Flash Attention 2

Flash Attention 2 ูู ุฅุตุฏุงุฑ ุฃุณุฑุน ูุฃูุซุฑ ุชุญุณูููุง ูู ุงููููุฐุฌ.

### ุงูุชุซุจูุช

ุฃููุงูุ ุชุญูู ููุง ุฅุฐุง ูุงู ุงูุฃุฌูุฒุฉ ุงูุฎุงุตุฉ ุจู ูุชูุงููุฉ ูุน Flash Attention 2. ูููู ุงูุนุซูุฑ ุนูู ุฃุญุฏุซ ูุงุฆูุฉ ูู ุงูุฃุฌูุฒุฉ ุงููุชูุงููุฉ ูู [ุงููุซุงุฆู ุงูุฑุณููุฉ](https://github.com/Dao-AILab/flash-attention#installation-and-features). ุฅุฐุง ูู ููู ุงูุฃุฌูุฒุฉ ุงูุฎุงุต ุจู ูุชูุงูููุง ูุน Flash Attention 2ุ ูููููู ุงูุงุณุชูุงุฏุฉ ูู ุชุญุณููุงุช ููุงุฉ ุงูุงูุชูุงู ูู ุฎูุงู ุฏุนู Transformer ุงูุฃูุถู ุงููุดูููุฉ [ุฃุนูุงู](https://huggingface.co/docs/transformers/main/en/model_doc/bark#using-better-transformer).

ุจุนุฏ ุฐููุ ูู ุจุชุซุจูุช ุฃุญุฏุซ ุฅุตุฏุงุฑ ูู Flash Attention 2:

```bash
pip install -U flash-attn --no-build-isolation
```

### ุงูุงุณุชุฎุฏุงู

ูุชุญููู ูููุฐุฌ ุจุงุณุชุฎุฏุงู Flash Attention 2ุ ูููููุง ุชูุฑูุฑ ุงูุญุฌุฉ `attn_implementation="flash_attention_2"` ุฅูู [`.from_pretrained`](https://huggingface.co/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained). ุณูููู ุฃูุถูุง ุจุชุญููู ุงููููุฐุฌ ูู ูุตู ุงูุฏูุฉ (ุนูู ุณุจูู ุงููุซุงู `torch.float16`)ุ ุญูุซ ูุคุฏู ุฐูู ุฅูู ุชูููู ุงุณุชุฎุฏุงู ุงูุฐุงูุฑุฉ ูุณุฑุนุฉ ุงูุงุณุชุฏูุงู ุจุดูู ูุจูุฑ ูุน ุนุฏู ูุฌูุฏ ุชุฏููุฑ ุชูุฑูุจูุง ูู ุฌูุฏุฉ ุงูุตูุช:

```python
>>> from transformers import Wav2Vec2Model

model = Wav2Vec2Model.from_pretrained("facebook/wav2vec2-large-960h-lv60-self", torch_dtype=torch.float16, attn_implementation="flash_attention_2").to(device)
...
```

### ุชุณุฑูุน ุงูุฃุฏุงุก ุงููุชููุน

ูููุง ููู ุฑุณู ุจูุงูู ูุชุณุฑูุน ุงูุฃุฏุงุก ุงููุชููุน ุงูุฐู ููุงุฑู ููุช ุงูุงุณุชุฏูุงู ุงูููู ุจูู ุงูุชูููุฐ ุงูุฃุตูู ูู ุงููุญููุงุช ููููุฐุฌ `facebook/wav2vec2-large-960h-lv60-self` ูุฅุตุฏุงุฑุงุช flash-attention-2 ูsdpa (scale-dot-product-attention). . ูุนุฑุถ ูุชูุณุท ุงูุชุณุฑูุน ุงูุฐู ุชู ุงูุญุตูู ุนููู ุนูู ุชูุณูู ุงูุชุญูู ูู `librispeech_asr` `clean`:

<div style="text-align: center">
<img src="https://huggingface.co/datasets/kamilakesbi/transformers_image_doc/resolve/main/data/Wav2Vec2_speedup.png">
</div>

## ุงูููุงุฑุฏ

ูุงุฆูุฉ ุจููุงุฑุฏ Hugging Face ุงูุฑุณููุฉ ูููุงุฑุฏ ุงููุฌุชูุน (ูุดุงุฑ ุฅูููุง ุจุฑูุฒ ๐) ููุณุงุนุฏุชู ูู ุงูุจุฏุก ุจุงุณุชุฎุฏุงู Wav2Vec2. ุฅุฐุง ููุช ููุชููุง ุจุชูุฏูู ููุฑุฏ ูุฅุฏุฑุงุฌู ููุงุ ููุฑุฌู ูุชุญ ุทูุจ ุณุญุจ ูุณูุฑุงุฌุนู! ูุฌุจ ุฃู ูุซุจุช ุงูููุฑุฏ ุจุดูู ูุซุงูู ุดูุฆูุง ุฌุฏูุฏูุง ุจุฏูุงู ูู ุชูุฑุงุฑ ููุฑุฏ ููุฌูุฏ.

<PipelineTag pipeline="audio-classification"/>

- ุฏูุชุฑ ููุงุญุธุงุช ุญูู ููููุฉ [ุงูุงุณุชูุงุฏุฉ ูู ูููุฐุฌ Wav2Vec2 ุงููุนูู ูุณุจููุง ูุชุตููู ุงููุดุงุนุฑ](https://colab.research.google.com/github/m3hrdadfi/soxan/blob/main/notebooks/Emotion_recognition_in_Greek_speech_using_Wav2Vec2.ipynb). ๐

- [`Wav2Vec2ForCTC`] ูุฏุนูู ุจูุงุณุทุฉ [ูุซุงู ุงููุต ุงูุจุฑูุฌู](https://github.com/huggingface/transformers/tree/main/examples/pytorch/audio-classification) ู [ุฏูุชุฑ ุงูููุงุญุธุงุช](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/audio_classification.ipynb).

- [ุฏููู ูููุฉ ุชุตููู ุงูุตูุช](../tasks/audio_classification)

<PipelineTag pipeline="automatic-speech-recognition"/>

- ููุดูุฑ ูุฏููุฉ ุญูู [ุชุนุฒูุฒ Wav2Vec2 ูุน n-grams ูู ๐ค Transformers](https://huggingface.co/blog/wav2vec2-with-ngram).

- ููุดูุฑ ูุฏููุฉ ุญูู ููููุฉ [ุงูุถุจุท ุงูุฏููู ูู Wav2Vec2 ููุชุนุฑู ุงูุชููุงุฆู ุนูู ุงูููุงู ุจุงููุบุฉ ุงูุฅูุฌููุฒูุฉ ุจุงุณุชุฎุฏุงู ๐ค Transformers](https://huggingface.co/blog/fine-tune-wav2vec2-english).

- ููุดูุฑ ูุฏููุฉ ุญูู [ุงูุถุจุท ุงูุฏููู ูู XLS-R ููุชุนุฑู ุงูุชููุงุฆู ุนูู ุงูููุงู ูุชุนุฏุฏ ุงููุบุงุช ุจุงุณุชุฎุฏุงู ๐ค Transformers](https://huggingface.co/blog/fine-tune-xlsr-wav2vec2).

- ุฏูุชุฑ ููุงุญุธุงุช ุญูู ููููุฉ [ุฅูุดุงุก ุชุนูููุงุช ุชูุถูุญูุฉ ูู YouTube ูุฃู ููุฏูู ุนู ุทุฑูู ูุณุฎ ุตูุช ุงูููุฏูู ุจุงุณุชุฎุฏุงู Wav2Vec2](https://colab.research.google.com/github/Muennighoff/ytclipcc/blob/main/wav2vec_youtube_captions.ipynb). ๐

- [`Wav2Vec2ForCTC`] ูุฏุนูู ูู ูุจู ุฏูุชุฑ ููุงุญุธุงุช ุญูู ููููุฉ [ุงูุถุจุท ุงูุฏููู ููููุฐุฌ ุงูุชุนุฑู ุนูู ุงูููุงู ุจุงููุบุฉ ุงูุฅูุฌููุฒูุฉ](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/speech_recognition.ipynb)ุ ู [ููููุฉ ุงูุถุจุท ุงูุฏููู ููููุฐุฌ ุงูุชุนุฑู ุนูู ุงูููุงู ุจุฃู ูุบุฉ](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multi_lingual_speech_recognition.ipynb).

- [ุฏููู ูููุฉ ุงูุชุนุฑู ุงูุชููุงุฆู ุนูู ุงูููุงู](../tasks/asr)

๐ ุงููุดุฑ

- ููุดูุฑ ูุฏููุฉ ุญูู ููููุฉ ูุดุฑ Wav2Vec2 ูู [ุงูุชุนุฑู ุงูุชููุงุฆู ุนูู ุงูููุงู ุจุงุณุชุฎุฏุงู ูุญููุงุช Hugging Face ูAmazon SageMaker](https://www.philschmid.de/automatic-speech-recognition-sagemaker).

## Wav2Vec2Config

[[autodoc]] Wav2Vec2Config

## Wav2Vec2CTCTokenizer

[[autodoc]] Wav2Vec2CTCTokenizer

- __call__
- save_vocabulary
- decode
- batch_decode
- set_target_lang

## Wav2Vec2FeatureExtractor

[[autodoc]] Wav2Vec2FeatureExtractor

- __call__

## Wav2Vec2Processor

[[autodoc]] Wav2Vec2Processor

- __call__
- pad
- from_pretrained
- save_pretrained
- batch_decode
- decode

## Wav2Vec2ProcessorWithLM

[[autodoc]] Wav2Vec2ProcessorWithLM

- __call__
- pad
- from_pretrained
- save_pretrained
- batch_decode
- decode

### ูู ุชุดููุฑ ููุงุทุน ุตูุชูุฉ ูุชุนุฏุฏุฉ

ุฅุฐุง ููุช ุชุฎุทุท ููู ุชุดููุฑ ุฏูุนุงุช ูุชุนุฏุฏุฉ ูู ุงูููุงุทุน ุงูุตูุชูุฉุ ููุฌุจ ุนููู ุงููุธุฑ ูู ุงุณุชุฎุฏุงู [`~Wav2Vec2ProcessorWithLM.batch_decode`] ูุชูุฑูุฑ `multiprocessing.Pool` ูุซุจุช.

ูู ุญุงูุฉ ุนุฏู ุฐููุ ุณุชููู ุณุฑุนุฉ ุฃุฏุงุก [`~Wav2Vec2ProcessorWithLM.batch_decode`] ุฃุจุทุฃ ูู ุงุณุชุฏุนุงุก [`~Wav2Vec2ProcessorWithLM.decode`] ููู ููุทุน ุตูุชู ุจุดูู ูุฑุฏูุ ุญูุซ ูููู ุจุฅูุดุงุก ูุซูู ูุฑุนู ุฌุฏูุฏ ูู `Pool` ููู ุงุณุชุฏุนุงุก. ุฑุงุฌุน ุงููุซุงู ุฃุฏูุงู:

```python
>>> # ุฏุนููุง ูุฑู ููููุฉ ุงุณุชุฎุฏุงู ุจุฑูุฉ ูุฏูุฑูุง ุงููุณุชุฎุฏู ููุชุฑููุฒ ุงูุฏูุนู ููููุงุทุน ุงูุตูุชูุฉ ุงููุชุนุฏุฏุฉ
>>> from multiprocessing import get_context
>>> from transformers import AutoTokenizer, AutoProcessor, AutoModelForCTC
>>> from datasets import load_dataset
>>> import datasets
>>> import torch

>>> # ุงุณุชูุฑุงุฏ ุงููููุฐุฌ ููุณุชุฎุฑุฌ ุงูููุฒุงุช ููุญูู ุงูุฑููุฒ
>>> model = AutoModelForCTC.from_pretrained("patrickvonplaten/wav2vec2-base-100h-with-lm").to("cuda")
>>> processor = AutoProcessor.from_pretrained("patrickvonplaten/wav2vec2-base-100h-with-lm")

>>> # ุชุญููู ูุฌููุนุฉ ุจูุงูุงุช ุงููุซุงู
>>> dataset = load_dataset("hf-internal-testing/librispeech_asr_dummy", "clean", split="validation")
>>> dataset = dataset.cast_column("audio", datasets.Audio(sampling_rate=16_000))


>>> def map_to_array(batch):
...     batch["speech"] = batch["audio"]["array"]
...     return batch


>>> # ุฅุนุฏุงุฏ ุจูุงูุงุช ุงูููุงู ููุงุณุชุฏูุงู ุงูุฏูุนู
>>> dataset = dataset.map(map_to_array, remove_columns=["audio"])


>>> def map_to_pred(batch, pool):
...     inputs = processor(batch["speech"], sampling_rate=16_000, padding=True, return_tensors="pt")
...     inputs = {k: v.to("cuda") for k, v in inputs.items()}

...     with torch.no_grad():
...         logits = model(**inputs).logits

...     transcription = processor.batch_decode(logits.cpu().numpy(), pool).text
...     batch["transcription"] = transcription
...     return batch


>>> # ููุงุญุธุฉ: ูุฌุจ ุฅูุดุงุก ุงูุจุฑูุฉ *ุจุนุฏ* `Wav2Vec2ProcessorWithLM`.
>>> # ูู ุญุงูุฉ ุนุฏู ุฐููุ ูู ุชููู ูุบุฉ ุงูููุฐุฌุฉ ูุชุงุญุฉ ููุนูููุงุช ุงููุฑุนูุฉ ููุจุฑูุฉ.
>>> # ุญุฏุฏ ุนุฏุฏ ุงูุนูููุงุช ูุญุฌู ุงูุฏูุนุฉ ุจูุงุกู ุนูู ุนุฏุฏ ูุญุฏุงุช ุงููุนุงูุฌุฉ ุงููุฑูุฒูุฉ ุงููุชููุฑุฉ ูุญุฌู ูุฌููุนุฉ ุงูุจูุงูุงุช
>>> with get_context("fork").Pool(processes=2) as pool:
...     result = dataset.map(
...         map_to_pred, batched=True, batch_size=2, fn_kwargs={"pool": pool}, remove_columns=["speech"]
...     )

>>> result["transcription"][:2]
['MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL', "NOR IS MISTER COULTER'S MANNER LESS INTERESTING THAN HIS MATTER"]
```

## ูุฎุฑุฌุงุช Wav2Vec2 ุงููุญุฏุฏุฉ

[[autodoc]] models.wav2vec2_with_lm.processing_wav2vec2_with_lm.Wav2Vec2DecoderWithLMOutput

[[autodoc]] models.wav2vec2.modeling_wav2vec2.Wav2Vec2BaseModelOutput

[[autodoc]] models.wav2vec2.modeling_wav2vec2.Wav2Vec2ForPreTrainingOutput

[[autodoc]] models.wav2vec2.modeling_flax_wav2vec2.FlaxWav2Vec2BaseModelOutput

[[autodoc]] models.wav2vec2.modeling_flax_wav2vec2.FlaxWav2Vec2ForPreTrainingOutput

<frameworkcontent>

<pt>

## Wav2Vec2Model

[[autodoc]] Wav2Vec2Model

- forward

## Wav2Vec2ForCTC

[[autodoc]] Wav2Vec2ForCTC

- forward
- load_adapter

## Wav2Vec2ForSequenceClassification

[[autodoc]] Wav2Vec2ForSequenceClassification

- forward

## Wav2Vec2ForAudioFrameClassification

[[autodoc]] Wav2Vec2ForAudioFrameClassification

- forward

## Wav2Vec2ForXVector

[[autodoc]] Wav2Vec2ForXVector

- forward

## Wav2Vec2ForPreTraining

[[autodoc]] Wav2Vec2ForPreTraining

- forward

</pt>

<tf>

## TFWav2Vec2Model

[[autodoc]] TFWav2Vec2Model

- call

## TFWav2Vec2ForSequenceClassification

[[autodoc]] TFWav2Vec2ForSequenceClassification

- call

## TFWav2Vec2ForCTC

[[autodoc]] TFWav2Vec2ForCTC

- call

</tf>

<jax>

## FlaxWav2Vec2Model

[[autodoc]] FlaxWav2Vec2Model

- __call__

## FlaxWav2Vec2ForCTC

[[autodoc]] FlaxWav2Vec2ForCTC

- __call__

## FlaxWav2Vec2ForPreTraining

[[autodoc]] FlaxWav2Vec2ForPreTraining

- __call__

</jax>

</frameworkcontent>