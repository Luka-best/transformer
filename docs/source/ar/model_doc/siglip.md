# SigLIP

## ูุธุฑุฉ ุนุงูุฉ
ุชู ุงูุชุฑุงุญ ูููุฐุฌ SigLIP ูู [Sigmoid Loss for Language Image Pre-Training](https://arxiv.org/abs/2303.15343) ุจูุงุณุทุฉ Xiaohua Zhai ูBasil Mustafa ูAlexander Kolesnikov ูLucas Beyer. ูููุชุฑุญ SigLIP ุงุณุชุจุฏุงู ุฏุงูุฉ ุงูุฎุณุงุฑุฉ ุงููุณุชุฎุฏูุฉ ูู [CLIP](clip) ุจุฎุณุงุฑุฉ Sigmoid ุซูุงุฆูุฉ ุจุณูุทุฉ. ููุคุฏู ุฐูู ุฅูู ุชุญุณูู ุงูุฃุฏุงุก ูู ุญูุซ ุฏูุฉ ุงูุชุตููู ุจุฏูู ุงูุฅุดุฑุงู ุนูู ImageNet.

ููุฏูุฉ ุงููุฑูุฉ ุงูุจุญุซูุฉ ูู ููุง ููู:

*ููุชุฑุญ ุฎุณุงุฑุฉ Sigmoid ุซูุงุฆูุฉ ุจุณูุทุฉ ููุชุนูู ุงูุชูููุฏู ููุบุฉ ูุงูุตูุฑุฉ (SigLIP). ุนูู ุนูุณ ุงูุชุนูู ุงูุชูููุฒู ุงูููุงุณู ูุน ุงูุชุทุจูุน Softmaxุ ุชุนูู ุฎุณุงุฑุฉ Sigmoid ููุท ุนูู ุฃุฒูุงุฌ ุงูุตูุฑ ูุงููุตูุต ููุง ุชุชุทูุจ ุฑุคูุฉ ุดุงููุฉ ููุชุดุงุจูุงุช ุงูุซูุงุฆูุฉ ูุฃุบุฑุงุถ ุงูุชุทุจูุน. ุชุณูุญ ุฎุณุงุฑุฉ Sigmoid ุฃูุถูุง ุจุฒูุงุฏุฉ ุญุฌู ุงูุฏูุนุฉ ูู ููุณ ุงูููุชุ ูุน ุชุญุณูู ุงูุฃุฏุงุก ุนูุฏ ุฃุญุฌุงู ุฏูุนุงุช ุฃุตุบุฑ. ูุจุงูุงูุชุฑุงู ูุน ุถุจุท ุงูุตูุฑุฉ ุงูููููุฉุ ุจุงุณุชุฎุฏุงู ุฃุฑุจุน ุดุฑุงุฆุญ TPUv4 ููุทุ ูููู ุจุชุฏุฑูุจ ูููุฐุฌ SigLiT ูุญูู ุฏูุฉ 84.5ูช ุนูู ImageNet ุจุฏูู ุฅุดุฑุงู ูู ููููู. ููุง ูุณูุญ ูุตู ุญุฌู ุงูุฏูุนุฉ ุนู ุงูุฎุณุงุฑุฉ ูุฏุฑุงุณุฉ ุชุฃุซูุฑ ุงูุฃูุซูุฉ ููุงุจู ุงูุฃุฒูุงุฌ ููุณุจุฉ ุงูุณูุจูุงุช ุฅูู ุงูุฅูุฌุงุจูุงุช. ูุฃุฎูุฑูุงุ ูููู ุจุฏูุน ุญุฌู ุงูุฏูุนุฉ ุฅูู ุฃูุตู ุญุฏุ ุญุชู ูููููุ ููุฌุฏ ุฃู ููุงุฆุฏ ุฒูุงุฏุฉ ุญุฌู ุงูุฏูุนุฉ ุชุชูุงุดู ุจุณุฑุนุฉุ ุญูุซ ูููู ุญุฌู ุงูุฏูุนุฉ ุงููุนููู 32 ุฃูููุง ูุงูููุง.*

## ูุตุงุฆุญ ุงูุงุณุชุฎุฏุงู

- ุงุณุชุฎุฏุงู SigLIP ูุดุงุจู ูู [CLIP](clip). ุงููุฑู ุงูุฑุฆูุณู ูู ุฎุณุงุฑุฉ ุงูุชุฏุฑูุจุ ูุงูุชู ูุง ุชุชุทูุจ ุฑุคูุฉ ุดุงููุฉ ูุฌููุน ุงูุชุดุงุจูุงุช ุงูุซูุงุฆูุฉ ููุตูุฑ ูุงููุตูุต ุฏุงุฎู ุฏูุนุฉ. ูุฌุจ ุชุทุจูู ุฏุงูุฉ ุงูุชูุดูุท Sigmoid ุนูู logitsุ ุจุฏูุงู ูู Softmax.

- ูุง ูุชู ุฏุนู ุงูุชุฏุฑูุจ ุจุนุฏ. ุฅุฐุง ููุช ุชุฑุบุจ ูู ุถุจุท ูููุฐุฌ SigLIP ุฃู ุงูุชุฏุฑูุจ ูู ุงูุตูุฑุ ุฑุงุฌุน ุฏุงูุฉ ุงูุฎุณุงุฑุฉ ูู [OpenCLIP](https://github.com/mlfoundations/open_clip/blob/73ad04ae7fb93ede1c02dc9040a828634cb1edf1/src/open_clip/loss.py#L307)ุ ูุงูุชู ุชุณุชููุฏ ูู ูุฎุชูู ุงููุฑุงูู `torch.distributed`.

- ุนูุฏ ุงุณุชุฎุฏุงู [`SiglipTokenizer`] ุฃู [`SiglipProcessor`] ุงููุณุชููููุ ุชุฃูุฏ ูู ุชูุฑูุฑ `padding="max_length"` ุญูุซ ุชู ุชุฏุฑูุจ ุงููููุฐุฌ ุจูุฐู ุงูุทุฑููุฉ.

<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/model_doc/siglip_table.jpeg"
alt="drawing" width="600"/>

<small> ูุชุงุฆุฌ ุชูููู SigLIP ููุงุฑูุฉ ุจู CLIP. ูุฃุฎูุฐุฉ ูู <a href="https://arxiv.org/abs/2303.15343">ุงููุฑูุฉ ุงูุจุญุซูุฉ ุงูุฃุตููุฉ</a>.</small>

ุชูุช ุงููุณุงููุฉ ุจูุฐุง ุงููููุฐุฌ ุจูุงุณุทุฉ [nielsr](https://huggingface.co/nielsr).
ูููู ุงูุนุซูุฑ ุนูู ุงูููุฏ ุงูุฃุตูู [ููุง](https://github.com/google-research/big_vision/tree/main).

## ูุซุงู ุงูุงุณุชุฎุฏุงู

ููุงู ุทุฑููุชุงู ุฑุฆูุณูุชุงู ูุงุณุชุฎุฏุงู SigLIP: ุฅูุง ุจุงุณุชุฎุฏุงู ูุงุฌูุฉ ุจุฑูุฌุฉ ุงูุชุทุจููุงุช ุงูุฎุงุตุฉ ุจุงูุฎุทูุท ุงูุฃูุงุจูุจุ ูุงูุชู ุชูุฌุฑููุฏ ูู ุงูุชุนููุฏ ูู ุฃุฌููุ ุฃู ุจุงุณุชุฎุฏุงู ูุฆุฉ `SiglipModel` ุจููุณู.

### ูุงุฌูุฉ ุจุฑูุฌุฉ ุงูุชุทุจููุงุช ุงูุฎุงุตุฉ ุจุงูุฎุทูุท ุงูุฃูุงุจูุจ

ุชุณูุญ ูุงุฌูุฉ ุจุฑูุฌุฉ ุงูุชุทุจููุงุช ุจุงุณุชุฎุฏุงู ุงููููุฐุฌ ูู ุจุถุน ุณุทูุฑ ูู ุงูููุฏ:

```python
>>> from transformers import pipeline
>>> from PIL import Image
>>> import requests

>>> # ุชุญููู ุงูุฃูุจูุจ
>>> image_classifier = pipeline(task="zero-shot-image-classification", model="google/siglip-base-patch16-224")

>>> # ุชุญููู ุงูุตูุฑุฉ
>>> url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
>>> image = Image.open(requests.get(url, stream=True).raw)

>>> # ุงูุงุณุชูุชุงุฌ
>>> outputs = image_classifier(image, candidate_labels=["2 cats", "a plane", "a remote"])
>>> outputs = [{"score": round(output["score"], 4), "label": output["label"] } for output in outputs]
>>> print(outputs)
[{'score': 0.1979, 'label': '2 cats'}, {'score': 0.0, 'label': 'a remote'}, {'score': 0.0, 'label': 'a plane'}]
```

### ุงุณุชุฎุฏุงู ุงููููุฐุฌ ุจููุณู

ุฅุฐุง ููุช ุชุฑูุฏ ุงูููุงู ุจุงููุนุงูุฌุฉ ุงููุณุจูุฉ ูุงููุงุญูุฉ ุจููุณูุ ููุฐุง ูู ูุง ูุฌุจ ูุนูู:

```python
>>> from PIL import Image
>>> import requests
>>> from transformers import AutoProcessor, AutoModel
>>> import torch

>>> model = AutoModel.from_pretrained("google/siglip-base-patch16-224")
>>> processor = AutoProcessor.from_pretrained("google/siglip-base-patch16-224")

>>> url = "http://images.cocodataset.org/val2017/000000039769.jpg"
>>> image = Image.open(requests.get(url, stream=True).raw)

>>> texts = ["a photo of 2 cats", "a photo of 2 dogs"]
>>> # ูู ุงูููู: ููุฑุฑ `padding=max_length` ุญูุซ ุชู ุชุฏุฑูุจ ุงููููุฐุฌ ุจูุฐู ุงูุทุฑููุฉ
>>> inputs = processor(text=texts, images=image, padding="max_length", return_tensors="pt")

>>> with torch.no_grad():
...     outputs = model(**inputs)

>>> logits_per_image = outputs.logits_per_image
>>> probs = torch.sigmoid(logits_per_image) # ูุฐู ูู ุงูุงุญุชูุงูุงุช
>>> print(f"{probs[0][0]:.1%} ุงุญุชูุงู ุฃู ุชููู ุงูุตูุฑุฉ 0 ูู '{texts[0]}'")
31.9% ุงุญุชูุงู ุฃู ุชููู ุงูุตูุฑุฉ 0 ูู 'a photo of 2 cats'
```

## ุงูููุงุฑุฏ

ูุงุฆูุฉ ุจููุงุฑุฏ Hugging Face ุงูุฑุณููุฉ ูููุงุฑุฏ ุงููุฌุชูุน (ูุดุงุฑ ุฅูููุง ุจู ๐) ููุณุงุนุฏุชู ูู ุงูุจุฏุก ุจุงุณุชุฎุฏุงู SigLIP.

- [ุฏููู ููุงู ุงูุชุตููู ุงูุตูุฑู ุจุฏูู ุฅุดุฑุงู](../tasks/zero_shot_image_classification_md)

- ูููู ุงูุนุซูุฑ ุนูู ุฏูุงุชุฑ ุงูููุงุญุธุงุช ุงูุชุฌุฑูุจูุฉ ูู SigLIP [ููุง](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/SigLIP). ๐

ุฅุฐุง ููุช ููุชููุง ุจุชูุฏูู ููุฑุฏ ูุฅุฏุฑุงุฌู ููุงุ ูุงูุฑุฌุงุก ูุชุญ ุทูุจ ุณุญุจ ูุณูุฑุงุฌุนู! ูุฌุจ ุฃู ููุธูุฑ ุงูููุฑุฏ ุจุดูู ูุซุงูู ุดูุฆูุง ุฌุฏูุฏูุง ุจุฏูุงู ูู ุชูุฑุงุฑ ููุฑุฏ ููุฌูุฏ.

## SiglipConfig

[[autodoc]] SiglipConfig

- from_text_vision_configs

## SiglipTextConfig

[[autodoc]] SiglipTextConfig

## SiglipVisionConfig

[[autodoc]] SiglipVisionConfig

## SiglipTokenizer

[[autodoc]] SiglipTokenizer

- build_inputs_with_special_tokens
- get_special_tokens_mask
- create_token_type_ids_from_sequences
- save_vocabulary

## SiglipImageProcessor

[[autodoc]] SiglipImageProcessor

- preprocess

## SiglipProcessor

[[autodoc]] SiglipProcessor

## SiglipModel

[[autodoc]] SiglipModel

- forward
- get_text_features
- get_image_features

## SiglipTextModel

[[autodoc]] SiglipTextModel

- forward

## SiglipVisionModel

[[autodoc]] SiglipVisionModel

- forward

## SiglipForImageClassification

[[autodoc]] SiglipForImageClassification

- forward