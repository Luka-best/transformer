# MEGA

<Tip warning={true}>

تم وضع هذا النموذج في وضع الصيانة فقط، ولا نقبل أي طلبات سحب (PRs) جديدة لتغيير شفرته.
إذا واجهتك أي مشكلات أثناء تشغيل هذا النموذج، يرجى إعادة تثبيت الإصدار الأخير الذي يدعم هذا النموذج: v4.40.2.
يمكنك القيام بذلك عن طريق تشغيل الأمر التالي: "pip install -U transformers==4.40.2".

</Tip>

## نظرة عامة

تم اقتراح نموذج MEGA في الورقة البحثية [Mega: Moving Average Equipped Gated Attention](https://arxiv.org/abs/2209.10655) بواسطة Xuezhe Ma و Chunting Zhou و Xiang Kong و Junxian He و Liangke Gui و Graham Neubig و Jonathan May و Luke Zettlemoyer.
يقترح MEGA نهجًا جديدًا للاهتمام الذاتي حيث تحتوي كل طبقة ترميز على متوسط متحرك أسي متعدد الرؤوس بالإضافة إلى رأس واحد من الاهتمام المعتاد المعتمد على الضرب النقطي، مما يمنح آلية الاهتمام تحيزات موضعية أقوى. يسمح هذا لـ MEGA بأن يكون تنافسيًا مع المحولات في المعايير القياسية بما في ذلك LRA مع امتلاكه لعدد أقل بكثير من المعلمات. تتيح كفاءة MEGA الحسابية إمكانية توسيع نطاقه إلى تسلسلات طويلة جدًا، مما يجعله خيارًا جذابًا لمهمات معالجة اللغات الطبيعية التي تتضمن وثائق طويلة.

ملخص الورقة البحثية هو كما يلي:

*أدت خيارات التصميم في آلية اهتمام المحول، بما في ذلك التحيز الاستقرائي الضعيف والتعقيد الحسابي التربيعي، إلى الحد من تطبيقه في نمذجة التسلسلات الطويلة. في هذه الورقة، نقدم Mega، وهي آلية اهتمام بوابة أحادية الرأس بسيطة ومبررة نظريًا ومزودة بمتوسط متحرك (أسّي) لدمج التحيز الاستقرائي للاعتمادية المحلية الواعية بالموضع في آلية الاهتمام غير الواعية بالموضع. نقترح أيضًا متغيرًا لـ Mega يتيح تعقيدًا خطيًا في الوقت والمساحة مع حدوث خسارة طفيفة فقط في الجودة، وذلك من خلال تقسيم التسلسل بالكامل بكفاءة إلى عدة أجزاء ذات طول ثابت. تُظهر التجارب واسعة النطاق على مجموعة متنوعة من معايير نمذجة التسلسلات، بما في ذلك Long Range Arena، والترجمة الآلية العصبية، ونمذجة اللغة التوليدية، وتصنيف الصور والكلام، أن Mega يحقق تحسينات كبيرة مقارنة بنماذج التسلسل الأخرى، بما في ذلك متغيرات المحولات ونماذج فضاء الحالة الحديثة.*

تمت المساهمة بهذا النموذج من قبل [mnaylor](https://huggingface.co/mnaylor).
يمكن العثور على الشفرة الأصلية [هنا](https://github.com/facebookresearch/mega).

## نصائح الاستخدام

- يمكن أن يعمل MEGA بشكل جيد جدًا بعدد قليل نسبيًا من المعلمات. راجع التذييل D في ورقة MEGA للحصول على أمثلة لمواصفات التصميم التي تعمل بشكل جيد في مختلف الإعدادات. عند استخدام MEGA كفك شفرة، تأكد من تعيين "bidirectional=False" لتجنب الأخطاء مع الاتجاه الافتراضي ثنائي الاتجاه.
- Mega-chunk هو متغير من Mega يقلل من التعقيد الزمني والمكاني من التربيعي إلى الخطي. يمكن استخدام التجزئة مع MegaConfig.use_chunking والتحكم في حجم الجزء باستخدام MegaConfig.chunk_size.

## ملاحظات التنفيذ

- كان للتنفيذ الأصلي لـ MEGA توقع غير متسق لأقنعة الاهتمام للوسائد والاهتمام الذاتي السببي بين طريقة الاهتمام الناعم وطريقة Laplace/squared ReLU. يعالج هذا التنفيذ عدم الاتساق هذا.
- لم يتضمن التنفيذ الأصلي تضمين نوع الرمز المميز؛ يضيف هذا التنفيذ الدعم لهذه الميزة، مع التحكم في الخيار باستخدام MegaConfig.add_token_type_embeddings.

## MegaConfig

[[autodoc]] MegaConfig

## MegaModel

[[autodoc]] MegaModel

- forward

## MegaForCausalLM

[[autodoc]] MegaForCausalLM

- forward

## MegaForMaskedLM

[[autodoc]] MegaForMaskedLM

- forward

## MegaForSequenceClassification

[[autodoc]] MegaForSequenceClassification

- forward

## MegaForMultipleChoice

[[autodoc]] MegaForMultipleChoice

- forward

## MegaForTokenClassification

[[autodoc]] MegaForTokenClassification

- forward

## MegaForQuestionAnswering

[[autodoc]] MegaForQuestionAnswering

- forward