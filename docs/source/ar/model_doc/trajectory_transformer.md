# محول المسار

> ⚠️ هذا الملف مكتوب بتنسيق Markdown ولكنه يحتوي على بناء جمل محدد لمُنشئ وثائقنا (يشبه MDX) قد لا يتم عرضه بشكل صحيح في عارض Markdown الخاص بك.

## نظرة عامة

اقتُرح نموذج محول المسار في "تعلم التعزيز غير المتصل كمشكلة واحدة كبيرة في نمذجة التسلسل" بواسطة مايكل جانر، وقيانغ لي، وسيرجي ليفين.

مقتطف من الورقة البحثية هو كما يلي:

> "يهتم تعلم التعزيز (RL) عادة بتقدير السياسات الثابتة أو النماذج أحادية الخطوة، والاستفادة من خاصية ماركوف لتقسيم المشكلات حسب الوقت. ومع ذلك، يمكننا أيضًا اعتبار RL كمشكلة نمذجة تسلسل عامة، بهدف إنتاج تسلسل من الإجراءات التي تؤدي إلى تسلسل من المكافآت المرتفعة. ومن المغري، عند النظر إليه بهذه الطريقة، أن نأخذ في الاعتبار ما إذا كانت نماذج التنبؤ بالتسلسل عالية السعة التي تعمل بشكل جيد في المجالات الأخرى، مثل معالجة اللغات الطبيعية، يمكن أن توفر أيضًا حلولًا فعالة لمشكلة RL. ولهذه الغاية، نستكشف كيف يمكن معالجة RL باستخدام أدوات نمذجة التسلسل، باستخدام بنية محول لنمذجة التوزيعات على المسارات وإعادة استخدام البحث الشعاعي كخوارزمية تخطيط. وتبسيط تعلم التعزيز كمشكلة نمذجة تسلسل لمجموعة من قرارات التصميم، مما يسمح لنا بالتخلص من العديد من المكونات الشائعة في خوارزميات RL غير المتصلة. ونحن نثبت مرونة هذا النهج في التنبؤ بالديناميكيات طويلة المدى، وتعلم التقليد، وتعزيز التعلم القائم على الأهداف، وتعزيز التعلم غير المتصل. علاوة على ذلك، نوضح أنه يمكن دمج هذا النهج مع الخوارزميات الحالية الخالية من النماذج لإنتاج مخطط من الطراز الأول في المهام طويلة المدى ذات المكافآت النادرة."

ساهم في هذا النموذج [CarlCochet](https://huggingface.co/CarlCochet). يمكن العثور على الكود الأصلي [هنا](https://github.com/jannerm/trajectory-transformer).

## نصائح الاستخدام

يُستخدم هذا المحول في تعلم التعزيز العميق. لاستخدامه، يجب إنشاء تسلسلات من الإجراءات والحالات والمكافآت من جميع الخطوات الزمنية السابقة. سيعامل هذا النموذج جميع هذه العناصر معًا كتسلسل واحد كبير (مسار).

## TrajectoryTransformerConfig

[[autodoc]] TrajectoryTransformerConfig

## TrajectoryTransformerModel

[[autodoc]] TrajectoryTransformerModel

- forward