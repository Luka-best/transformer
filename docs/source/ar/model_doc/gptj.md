# GPT-J

## ูุธุฑุฉ ุนุงูุฉ
ูููุฐุฌ GPT-J ูู ูููุฐุฌ ูุบูู ุงุญุชูุงูู ุชู ุฅุตุฏุงุฑู ูู ูุณุชูุฏุน [kingoflolz/mesh-transformer-jax](https://github.com/kingoflolz/mesh-transformer-jax) ุจูุงุณุทุฉ Ben Wang ู Aran Komatsuzaki. ููู ูุดุจู ูููุฐุฌ GPT-2 ุญูุซ ุชู ุชุฏุฑูุจู ุนูู ูุฌููุนุฉ ุจูุงูุงุช [the Pile](https://pile.eleuther.ai/) ูุฅูุชุงุฌ ุงููุตูุต ุจุดูู ุชููุงุฆู.

ุชูุช ุงููุณุงููุฉ ุจูุฐุง ุงููููุฐุฌ ูู ูุจู [Stella Biderman](https://huggingface.co/stellaathena).

## ูุตุงุฆุญ ุงูุงุณุชุฎุฏุงู
- ูุชุญููู [GPT-J](https://huggingface.co/EleutherAI/gpt-j-6B) ุจุชูุณูู float32ุ ุณุชุญุชุงุฌ ุฅูู ุถุนู ุญุฌู ุงูุฐุงูุฑุฉ ุงูุนุดูุงุฆูุฉ ูููููุฐุฌุ ุฃู 1x ูุญุฌู ุงูุฃูุฒุงู ุงูุฃูููุฉ ู 1x ูุชุญููู ููุทุฉ ุงูุชูุชูุด. ูุฐููุ ุจุงููุณุจุฉ ูู GPT-Jุ ุณุชููู ููุงู ุญุงุฌุฉ ุฅูู 48 ุฌูุฌุงุจุงูุช ูู ุงูุฐุงูุฑุฉ ุงูุนุดูุงุฆูุฉ ูุญุฏ ุฃุฏูู ูุชุญููู ุงููููุฐุฌ ููุท. ูุชูููู ุงุณุชุฎุฏุงู ุงูุฐุงูุฑุฉ ุงูุนุดูุงุฆูุฉุ ููุงู ุจุนุถ ุงูุฎูุงุฑุงุช. ูููู ุงุณุชุฎุฏุงู ูุณูุท `torch_dtype` ูุชููุฆุฉ ุงููููุฐุฌ ุจูุตู ุงูุฏูุฉ ุนูู ุฌูุงุฒ CUDA ููุท. ููุงู ุฃูุถูุง ูุฑุน fp16 ูุงูุฐู ูุฎุฒู ุฃูุฒุงู fp16ุ ูุงูุฐู ูููู ุงุณุชุฎุฏุงูู ูุชูููู ุงุณุชุฎุฏุงู ุงูุฐุงูุฑุฉ ุงูุนุดูุงุฆูุฉ:

```python
>>> from transformers import GPTJForCausalLM
>>> import torch

>>> device = "cuda"
>>> model = GPTJForCausalLM.from_pretrained(
...     "EleutherAI/gpt-j-6B",
...     revision="float16",
...     torch_dtype=torch.float16,
... ).to(device)
```

- ูุฌุจ ุฃู ูุชูุงุณุจ ุงููููุฐุฌ ูุน ุฐุงูุฑุฉ GPU ุจุณุนุฉ 16 ุฌูุฌุงุจุงูุช ููุชูููุฐ. ูููู ุจุงููุณุจุฉ ููุชุฏุฑูุจ/ุงูุถุจุท ุงูุฏูููุ ุณูุชุทูุจ ุงูุฃูุฑ ุฐุงูุฑุฉ GPU ุฃูุจุฑ ุจูุซูุฑ. ุนูู ุณุจูู ุงููุซุงูุ ูููู ููุญุณููู Adam ุจุฅูุดุงุก ุฃุฑุจุน ูุณุฎ ูู ุงููููุฐุฌ: ุงููููุฐุฌุ ูุงููุดุชูุงุชุ ููุชูุณุท ุงููุดุชูุงุชุ ููุชูุณุท ุงููุฑุจุนุงุช ูููุดุชูุงุช. ูุฐููุ ุณุชุญุชุงุฌ ุฅูู ุฐุงูุฑุฉ GPU ุจุญุฌู 4x ุนูู ุงูุฃูู ูุญุฌู ุงููููุฐุฌุ ุญุชู ูุน ุงูุฏูุฉ ุงููุฎุชูุทุฉุ ูุฃู ุชุญุฏูุซุงุช ุงููุดุชูุงุช ุชููู ูู ุชูุณูู fp32. ูุฐุง ูุง ูุดูู ุงููุตูููุงุช ูุงูุฏูุนุงุชุ ูุงูุชู ุชุชุทูุจ ุฃูุถูุง ุงููุฒูุฏ ูู ุฐุงูุฑุฉ GPU. ูุฐููุ ูุฌุจ ุงุณุชูุดุงู ุญููู ูุซู DeepSpeed ูุชุฏุฑูุจ/ุถุจุท ุงููููุฐุฌ. ุงูุฎูุงุฑ ุงูุขุฎุฑ ูู ุงุณุชุฎุฏุงู ุงูููุฏ ุงูุฃุตูู ูุชุฏุฑูุจ/ุถุจุท ุงููููุฐุฌ ุนูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (TPU)ุ ุซู ุชุญููู ุงููููุฐุฌ ุฅูู ุชูุณูู Transformers ููุชูููุฐ. ูููู ุงูุนุซูุฑ ุนูู ุงูุชุนูููุงุช ุงูุฎุงุตุฉ ุจุฐูู [ููุง](https://github.com/kingoflolz/mesh-transformer-jax/blob/master/howto_finetune.md).

- ุนูู ุงูุฑุบู ูู ุฃู ูุตูููุฉ ุงูุชุนูููุงุช ุงูุชูุถูุญูุฉ ููุง ุญุฌู 50400ุ ุฅูุง ุฃู ูุญุฏุฏ GPT-2 ูุณุชุฎุฏู ููุท 50257 ุฅุฏุฎุงููุง. ุชู ุฅุถุงูุฉ ูุฐู ุงูุฑููุฒ ุงูุฅุถุงููุฉ ูู ุฃุฌู ุงูููุงุกุฉ ุนูู ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (TPUs). ููุชุฌูุจ ุนุฏู ุงูุชุทุงุจู ุจูู ุญุฌู ูุตูููุฉ ุงูุชุนูููุงุช ุงูุชูุถูุญูุฉ ูุญุฌู ุงูููุฑุฏุงุชุ ูุญุชูู ูุญุฏุฏ ุงูู GPT-J ุนูู 143 ุฑูุฒูุง ุฅุถุงูููุง `<|extratoken_1|>... <|extratoken_143|>`ุ ูุจุงูุชุงูู ูุตุจุญ ุญุฌู ููุฑุฏุงุช ุงููุญูู 50400 ุฃูุถูุง.

## ุฃูุซูุฉ ุงูุงุณุชุฎุฏุงู
ูููู ุงุณุชุฎุฏุงู ุทุฑููุฉ [`~generation.GenerationMixin.generate`] ูุชูููุฏ ุงููุตูุต ุจุงุณุชุฎุฏุงู ูููุฐุฌ GPT-J.

```python
>>> from transformers import AutoModelForCausalLM, AutoTokenizer

>>> model = AutoModelForCausalLM.from_pretrained("EleutherAI/gpt-j-6B")
>>> tokenizer = AutoTokenizer.from_pretrained("EleutherAI/gpt-j-6B")

>>> prompt = (
...     "In a shocking finding, scientists discovered a herd of unicorns living in a remote, "
...     "previously unexplored valley, in the Andes Mountains. Even more surprising to the "
...     "researchers was the fact that the unicorns spoke perfect English."
... )

>>> input_ids = tokenizer(prompt, return_tensors="pt").input_ids

>>> gen_tokens = model.generate(
...     input_ids,
...     do_sample=True,
...     temperature=0.9,
...     max_length=100,
... )
>>> gen_text = tokenizer.batch_decode(gen_tokens)[0]
```

ุฃู ุจุงุณุชุฎุฏุงู ุงูุฏูุฉ ุงูุนุงุฆูุฉ 16:

```python
>>> from transformers import GPTJForCausalLM, AutoTokenizer
>>> import torch

>>> device = "cuda"
>>> model = GPTJForCausalLM.from_pretrained("EleutherAI/gpt-j-6B", torch_dtype=torch.float16).to(device)
>>> tokenizer = AutoTokenizer.from_pretrained("EleutherAI/gpt-j-6B")

>>> prompt = (
...     "In a shocking finding, scientists discovered a herd of unicorns living in a remote, "
...     "previously unexplored valley, in the Andes Mountains. Even more surprising to the "
...     "researchers was the fact that the unicorns spoke perfect English."
... )

>>> input_ids = tokenizer(prompt, return_tensors="pt").input_ids.to(device)

>>> gen_tokens = model.generate(
...     input_ids,
...     do_sample=True,
...     temperature=0.9,
...     max_length=100,
... )
>>> gen_text = tokenizer.batch_decode(gen_tokens)[0]
```

## ุงูููุงุฑุฏ
ูููุง ููู ูุงุฆูุฉ ุจููุงุฑุฏ Hugging Face ุงูุฑุณููุฉ ูููุงุฑุฏ ุงููุฌุชูุน (ุงููุดุงุฑ ุฅูููุง ุจุฑูุฒ ๐) ููุณุงุนุฏุชู ูู ุงูุจุฏุก ูู ุงุณุชุฎุฏุงู GPT-J. ุฅุฐุง ููุช ููุชููุง ุจุชูุฏูู ููุฑุฏ ูุฅุฏุฑุงุฌู ููุงุ ููุฑุฌู ูุชุญ ุทูุจ ุณุญุจ Pull Request ูุณูููู ุจูุฑุงุฌุนุชู! ูุฌุจ ุฃู ููุธูุฑ ุงูููุฑุฏ ุจุดูู ูุซุงูู ุดูุฆูุง ุฌุฏูุฏูุง ุจุฏูุงู ูู ุชูุฑุงุฑ ููุฑุฏ ููุฌูุฏ.

- ูุตู [GPT-J](https://huggingface.co/EleutherAI/gpt-j-6B).
- ูุฏููุฉ ุญูู ููููุฉ [ูุดุฑ GPT-J 6B ููุชูููุฐ ุจุงุณุชุฎุฏุงู Hugging Face Transformers ูAmazon SageMaker](https://huggingface.co/blog/gptj-sagemaker).
- ูุฏููุฉ ุญูู ููููุฉ [ุชุณุฑูุน ุชูููุฐ GPT-J ุจุงุณุชุฎุฏุงู DeepSpeed-Inference ุนูู ูุญุฏุงุช ูุนุงูุฌุฉ ุงูุฑุณูููุงุช](https://www.philschmid.de/gptj-deepspeed-inference).
- ููุดูุฑ ูุฏููุฉ ููุฏู [GPT-J-6B: 6B JAX-Based Transformer](https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/). ๐
- ุฏูุชุฑ ููุงุญุธุงุช ูู [GPT-J-6B Inference Demo](https://colab.research.google.com/github/kingoflolz/mesh-transformer-jax/blob/master/colab_demo.ipynb). ๐
- ุฏูุชุฑ ููุงุญุธุงุช ุขุฎุฑ ููุถุญ [Inference with GPT-J-6B](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/GPT-J-6B/Inference_with_GPT_J_6B.ipynb).
- ูุตู [ููุฐุฌุฉ ุงููุบุฉ ุงูุณุจุจูุฉ](https://huggingface.co/course/en/chapter7/6?fw=pt#training-a-causal-language-model-from-scratch) ูู ุฏูุฑุฉ ๐ค Hugging Face Course.
- [`GPTJForCausalLM`] ูุฏุนูู ุจูุงุณุทุฉ [ูุซุงู ุจุฑูุฌุฉ ุงูููุงุฐุฌ ุงููุบููุฉ ุงูุณุจุจูุฉ](https://github.com/huggingface/transformers/tree/main/examples/pytorch/language-modeling#gpt-2gpt-and-causal-language-modeling)ุ ู[ูุซุงู ุงููุต ุงููุตู](https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-generation)ุ ู[ุฏูุชุฑ ุงูููุงุญุธุงุช](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling.ipynb).
- [`TFGPTJForCausalLM`] ูุฏุนูู ุจูุงุณุทุฉ [ูุซุงู ุจุฑูุฌุฉ ุงูููุงุฐุฌ ุงููุบููุฉ ุงูุณุจุจูุฉ](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/language-modeling#run_clmpy) ู[ุฏูุชุฑ ุงูููุงุญุธุงุช](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling-tf.ipynb).
- [`FlaxGPTJForCausalLM`] ูุฏุนูู ุจูุงุณุทุฉ [ูุซุงู ุจุฑูุฌุฉ ุงูููุงุฐุฌ ุงููุบููุฉ ุงูุณุจุจูุฉ](https://github.com/huggingface/transformers/tree/main/examples/flax/language-modeling#causal-language-modeling) ู[ุฏูุชุฑ ุงูููุงุญุธุงุช](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/causal_language_modeling_flax.ipynb).

**ููุงุฑุฏ ุงูุชูุซูู**

- ุฏููู ููุงู ุชุตููู ุงููุตูุต [Text classification task guide](../tasks/sequence_classification)
- ุฏููู ููุงู ุงูุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉ [Question answering task guide](../tasks/question_answering)
- ุฏููู ููุงู ููุฐุฌุฉ ุงููุบุฉ ุงูุณุจุจูุฉ [Causal language modeling task guide](../tasks/language_modeling)

## GPTJConfig

[[autodoc]] GPTJConfig

- all

<frameworkcontent>

<pt>

## GPTJModel

[[autodoc]] GPTJModel

- forward

## GPTJForCausalLM

[[autodoc]] GPTJForCausalLM

- forward

## GPTJForSequenceClassification

[[autodoc]] GPTJForSequenceClassification

- forward

## GPTJForQuestionAnswering

[[autodoc]] GPTJForQuestionAnswering

- forward

</pt>

<tf>

## TFGPTJModel

[[autodoc]] TFGPTJModel

- call

## TFGPTJForCausalLM

[[autodoc]] TFGPTJForCausalLM

- call

## TFGPTJForSequenceClassification

[[autodoc]] TFGPTJForSequenceClassification

- call

## TFGPTJForQuestionAnswering

[[autodoc]] TFGPTJForQuestionAnswering

- call

</tf>

<jax>

## FlaxGPTJModel

[[autodoc]] FlaxGPTJModel

- __call__

## FlaxGPTJForCausalLM

[[autodoc]] FlaxGPTJForCausalLM

- __call__

</jax>

</frameworkcontent>