# ViTDet

## نظرة عامة

اقترح نموذج ViTDet في بحث [استكشاف العمود الفقري لشبكة المحول البصري البسيط للكشف عن الأجسام](https://arxiv.org/abs/2203.16527) من قبل يانغهاو لي، هانزي ماو، روس جيرشيك، كايمينغ هي.

يستفيد ViTDet من محول الرؤية [Vision Transformer](vit) لمهمة الكشف عن الأجسام.

الملخص من الورقة هو ما يلي:

*نستكشف محول الرؤية البسيط وغير الهرمي (ViT) كشبكة عمود فقري للكشف عن الأجسام. يمكّن هذا التصميم بنية ViT الأصلية من الضبط الدقيق للكشف عن الأجسام دون الحاجة إلى إعادة تصميم عمود فقري هرمي للتعلم المسبق. وبأقل التعديلات للضبط الدقيق، يمكن لكاشف العمود الفقري البسيط لدينا تحقيق نتائج تنافسية. ومما يثير الدهشة أننا نلاحظ ما يلي: '1' من الكافي بناء هرمية مميزة بسيطة من خريطة مميزة ذات مقياس واحد (بدون التصميم FPN الشائع) و '2' من الكافي استخدام انتباه النافذة (بدون تحويل) بمساعدة عدد قليل جدًا من كتل الانتشار عبر النوافذ. باستخدام العمود الفقري ViT البسيط المسبق التدريب كـ Masked Autoencoders (MAE)، يمكن لكاشفنا، المسمى ViTDet، التنافس مع الطرق الرائدة السابقة التي كانت جميعها تعتمد على العمود الفقري الهرمي، حيث يصل إلى 61.3 AP_box على مجموعة بيانات COCO باستخدام ImageNet-1K للتعلم المسبق فقط. نأمل أن تجذب دراستنا الانتباه إلى الأبحاث حول كواشف العمود الفقري البسيطة.*

ساهم بهذا النموذج [nielsr](https://huggingface.co/nielsr).

يمكن العثور على الكود الأصلي [هنا](https://github.com/facebookresearch/detectron2/tree/main/projects/ViTDet).

نصائح:

- في الوقت الحالي، يتوفر العمود الفقري فقط.

## VitDetConfig

[[autodoc]] VitDetConfig

## VitDetModel

[[autodoc]] VitDetModel

- forward