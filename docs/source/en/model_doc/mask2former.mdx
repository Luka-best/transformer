<!--Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

# Mask2Former

## Overview

The Mask2Former model was proposed in [Masked-attention Mask Transformer for Universal Image Segmentation](https://arxiv.org/abs/2112.01527) by Bowen Cheng, Ishan Misra, Alexander G. Schwing, Alexander Kirillov, Rohit Girdhar.
Mask2Former is a unified framework for panoptic, instance and semantic segmentation and features significant performance and efficiency improvements over MaskFormer.

The abstract from the paper is the following:

*Image segmentation groups pixels with different seman-
tics, e.g., category or instance membership. Each choice
of semantics defines a task. While only the semantics of
each task differ, current research focuses on designing spe-
cialized architectures for each task. We present Masked-
attention Mask Transformer (Mask2Former), a new archi-
tecture capable of addressing any image segmentation task
(panoptic, instance or semantic). Its key components in-
clude masked attention, which extracts localized features by
constraining cross-attention within predicted mask regions.
In addition to reducing the research effort by at least three
times, it outperforms the best specialized architectures by
a significant margin on four popular datasets. Most no-
tably, Mask2Former sets a new state-of-the-art for panoptic
segmentation (57.8 PQ on COCO), instance segmentation
(50.1 AP on COCO) and semantic segmentation (57.7 mIoU
on ADE20K).*

Tips:

<INSERT TIPS ABOUT MODEL HERE>

This model was contributed by [INSERT YOUR HF USERNAME HERE](https://huggingface.co/<INSERT YOUR HF USERNAME HERE>).
The original code can be found [here](https://github.com/facebookresearch/Mask2Former).

## MaskFormer specific outputs

[[autodoc]] models.mask2former.modeling_mask2former.Mask2FormerModelOutput

[[autodoc]] models.mask2former.modeling_mask2former.Mask2FormerForUniversalSegmentationOutput

## Mask2FormerConfig

[[autodoc]] Mask2FormerConfig

## Mask2FormerImageProcessor

[[autodoc]] Mask2FormerImageProcessor
    - preprocess
    - encode_inputs
    - post_process_semantic_segmentation
    - post_process_instance_segmentation
    - post_process_panoptic_segmentation

## Mask2FormerModel

[[autodoc]] Mask2FormerModel
    - forward

## Mask2FormerForUniversalSegmentation

[[autodoc]] Mask2FormerForUniversalSegmentation
    - forward
