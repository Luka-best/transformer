<!--Copyright 2023 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

# Udop

## Overview

The udop models was presented in [Unifying Vision, Text, and Layout for Universal Document Processing](https://arxiv.org/pdf/2212.02623.pdf) by Zineng Tang, Ziyi Yang, Guoxin Wang, Yuwei Fang, Yang Liu, Chenguang Zhu, Michael Zeng, Cha Zhang, Mohit Bansal.
Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu.

The abstract from the paper is the following:

*We propose Universal Document Processing (UDOP), a foundation Document AI model which unifies text, image, and layout
modalities together with varied task formats, including document understanding and generation. UDOP leverages the
spatial correlation between textual content and document image to model image, text, and layout modalities with one
uniform representation. With a novel Vision-Text-Layout Transformer, UDOP unifies pretraining and multi-domain
downstream tasks into a prompt-based sequence generation scheme. UDOP is pretrained on both large-scale unlabeled
document corpora using innovative self-supervised objectives and diverse labeled data. UDOP also learns to generate
document images from text and layout modalities via masked image reconstruction. To the best of our knowledge, this is
the first time in the field of document AI that one model simultaneously achieves high-quality neural document editing
and content customization. Our method sets the state-of-the-art on 9 Document AI tasks, e.g., document understanding
and QA, across diverse data domains like finance reports, academic papers, and websites. UDOP ranks first on the
leaderboard of the Document Understanding Benchmark (DUE).*

T5 comes in two variations :

- [udop-uni]

- [udop-dual]

All checkpoints can be found on the [hub](https://huggingface.co/models?search=udop).

This model was contributed by [A K Raghavan](https://github.com/raghavanone). The original code can be found [here](https://github.com/microsoft/i-Code/tree/main/i-Code-Doc).

<a id='training'></a>

## Inference

At inference time, it is recommended to use [`~generation.GenerationMixin.generate`]. This
method takes care of encoding the input and feeding the encoded hidden states via cross-attention layers to the decoder
and auto-regressively generates the decoder output. Check out [this blog post](https://huggingface.co/blog/how-to-generate) to know all the details about generating text with Transformers.
There's also [this blog post](https://huggingface.co/blog/encoder-decoder#encoder-decoder) which explains how
generation works in general in encoder-decoder models.

```python
>>> from transformers import AutoTokenizer, UdopDualForConditionalGeneration

>>> tokenizer = AutoTokenizer.from_pretrained("udop-uni")
>>> model = UdopDualForConditionalGeneration.from_pretrained("udop-uni")

>>> input_ids = tokenizer("The <extra_id_0> walks", return_tensors="pt").input_ids
>>> text_seg_data = torch.tensor([[0.11, 0.22, 0.43, 0.99], [0.13, 0.26, 0.33, 0.59], [0.09, 0.11, 0.29, 0.29]])
>>> image_input = torch.randn([1, 224, 224, 3])
>>> image_seg_data = torch.randn([1, 194, 4])
>>> labels = torch.tensor([[8, 3, 238, 12394, 1]])
>>> outputs = model(
...     input_ids=input_ids,
...     image=image_input,
...     seg_data=text_seg_data,
...     visual_seg_data=image_seg_data,
...     labels=labels,
... )
>>> loss = outputs.loss
>>> logits = outputs.logits
```

## Performance

If you'd like a faster training and inference performance, install [apex](https://github.com/NVIDIA/apex#quick-start) and then the model will automatically use `apex.normalization.FusedRMSNorm` instead of `UdopLayerNorm`. The former uses an optimized fused kernel which is several times faster than the latter.


## Resources

A list of official Hugging Face and community (indicated by ðŸŒŽ) resources to help you get started with Udop. If you're interested in submitting a resource to be included here, please feel free to open a Pull Request and we'll review it! The resource should ideally demonstrate something new instead of duplicating an existing resource.

## UdopConfig

[[autodoc]] UdopConfig

## UdopTokenizer

[[autodoc]] UdopTokenizer
    - build_inputs_with_special_tokens
    - get_special_tokens_mask
    - create_token_type_ids_from_sequences
    - save_vocabulary

## UdopTokenizerFast

[[autodoc]] UdopTokenizerFast

## UdopUnimodelForConditionalGeneration

[[autodoc]] UdopUnimodelForConditionalGeneration
    - forward

## UdopDualForConditionalGeneration

[[autodoc]] UdopDualForConditionalGeneration
    - forward
