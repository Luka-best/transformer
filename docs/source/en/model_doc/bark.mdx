<!--Copyright 2023 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

# Bark

## Overview

The `Bark` model is a transformer-based text-to-audio model proposed by Suno's AI team in [suno-ai/bark](https://github.com/suno-ai/bark). 


`Bark` is made of 4 main modules:

- A `semantic model ` (also named `text model`), i.e a causal autoregressive transformer (GPT2-like), which takes into input a tokenized text
- A `coarse acoustics model` (also named `coarse model`), also a causal autoregressive transformer, taking into input the results of the last model. It aims at regressing the first two audio codebooks necessary to `encodec`.
- A `fine acoustics model` (`fine model`), this time a non-causal autoencoder transformer, which iteratively predicts the 6 last codebooks based on the sum of the previous codebooks embeddings.
- having predicted 8 codebooks channels of `encodec`, Bark uses `encodec` to generate the output audio array.

Note that each of the first 3 modules can take optional conditional speaker embeddings aiming at conditioning the output audio according to `specific preset voices.


Tips:

`Bark` can generate highly realistic, **multilingual** speech as well as other audio - including music, background noise and simple sound effects. 
The model can also produce **nonverbal communications** like laughing, sighing and crying.
Suno offers a library of voice presets in a number of languages [here](https://suno-ai.notion.site/8b8e8749ed514b0cbf3f699013548683?v=bc67cff786b04b50b3ceb756fd05f68c).
These presets are also uploaded in the hub [here](https://huggingface.co/ylacombe/bark-small/tree/main/speaker_embeddings) or [here](https://huggingface.co/ylacombe/bark-large/tree/main/speaker_embeddings).


This model was contributed by [ylacombe](https://huggingface.co/ylacombe).
The original code can be found [here](https://github.com/suno-ai/bark).


## BarkConfig

[[autodoc]] BarkConfig
    - all

## BarkModuleConfig

[[autodoc]] BarkModuleConfig
    - all

## BarkProcessor

[[autodoc]] BarkProcessor
    - all

## BarkModel

[[autodoc]] BarkModel
    - generate_audio

## BarkSemanticModule

[[autodoc]] BarkSemanticModule
    - forward

## BarkCoarseAcousticsModule

[[autodoc]] BarkCoarseAcousticsModule
    - forward

## BarkFineAcousticsModule

[[autodoc]] BarkFineAcousticsModule
    - forward

## BarkCausalModule

[[autodoc]] BarkCausalModule
    - forward

## BarkCoarseAcousticsConfig

[[autodoc]] BarkCoarseAcousticsConfig
    - all

## BarkFineAcousticsConfig

[[autodoc]] BarkFineAcousticsConfig
    - all

## BarkSemanticConfig

[[autodoc]] BarkSemanticConfig
    - all

