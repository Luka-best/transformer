{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ed4146f",
   "metadata": {},
   "source": [
    "# PatchTSMixer workflow examples on ETTH dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2d008c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dccstor/dnn_forecasting/conda_envs/envs/fm/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import PatchTSMixerConfig, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3491b28",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153a8600",
   "metadata": {},
   "source": [
    "Generate and prepare dummy data to test the pretraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a24659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "class ETTDataset(Dataset):\n",
    "    def __init__(self, root_path='/dccstor/dnn_forecasting/FM/data/ETDataset/ETT-small/', data_file='ETTh1.csv', \n",
    "                 seq_len=128, pred_len=32,\n",
    "                 split='train',                  \n",
    "                 scale=True\n",
    "                 ):\n",
    "        \n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        # init\n",
    "        assert split in ['train', 'test', 'val']\n",
    "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
    "        self.set_type = type_map[split]\n",
    "                \n",
    "        self.scale = scale                        \n",
    "\n",
    "        self.root_path = root_path\n",
    "        self.data_file = data_file\n",
    "        self.__read_data__()\n",
    "\n",
    "    def __read_data__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        df_raw = pd.read_csv(os.path.join(self.root_path, self.data_file))\n",
    "\n",
    "        border1s = [0, 12 * 30 * 24 - self.seq_len, 12 * 30 * 24 + 4 * 30 * 24 - self.seq_len]\n",
    "        border2s = [12 * 30 * 24, 12 * 30 * 24 + 4 * 30 * 24, 12 * 30 * 24 + 8 * 30 * 24]\n",
    "        border1 = border1s[self.set_type]\n",
    "        border2 = border2s[self.set_type]\n",
    "        \n",
    "        cols_data = df_raw.columns[1:]\n",
    "        df_data = df_raw[cols_data]\n",
    "\n",
    "        if self.scale:\n",
    "            train_data = df_data[border1s[0]:border2s[0]]\n",
    "            self.scaler.fit(train_data.values)\n",
    "            data = self.scaler.transform(df_data.values)\n",
    "        else:\n",
    "            data = df_data.values\n",
    "        \n",
    "        self.data_x = data[border1:border2]\n",
    "        self.data_y = data[border1:border2]        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        s_begin = index\n",
    "        s_end = s_begin + self.seq_len\n",
    "        r_begin = s_end\n",
    "        r_end = r_begin + self.pred_len \n",
    "\n",
    "        seq_x = self.data_x[s_begin:s_end]\n",
    "        seq_y = self.data_y[r_begin:r_end]        \n",
    "        return {\"context_values\": torch.Tensor(seq_x), \"target_values\": torch.Tensor(seq_y)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        return self.scaler.inverse_transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f107ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORECAST_LEN = 96\n",
    "n_features = 7\n",
    "SEQ_LEN = 512\n",
    "seq_len = SEQ_LEN\n",
    "patch_len = 16\n",
    "stride = patch_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35d30023",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_train = ETTDataset(split=\"train\", seq_len=SEQ_LEN, pred_len=FORECAST_LEN)\n",
    "dset_val = ETTDataset(split=\"val\", seq_len=SEQ_LEN, pred_len=FORECAST_LEN)\n",
    "dset_test = ETTDataset(split=\"test\", seq_len=SEQ_LEN, pred_len=FORECAST_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f138a5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 7]), torch.Size([96, 7]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd=dset_val.__getitem__(0)\n",
    "dd[\"context_values\"].shape, dd[\"target_values\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cffaaecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_patches should be (no need to specify)\n",
    "num_patches = seq_len//patch_len\n",
    "num_patches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edad9744",
   "metadata": {},
   "source": [
    "## 1. Directly train a `PatchTSMixer` forecasting model, and evaluate the test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd207bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PatchTSMixerForForecasting\n",
    "\n",
    "forecast_config = PatchTSMixerConfig(\n",
    "    in_channels=n_features,\n",
    "    seq_len=SEQ_LEN,\n",
    "    patch_len=patch_len,\n",
    "    stride=stride,\n",
    "    num_features=48,\n",
    "    num_layers=2,\n",
    "    dropout=0.5,\n",
    "    mode=\"common_channel\",\n",
    "    revin=True,\n",
    "    expansion_factor=3,\n",
    "    head_dropout=0.7,\n",
    "    forecast_len=FORECAST_LEN\n",
    ")\n",
    "\n",
    "forecast_model = PatchTSMixerForForecasting(forecast_config)\n",
    "\n",
    "forecast_args = TrainingArguments(\n",
    "        output_dir='./dump/etth1/direct_forecast/checkpoint',\n",
    "        overwrite_output_dir=True,\n",
    "        learning_rate=0.0001,\n",
    "        num_train_epochs=100,\n",
    "        do_eval=True,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=1024,\n",
    "        report_to='tensorboard',\n",
    "        save_strategy='epoch',\n",
    "        logging_strategy=\"epoch\",\n",
    "        save_total_limit=3,\n",
    "        logging_dir='./dump/etth1/direct_forecast/logs',  # Make sure to specify a logging directory\n",
    "        \n",
    "        load_best_model_at_end=True,  # Load the best model when training ends\n",
    "        metric_for_best_model=\"eval_loss\",  # Metric to monitor for early stopping\n",
    "        greater_is_better=False,  # For loss\n",
    "    )\n",
    "\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "# Create the early stopping callback\n",
    "early_stopping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience=10,  # Number of epochs with no improvement after which to stop\n",
    "    early_stopping_threshold=0.0001,  # Minimum improvement required to consider as improvement\n",
    ")\n",
    "\n",
    "forecast_trainer = Trainer(\n",
    "    model=forecast_model,\n",
    "    args=forecast_args,\n",
    "    train_dataset=dset_train,\n",
    "    eval_dataset=dset_val,\n",
    "    callbacks=[early_stopping_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d63e7415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5292' max='25200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 5292/25200 01:31 < 05:42, 58.07 it/s, Epoch 21/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.527300</td>\n",
       "      <td>0.747703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.420200</td>\n",
       "      <td>0.713125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.393600</td>\n",
       "      <td>0.697876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.378400</td>\n",
       "      <td>0.692840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.370600</td>\n",
       "      <td>0.684963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.364400</td>\n",
       "      <td>0.685008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.359700</td>\n",
       "      <td>0.681701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.358700</td>\n",
       "      <td>0.682566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.355300</td>\n",
       "      <td>0.679382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.354000</td>\n",
       "      <td>0.680346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.351700</td>\n",
       "      <td>0.676354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.351700</td>\n",
       "      <td>0.681235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.348600</td>\n",
       "      <td>0.680230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.348100</td>\n",
       "      <td>0.679202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.347900</td>\n",
       "      <td>0.680351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.348000</td>\n",
       "      <td>0.680420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.346700</td>\n",
       "      <td>0.684649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>0.680839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.347000</td>\n",
       "      <td>0.680382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.345100</td>\n",
       "      <td>0.681524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.344300</td>\n",
       "      <td>0.681084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5292, training_loss=0.36701976721339036, metrics={'train_runtime': 94.3389, 'train_samples_per_second': 8515.05, 'train_steps_per_second': 267.122, 'total_flos': 711526928007168.0, 'train_loss': 0.36701976721339036, 'epoch': 21.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d3b4a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.36459630727767944,\n",
       " 'eval_runtime': 0.1609,\n",
       " 'eval_samples_per_second': 17311.979,\n",
       " 'eval_steps_per_second': 18.648,\n",
       " 'epoch': 21.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_trainer.evaluate(dset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2085e666",
   "metadata": {},
   "source": [
    "## 2. Pretrain a `PatchTSMixer` model with HF trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "676f195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PatchTSMixerForMaskPretraining\n",
    "\n",
    "pretrain_config = PatchTSMixerConfig(\n",
    "    in_channels=n_features,\n",
    "    seq_len=SEQ_LEN,\n",
    "    patch_len=patch_len,\n",
    "    stride=stride,\n",
    "    num_features=48,\n",
    "    num_layers=2,\n",
    "    dropout=0.5,\n",
    "    mode=\"common_channel\",\n",
    "    revin=True,\n",
    "    expansion_factor=3,\n",
    "    head_dropout=0.7,\n",
    "    forecast_len=FORECAST_LEN\n",
    ")\n",
    "\n",
    "pretrain_model = PatchTSMixerForMaskPretraining(pretrain_config)\n",
    "\n",
    "pretrain_args = TrainingArguments(\n",
    "        output_dir='./dump/etth1/pretrain/checkpoint',\n",
    "        overwrite_output_dir=True,\n",
    "        learning_rate=0.0001,\n",
    "        num_train_epochs=100,\n",
    "        do_eval=True,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=1024,\n",
    "        report_to='tensorboard',\n",
    "        save_strategy='epoch',\n",
    "        logging_strategy=\"epoch\",\n",
    "        save_total_limit=3,\n",
    "        logging_dir='./dump/etth1/pretrain/logs',  # Make sure to specify a logging directory\n",
    "        \n",
    "        load_best_model_at_end=True,  # Load the best model when training ends\n",
    "        metric_for_best_model=\"eval_loss\",  # Metric to monitor for early stopping\n",
    "        greater_is_better=False,  # For loss\n",
    "    )\n",
    "\n",
    "pretrain_trainer = Trainer(\n",
    "    model=pretrain_model,\n",
    "    args=pretrain_args,\n",
    "    train_dataset=dset_train,\n",
    "    eval_dataset=dset_val,\n",
    "    callbacks=[early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67be058a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25200' max='25200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25200/25200 07:12, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.064500</td>\n",
       "      <td>0.751602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.824200</td>\n",
       "      <td>0.620294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.729200</td>\n",
       "      <td>0.547623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.670800</td>\n",
       "      <td>0.499021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.634900</td>\n",
       "      <td>0.471680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.610400</td>\n",
       "      <td>0.450470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.594000</td>\n",
       "      <td>0.436930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.580700</td>\n",
       "      <td>0.427861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.572900</td>\n",
       "      <td>0.417699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.566000</td>\n",
       "      <td>0.410220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.559900</td>\n",
       "      <td>0.405185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.556600</td>\n",
       "      <td>0.399340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.552000</td>\n",
       "      <td>0.394550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.548200</td>\n",
       "      <td>0.390236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.544300</td>\n",
       "      <td>0.385956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.542600</td>\n",
       "      <td>0.382166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.539500</td>\n",
       "      <td>0.379214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.537300</td>\n",
       "      <td>0.374995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.535000</td>\n",
       "      <td>0.373564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.532800</td>\n",
       "      <td>0.368819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.531200</td>\n",
       "      <td>0.365917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.530300</td>\n",
       "      <td>0.364193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.529000</td>\n",
       "      <td>0.360163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.526800</td>\n",
       "      <td>0.357074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.524700</td>\n",
       "      <td>0.357058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.524500</td>\n",
       "      <td>0.353242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.522900</td>\n",
       "      <td>0.352755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.521500</td>\n",
       "      <td>0.348743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.521300</td>\n",
       "      <td>0.349079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.519300</td>\n",
       "      <td>0.347196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.518700</td>\n",
       "      <td>0.347380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.517800</td>\n",
       "      <td>0.347567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.516700</td>\n",
       "      <td>0.345255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.516400</td>\n",
       "      <td>0.343885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.515500</td>\n",
       "      <td>0.344228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.514400</td>\n",
       "      <td>0.341788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.514300</td>\n",
       "      <td>0.341458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.513300</td>\n",
       "      <td>0.341324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.512900</td>\n",
       "      <td>0.341212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.512200</td>\n",
       "      <td>0.339680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.512400</td>\n",
       "      <td>0.339371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.511300</td>\n",
       "      <td>0.339823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.511400</td>\n",
       "      <td>0.337776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.510700</td>\n",
       "      <td>0.335845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.510600</td>\n",
       "      <td>0.336758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.509500</td>\n",
       "      <td>0.336689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.509600</td>\n",
       "      <td>0.335972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.509400</td>\n",
       "      <td>0.335644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.508800</td>\n",
       "      <td>0.335113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.508600</td>\n",
       "      <td>0.333798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.508400</td>\n",
       "      <td>0.332963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.508300</td>\n",
       "      <td>0.334344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.507900</td>\n",
       "      <td>0.332674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.507100</td>\n",
       "      <td>0.332943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.508000</td>\n",
       "      <td>0.333894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.507200</td>\n",
       "      <td>0.331781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.507200</td>\n",
       "      <td>0.331564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.507000</td>\n",
       "      <td>0.332920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.505600</td>\n",
       "      <td>0.331297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.506300</td>\n",
       "      <td>0.330505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.506000</td>\n",
       "      <td>0.331075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.505700</td>\n",
       "      <td>0.329950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.505700</td>\n",
       "      <td>0.329156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.504900</td>\n",
       "      <td>0.328145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.504800</td>\n",
       "      <td>0.331825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.504300</td>\n",
       "      <td>0.329529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.504400</td>\n",
       "      <td>0.328976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.504700</td>\n",
       "      <td>0.328397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.504600</td>\n",
       "      <td>0.327660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.503600</td>\n",
       "      <td>0.327803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.504300</td>\n",
       "      <td>0.328301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.504500</td>\n",
       "      <td>0.327707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.503000</td>\n",
       "      <td>0.327144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.503500</td>\n",
       "      <td>0.327647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.503800</td>\n",
       "      <td>0.327100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.503000</td>\n",
       "      <td>0.327786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.503000</td>\n",
       "      <td>0.327231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.503100</td>\n",
       "      <td>0.327461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.503800</td>\n",
       "      <td>0.327244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.503200</td>\n",
       "      <td>0.326404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.502900</td>\n",
       "      <td>0.326327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.503200</td>\n",
       "      <td>0.325918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.502500</td>\n",
       "      <td>0.325971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.503100</td>\n",
       "      <td>0.326827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.503100</td>\n",
       "      <td>0.326652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.503200</td>\n",
       "      <td>0.326069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.502900</td>\n",
       "      <td>0.325573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.502100</td>\n",
       "      <td>0.324864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.502200</td>\n",
       "      <td>0.326341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.502700</td>\n",
       "      <td>0.325146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.502200</td>\n",
       "      <td>0.324982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.502700</td>\n",
       "      <td>0.326295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.502900</td>\n",
       "      <td>0.324697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.502100</td>\n",
       "      <td>0.325848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.502600</td>\n",
       "      <td>0.326000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.502900</td>\n",
       "      <td>0.326180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.502200</td>\n",
       "      <td>0.326188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.501400</td>\n",
       "      <td>0.326197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.502300</td>\n",
       "      <td>0.324844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.502200</td>\n",
       "      <td>0.325200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=25200, training_loss=0.5301023770892431, metrics={'train_runtime': 432.8078, 'train_samples_per_second': 1856.02, 'train_steps_per_second': 58.224, 'total_flos': 852929082163200.0, 'train_loss': 0.5301023770892431, 'epoch': 100.0})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f26e8795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3986164629459381,\n",
       " 'eval_runtime': 0.1289,\n",
       " 'eval_samples_per_second': 21608.126,\n",
       " 'eval_steps_per_second': 23.276,\n",
       " 'epoch': 100.0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain_trainer.evaluate(dset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dd5711",
   "metadata": {},
   "source": [
    "### Save batch and output for pytests (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b867089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<accelerate.data_loader.DataLoaderShard at 0x14a5dabc02e0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get train dataloader\n",
    "eval_dataloader = pretrain_trainer.get_eval_dataloader()\n",
    "eval_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f58dc992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['context_values'])\n",
      "torch.Size([1024, 512, 7])\n"
     ]
    }
   ],
   "source": [
    "for X in eval_dataloader:\n",
    "    print(X.keys())\n",
    "    print(X[\"context_values\"].shape)\n",
    "    torch.save(X, \"./dump/etth1/pretrain/batch.pt\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9640ef9a",
   "metadata": {},
   "source": [
    "### Saving and loading the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7fd657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_trainer.save_model(\"./dump/etth1/pretrain/patchtsmixer_pretrained_etth1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "30fdbce0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_model = PatchTSMixerForMaskPretraining.from_pretrained('./dump/etth1/pretrain/patchtsmixer_pretrained_etth1').to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a41e7f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3092]],\n",
      "\n",
      "        [[ 0.6213]],\n",
      "\n",
      "        [[-0.2071]],\n",
      "\n",
      "        [[-0.2825]],\n",
      "\n",
      "        [[-0.4129]],\n",
      "\n",
      "        [[ 2.3598]],\n",
      "\n",
      "        [[ 0.1951]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "loaded_model.eval()\n",
    "with torch.no_grad():\n",
    "    d_out = loaded_model.forward(X['context_values'].reshape(1024,seq_len,n_features).to(\"cuda\"))\n",
    "print(d_out.prediction_logits[0, :7, :1, :1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904c76d8",
   "metadata": {},
   "source": [
    "Copy the above values in a pytest and use the dumped model to verify (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54237ad7",
   "metadata": {},
   "source": [
    "## 3. Use the pretrained model (step 2) to finetune for a forecasting task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "148f5c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PatchTSMixerForForecasting were not initialized from the model checkpoint at ./dump/etth1/pretrain/patchtsmixer_pretrained_etth1 and are newly initialized: ['head.head.base_forecast_block.1.bias', 'head.head.base_forecast_block.1.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "finetune_forecast_model = PatchTSMixerForForecasting.from_pretrained('./dump/etth1/pretrain/patchtsmixer_pretrained_etth1')\n",
    "\n",
    "finetune_forecast_args = TrainingArguments(\n",
    "        output_dir='./dump/etth1/finetune_forecast/checkpoint',\n",
    "        overwrite_output_dir=True,\n",
    "        learning_rate=0.0001,\n",
    "        num_train_epochs=100,\n",
    "        do_eval=True,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=1024,\n",
    "        report_to='tensorboard',\n",
    "        save_strategy='epoch',\n",
    "        logging_strategy=\"epoch\",\n",
    "        save_total_limit=3,\n",
    "        logging_dir='./dump/etth1/finetune_forecast/logs',  # Make sure to specify a logging directory\n",
    "        \n",
    "        load_best_model_at_end=True,  # Load the best model when training ends\n",
    "        metric_for_best_model=\"eval_loss\",  # Metric to monitor for early stopping\n",
    "        greater_is_better=False,  # For loss\n",
    "    )\n",
    "\n",
    "finetune_forecast_trainer = Trainer(\n",
    "    model=finetune_forecast_model,\n",
    "    args=finetune_forecast_args,\n",
    "    train_dataset=dset_train,\n",
    "    eval_dataset=dset_val,\n",
    "    callbacks=[early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "29c6a73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5292' max='25200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 5292/25200 01:30 < 05:39, 58.72 it/s, Epoch 21/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.521100</td>\n",
       "      <td>0.798352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.421900</td>\n",
       "      <td>0.750673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.396400</td>\n",
       "      <td>0.727025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.382100</td>\n",
       "      <td>0.716788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.374500</td>\n",
       "      <td>0.705748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.368100</td>\n",
       "      <td>0.704222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.363000</td>\n",
       "      <td>0.697547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.361100</td>\n",
       "      <td>0.697067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.356400</td>\n",
       "      <td>0.693689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.353800</td>\n",
       "      <td>0.692488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.352100</td>\n",
       "      <td>0.689431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.350700</td>\n",
       "      <td>0.690968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.346800</td>\n",
       "      <td>0.690534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>0.690416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.691247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.344700</td>\n",
       "      <td>0.691341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.342700</td>\n",
       "      <td>0.694459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.341800</td>\n",
       "      <td>0.692595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.341600</td>\n",
       "      <td>0.690527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.340500</td>\n",
       "      <td>0.692393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.337800</td>\n",
       "      <td>0.695145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5292, training_loss=0.36609856395764684, metrics={'train_runtime': 90.1336, 'train_samples_per_second': 8912.326, 'train_steps_per_second': 279.585, 'total_flos': 711526928007168.0, 'train_loss': 0.36609856395764684, 'epoch': 21.0})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_forecast_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ac43fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.36578306555747986,\n",
       " 'eval_runtime': 0.1696,\n",
       " 'eval_samples_per_second': 16425.723,\n",
       " 'eval_steps_per_second': 17.694,\n",
       " 'epoch': 21.0}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_forecast_trainer.evaluate(dset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e417dd2d",
   "metadata": {},
   "source": [
    "### Save/Load and dump outputs for pytest (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4c3c5cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_forecast_trainer.save_model(\"./dump/etth1/finetune_forecast/patchtsmixer_finetune_forecast_etth1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "83fe0da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<accelerate.data_loader.DataLoaderShard at 0x14a5ddd54640>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get train dataloader\n",
    "eval_dataloader = finetune_forecast_trainer.get_eval_dataloader()\n",
    "eval_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c80c0b9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_model = PatchTSMixerForForecasting.from_pretrained('./dump/etth1/finetune_forecast/patchtsmixer_finetune_forecast_etth1').to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "02383ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['context_values', 'target_values'])\n",
      "torch.Size([1024, 512, 7]) torch.Size([1024, 96, 7])\n"
     ]
    }
   ],
   "source": [
    "for X in eval_dataloader:\n",
    "    print(X.keys())\n",
    "    print(X[\"context_values\"].shape, X[\"target_values\"].shape)\n",
    "    torch.save(X, \"./dump/etth1/finetune_forecast/batch_forecast.pt\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "be41efeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4179, -0.0815,  0.4532,  0.7133, -0.3059, -2.3659,  0.2807]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "loaded_model.eval()\n",
    "with torch.no_grad():\n",
    "    output_batch = loaded_model(X[\"context_values\"])\n",
    "print(output_batch.prediction_logits[0, :1, :7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ebfcfa",
   "metadata": {},
   "source": [
    "Copy the above values in a pytest and use the dumped model to verify (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed406193",
   "metadata": {},
   "source": [
    "## 4. Use pretrained model to finetune for a prediction task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cc0b591f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./dump/etth1/pretrain/patchtsmixer_pretrained_etth1 were not used when initializing PatchTSMixerForForecasting: ['head.head.base_pt_block.1.weight', 'head.head.base_pt_block.1.bias']\n",
      "- This IS expected if you are initializing PatchTSMixerForForecasting from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing PatchTSMixerForForecasting from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of PatchTSMixerForForecasting were not initialized from the model checkpoint at ./dump/etth1/pretrain/patchtsmixer_pretrained_etth1 and are newly initialized: ['head.head.base_forecast_block.1.bias', 'head.head.base_forecast_block.1.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# We can either provide the forecast channel indices during pretraining\n",
    "# Or, we can update the config and pass it again\n",
    "pretrain_config.update({\"forecast_channel_indices\": [3,5]})\n",
    "finetune_prediction_model = PatchTSMixerForForecasting.from_pretrained('./dump/etth1/pretrain/patchtsmixer_pretrained_etth1', config=pretrain_config)\n",
    "\n",
    "\n",
    "finetune_prediction_args = TrainingArguments(\n",
    "        output_dir='./dump/etth1/finetune_prediction/checkpoint',\n",
    "        overwrite_output_dir=True,\n",
    "        learning_rate=0.0001,\n",
    "        num_train_epochs=100,\n",
    "        do_eval=True,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=1024,\n",
    "        report_to='tensorboard',\n",
    "        save_strategy='epoch',\n",
    "        logging_strategy=\"epoch\",\n",
    "        save_total_limit=3,\n",
    "        logging_dir='./dump/etth1/finetune_prediction/logs',  # Make sure to specify a logging directory\n",
    "        \n",
    "        load_best_model_at_end=True,  # Load the best model when training ends\n",
    "        metric_for_best_model=\"eval_loss\",  # Metric to monitor for early stopping\n",
    "        greater_is_better=False,  # For loss\n",
    "    )\n",
    "\n",
    "finetune_prediction_trainer = Trainer(\n",
    "    model=finetune_prediction_model,\n",
    "    args=finetune_prediction_args,\n",
    "    train_dataset=dset_train,\n",
    "    eval_dataset=dset_val,\n",
    "    callbacks=[early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3cf65b2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13104' max='25200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13104/25200 03:41 < 03:24, 59.08 it/s, Epoch 52/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.471100</td>\n",
       "      <td>1.063311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.381700</td>\n",
       "      <td>0.968746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.356300</td>\n",
       "      <td>0.951072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.340300</td>\n",
       "      <td>0.910686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.332200</td>\n",
       "      <td>0.889850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.323900</td>\n",
       "      <td>0.905374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.319300</td>\n",
       "      <td>0.894543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.317300</td>\n",
       "      <td>0.900420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.310300</td>\n",
       "      <td>0.876824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.305300</td>\n",
       "      <td>0.876611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.304600</td>\n",
       "      <td>0.861640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.300500</td>\n",
       "      <td>0.866134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.296900</td>\n",
       "      <td>0.861691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.295200</td>\n",
       "      <td>0.864132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.294600</td>\n",
       "      <td>0.866830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.292100</td>\n",
       "      <td>0.873413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.290600</td>\n",
       "      <td>0.876111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.290500</td>\n",
       "      <td>0.856560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.289700</td>\n",
       "      <td>0.855160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.287300</td>\n",
       "      <td>0.856204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.284500</td>\n",
       "      <td>0.850275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.283100</td>\n",
       "      <td>0.856648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.282600</td>\n",
       "      <td>0.845566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.281200</td>\n",
       "      <td>0.855643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.280200</td>\n",
       "      <td>0.845296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.279400</td>\n",
       "      <td>0.837820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.278800</td>\n",
       "      <td>0.846802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.275600</td>\n",
       "      <td>0.841035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.277400</td>\n",
       "      <td>0.835349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.275500</td>\n",
       "      <td>0.836622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.275600</td>\n",
       "      <td>0.836364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.275400</td>\n",
       "      <td>0.841217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.274000</td>\n",
       "      <td>0.835252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.272100</td>\n",
       "      <td>0.849679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.272600</td>\n",
       "      <td>0.829977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.271600</td>\n",
       "      <td>0.828511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.270600</td>\n",
       "      <td>0.839626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.271400</td>\n",
       "      <td>0.840293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.279200</td>\n",
       "      <td>0.840311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>0.846045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.269600</td>\n",
       "      <td>0.839933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.270800</td>\n",
       "      <td>0.827300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.268900</td>\n",
       "      <td>0.837910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.268000</td>\n",
       "      <td>0.835919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.268200</td>\n",
       "      <td>0.839337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.267400</td>\n",
       "      <td>0.838319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.273800</td>\n",
       "      <td>0.844334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.265900</td>\n",
       "      <td>0.847192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.266300</td>\n",
       "      <td>0.835321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.266100</td>\n",
       "      <td>0.841005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.266000</td>\n",
       "      <td>0.839594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.264300</td>\n",
       "      <td>0.837705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=13104, training_loss=0.2912400167649191, metrics={'train_runtime': 221.7843, 'train_samples_per_second': 3621.988, 'train_steps_per_second': 113.624, 'total_flos': 1761876202684416.0, 'train_loss': 0.2912400167649191, 'epoch': 52.0})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_prediction_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6f462b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 02:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.14809785783290863,\n",
       " 'eval_runtime': 0.171,\n",
       " 'eval_samples_per_second': 16281.896,\n",
       " 'eval_steps_per_second': 17.539,\n",
       " 'epoch': 52.0}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_prediction_trainer.evaluate(dset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c67928ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.8272998332977295,\n",
       " 'eval_runtime': 0.1701,\n",
       " 'eval_samples_per_second': 16376.718,\n",
       " 'eval_steps_per_second': 17.641,\n",
       " 'epoch': 52.0}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_prediction_trainer.evaluate(dset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4c64d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_prediction_trainer.save_model(\"./dump/etth1/finetune_prediction/patchtsmixer_finetune_prediction_etth1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "63eec2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<accelerate.data_loader.DataLoaderShard at 0x14a5dddca670>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get train dataloader\n",
    "eval_dataloader = finetune_prediction_trainer.get_eval_dataloader()\n",
    "eval_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a3717bfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_model = PatchTSMixerForForecasting.from_pretrained('./dump/etth1/finetune_prediction/patchtsmixer_finetune_prediction_etth1').to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "44d6d2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['context_values', 'target_values'])\n",
      "torch.Size([1024, 512, 7]) torch.Size([1024, 96, 7])\n"
     ]
    }
   ],
   "source": [
    "for X in eval_dataloader:\n",
    "    print(X.keys())\n",
    "    print(X[\"context_values\"].shape, X[\"target_values\"].shape)\n",
    "    torch.save(X, \"./dump/etth1/finetune_prediction/batch_prediction.pt\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "668dda5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 96, 2])\n",
      "tensor([[ 0.6744, -2.3873]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "loaded_model.eval()\n",
    "with torch.no_grad():\n",
    "    output_batch = loaded_model(X[\"context_values\"])\n",
    "print(output_batch.prediction_logits.shape)\n",
    "print(output_batch.prediction_logits[0, :1, :7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a3cd75",
   "metadata": {},
   "source": [
    "Note that, the output has only 2 channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619e7ab6",
   "metadata": {},
   "source": [
    "## 5. Register model under Auto Classes and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3bb27f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModel, AutoModelForPreTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f2091828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoConfig.register(\"patchtsmixer\", PatchTSMixerConfig)\n",
    "AutoModelForPreTraining.register(PatchTSMixerConfig, PatchTSMixerForMaskPretraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d9f6edd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_model = AutoModelForPreTraining.from_pretrained('./dump/etth1/pretrain/patchtsmixer_pretrained_etth1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "be5f6812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.1099,  0.1911,  0.2393,  ...,  0.4792,  0.5710,  0.6027],\n",
       "          [ 0.2099,  0.0878, -0.0625,  ...,  0.2933,  0.3861,  0.5001],\n",
       "          [ 0.5203,  0.5468,  0.5345,  ..., -1.1861, -1.0121, -0.7806],\n",
       "          ...,\n",
       "          [ 0.8465,  0.8854,  0.8678,  ..., -2.5289, -2.1887, -1.7487],\n",
       "          [-0.3460, -0.1029,  0.1233,  ...,  0.8395,  0.7848,  0.6829],\n",
       "          [-0.2900, -0.4114, -0.5374,  ...,  0.3404,  0.3283,  0.3139]],\n",
       "\n",
       "         [[-1.5066, -1.5974, -1.7086,  ..., -0.9671, -0.9586, -0.9059],\n",
       "          [-0.7273, -0.7845, -0.8463,  ..., -1.9130, -1.5215, -1.1196],\n",
       "          [-0.6896, -0.7026, -0.7588,  ..., -1.3015, -1.5143, -1.5829],\n",
       "          ...,\n",
       "          [ 1.0302,  1.0833,  1.0637,  ...,  1.5262,  1.1418,  0.7456],\n",
       "          [-0.3708, -0.4422, -0.4905,  ...,  0.9482,  0.7597,  0.6537],\n",
       "          [ 0.7262,  0.7794,  0.7970,  ...,  0.0542,  0.1150,  0.1876]],\n",
       "\n",
       "         [[ 0.0588,  0.1476,  0.2144,  ...,  0.5340,  0.5515,  0.5221],\n",
       "          [ 0.1438,  0.0114, -0.1591,  ...,  0.3195,  0.4271,  0.5519],\n",
       "          [ 0.6962,  0.7435,  0.7375,  ..., -1.0923, -0.8934, -0.6538],\n",
       "          ...,\n",
       "          [ 0.7694,  0.8323,  0.8309,  ..., -2.4989, -2.1317, -1.6909],\n",
       "          [-0.3733, -0.1661,  0.0246,  ...,  0.7150,  0.6435,  0.5289],\n",
       "          [-0.3633, -0.4910, -0.6199,  ...,  0.2729,  0.2765,  0.2789]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.6748,  0.6590,  0.4849,  ..., -0.6340, -0.1186,  0.2534],\n",
       "          [ 0.2170,  0.4195,  0.6125,  ..., -0.4873, -0.9359, -1.2017],\n",
       "          [-1.7304, -1.8921, -1.9840,  ..., -0.5963, -0.8502, -0.9681],\n",
       "          ...,\n",
       "          [ 0.4977,  0.4542,  0.3801,  ..., -0.0590, -0.2647, -0.3319],\n",
       "          [ 0.8331,  1.0311,  1.2783,  ...,  1.4770,  1.7295,  1.8260],\n",
       "          [ 0.6399,  0.6786,  0.6967,  ...,  0.5234,  0.4457,  0.4086]],\n",
       "\n",
       "         [[-2.0242, -2.2486, -2.4617,  ..., -2.5740, -2.4670, -2.2631],\n",
       "          [-2.1113, -2.1499, -2.1492,  ..., -2.9636, -2.9551, -2.8034],\n",
       "          [-2.8757, -2.9603, -2.9690,  ..., -2.4233, -2.4700, -2.4321],\n",
       "          ...,\n",
       "          [ 0.4810,  0.5174,  0.5634,  ...,  0.5673,  0.5306,  0.4995],\n",
       "          [ 0.6250,  0.6276,  0.6846,  ...,  0.9468,  0.8318,  0.7438],\n",
       "          [ 0.7378,  0.7902,  0.8149,  ...,  0.2558,  0.2471,  0.2810]],\n",
       "\n",
       "         [[ 0.1936,  0.1421,  0.1296,  ...,  0.0519, -0.0228, -0.0418],\n",
       "          [ 0.0644, -0.0142, -0.0432,  ..., -1.1953, -1.2446, -1.0888],\n",
       "          [-0.6209, -0.6165, -0.5739,  ...,  0.1107,  0.1739,  0.1889],\n",
       "          ...,\n",
       "          [ 0.3198,  0.2942,  0.2611,  ...,  1.1723,  1.2652,  1.2448],\n",
       "          [ 1.3666,  1.3407,  1.2185,  ...,  0.5132,  0.3048,  0.1993],\n",
       "          [ 0.4776,  0.5785,  0.6791,  ...,  0.3802,  0.2986,  0.2766]]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# auto_model(test_data.to('mps')).prediction_logits\n",
    "auto_model(dset_test.__getitem__(0)['context_values'].reshape(1,seq_len,n_features)).prediction_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d95109",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
