{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95c3f79b",
   "metadata": {},
   "source": [
    "# PatchTSMixer workflow examples on ETTH dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bbecb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dccstor/dnn_forecasting/conda_envs/envs/fm/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import PatchTSMixerConfig, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d150c40b",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c49eb6a",
   "metadata": {},
   "source": [
    "Generate and prepare dummy data to test the pretraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bde199a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "class ETTDataset(Dataset):\n",
    "    def __init__(self, root_path='/dccstor/dnn_forecasting/FM/data/ETDataset/ETT-small/', data_file='ETTh2.csv', \n",
    "                 seq_len=128, pred_len=32,\n",
    "                 split='train',                  \n",
    "                 scale=True\n",
    "                 ):\n",
    "        \n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        # init\n",
    "        assert split in ['train', 'test', 'val']\n",
    "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
    "        self.set_type = type_map[split]\n",
    "                \n",
    "        self.scale = scale                        \n",
    "\n",
    "        self.root_path = root_path\n",
    "        self.data_file = data_file\n",
    "        self.__read_data__()\n",
    "\n",
    "    def __read_data__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        df_raw = pd.read_csv(os.path.join(self.root_path, self.data_file))\n",
    "\n",
    "        border1s = [0, 12 * 30 * 24 - self.seq_len, 12 * 30 * 24 + 4 * 30 * 24 - self.seq_len]\n",
    "        border2s = [12 * 30 * 24, 12 * 30 * 24 + 4 * 30 * 24, 12 * 30 * 24 + 8 * 30 * 24]\n",
    "        border1 = border1s[self.set_type]\n",
    "        border2 = border2s[self.set_type]\n",
    "        \n",
    "        cols_data = df_raw.columns[1:]\n",
    "        df_data = df_raw[cols_data]\n",
    "\n",
    "        if self.scale:\n",
    "            train_data = df_data[border1s[0]:border2s[0]]\n",
    "            self.scaler.fit(train_data.values)\n",
    "            data = self.scaler.transform(df_data.values)\n",
    "        else:\n",
    "            data = df_data.values\n",
    "        \n",
    "        self.data_x = data[border1:border2]\n",
    "        self.data_y = data[border1:border2]        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        s_begin = index\n",
    "        s_end = s_begin + self.seq_len\n",
    "        r_begin = s_end\n",
    "        r_end = r_begin + self.pred_len \n",
    "\n",
    "        seq_x = self.data_x[s_begin:s_end]\n",
    "        seq_y = self.data_y[r_begin:r_end]        \n",
    "        return {\"context_values\": torch.Tensor(seq_x), \"target_values\": torch.Tensor(seq_y)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        return self.scaler.inverse_transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f27b096",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORECAST_LEN = 96\n",
    "n_features = 7\n",
    "SEQ_LEN = 512\n",
    "seq_len = SEQ_LEN\n",
    "patch_len = 16\n",
    "stride = patch_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1afd7a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_train = ETTDataset(split=\"train\", seq_len=SEQ_LEN, pred_len=FORECAST_LEN)\n",
    "dset_val = ETTDataset(split=\"val\", seq_len=SEQ_LEN, pred_len=FORECAST_LEN)\n",
    "dset_test = ETTDataset(split=\"test\", seq_len=SEQ_LEN, pred_len=FORECAST_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9320e678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 7]), torch.Size([96, 7]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd=dset_val.__getitem__(0)\n",
    "dd[\"context_values\"].shape, dd[\"target_values\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78978587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_patches should be (no need to specify)\n",
    "num_patches = seq_len//patch_len\n",
    "num_patches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526ece88",
   "metadata": {},
   "source": [
    "## 1. Directly train a `PatchTSMixer` forecasting model, and evaluate the test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66e6c2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PatchTSMixerForForecasting\n",
    "\n",
    "forecast_config = PatchTSMixerConfig(\n",
    "    in_channels=n_features,\n",
    "    seq_len=SEQ_LEN,\n",
    "    patch_len=patch_len,\n",
    "    stride=stride,\n",
    "    num_features=48,\n",
    "    num_layers=2,\n",
    "    dropout=0.5,\n",
    "    mode=\"common_channel\",\n",
    "    revin=True,\n",
    "    expansion_factor=3,\n",
    "    head_dropout=0.7,\n",
    "    forecast_len=FORECAST_LEN\n",
    ")\n",
    "\n",
    "forecast_model = PatchTSMixerForForecasting(forecast_config)\n",
    "\n",
    "forecast_args = TrainingArguments(\n",
    "        output_dir='./dump/etth2/direct_forecast/checkpoint',\n",
    "        overwrite_output_dir=True,\n",
    "        learning_rate=0.0001,\n",
    "        num_train_epochs=100,\n",
    "        do_eval=True,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=1024,\n",
    "        report_to='tensorboard',\n",
    "        save_strategy='epoch',\n",
    "        logging_strategy=\"epoch\",\n",
    "        save_total_limit=3,\n",
    "        logging_dir='./dump/etth2/direct_forecast/logs',  # Make sure to specify a logging directory\n",
    "        \n",
    "        load_best_model_at_end=True,  # Load the best model when training ends\n",
    "        metric_for_best_model=\"eval_loss\",  # Metric to monitor for early stopping\n",
    "        greater_is_better=False,  # For loss\n",
    "    )\n",
    "\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "# Create the early stopping callback\n",
    "early_stopping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience=10,  # Number of epochs with no improvement after which to stop\n",
    "    early_stopping_threshold=0.0001,  # Minimum improvement required to consider as improvement\n",
    ")\n",
    "\n",
    "forecast_trainer = Trainer(\n",
    "    model=forecast_model,\n",
    "    args=forecast_args,\n",
    "    train_dataset=dset_train,\n",
    "    eval_dataset=dset_val,\n",
    "    callbacks=[early_stopping_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40714b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4536' max='25200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 4536/25200 00:45 < 03:27, 99.54 it/s, Epoch 18/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.581600</td>\n",
       "      <td>0.231726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.484400</td>\n",
       "      <td>0.220617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.454100</td>\n",
       "      <td>0.215540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.436900</td>\n",
       "      <td>0.211976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.428100</td>\n",
       "      <td>0.210721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.420800</td>\n",
       "      <td>0.207517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.415500</td>\n",
       "      <td>0.208131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.412200</td>\n",
       "      <td>0.207082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.408600</td>\n",
       "      <td>0.208413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.404600</td>\n",
       "      <td>0.208888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.401800</td>\n",
       "      <td>0.209868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.399000</td>\n",
       "      <td>0.209597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.396700</td>\n",
       "      <td>0.208525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.393200</td>\n",
       "      <td>0.208558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.391800</td>\n",
       "      <td>0.208841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.387900</td>\n",
       "      <td>0.207676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.387100</td>\n",
       "      <td>0.208467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.385200</td>\n",
       "      <td>0.207148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4536, training_loss=0.4216494383635344, metrics={'train_runtime': 47.2475, 'train_samples_per_second': 17001.967, 'train_steps_per_second': 533.362, 'total_flos': 609880224006144.0, 'train_loss': 0.4216494383635344, 'epoch': 18.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfe9293c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2684691846370697,\n",
       " 'eval_runtime': 0.0813,\n",
       " 'eval_samples_per_second': 34255.332,\n",
       " 'eval_steps_per_second': 36.9,\n",
       " 'epoch': 18.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_trainer.evaluate(dset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a507a0ca",
   "metadata": {},
   "source": [
    "## 2. Pretrain a `PatchTSMixer` model with HF trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a47daa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PatchTSMixerForMaskPretraining\n",
    "\n",
    "pretrain_config = PatchTSMixerConfig(\n",
    "    in_channels=n_features,\n",
    "    seq_len=SEQ_LEN,\n",
    "    patch_len=patch_len,\n",
    "    stride=stride,\n",
    "    num_features=48,\n",
    "    num_layers=2,\n",
    "    dropout=0.5,\n",
    "    mode=\"common_channel\",\n",
    "    revin=True,\n",
    "    expansion_factor=3,\n",
    "    head_dropout=0.7,\n",
    "    forecast_len=FORECAST_LEN\n",
    ")\n",
    "\n",
    "pretrain_model = PatchTSMixerForMaskPretraining(pretrain_config)\n",
    "\n",
    "pretrain_args = TrainingArguments(\n",
    "        output_dir='./dump/etth2/pretrain/checkpoint',\n",
    "        overwrite_output_dir=True,\n",
    "        learning_rate=0.0001,\n",
    "        num_train_epochs=100,\n",
    "        do_eval=True,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=1024,\n",
    "        report_to='tensorboard',\n",
    "        save_strategy='epoch',\n",
    "        logging_strategy=\"epoch\",\n",
    "        save_total_limit=3,\n",
    "        logging_dir='./dump/etth2/pretrain/logs',  # Make sure to specify a logging directory\n",
    "        \n",
    "        load_best_model_at_end=True,  # Load the best model when training ends\n",
    "        metric_for_best_model=\"eval_loss\",  # Metric to monitor for early stopping\n",
    "        greater_is_better=False,  # For loss\n",
    "    )\n",
    "\n",
    "pretrain_trainer = Trainer(\n",
    "    model=pretrain_model,\n",
    "    args=pretrain_args,\n",
    "    train_dataset=dset_train,\n",
    "    eval_dataset=dset_val,\n",
    "    callbacks=[early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "424008eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19656' max='25200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19656/25200 03:25 < 00:58, 95.46 it/s, Epoch 78/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.058700</td>\n",
       "      <td>0.763012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.824200</td>\n",
       "      <td>0.643187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.731500</td>\n",
       "      <td>0.578778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.674500</td>\n",
       "      <td>0.539403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.640900</td>\n",
       "      <td>0.512444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.615500</td>\n",
       "      <td>0.494741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.596700</td>\n",
       "      <td>0.479723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.585300</td>\n",
       "      <td>0.465993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.575400</td>\n",
       "      <td>0.455753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.567500</td>\n",
       "      <td>0.447083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.560200</td>\n",
       "      <td>0.442111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.555700</td>\n",
       "      <td>0.435504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.550600</td>\n",
       "      <td>0.427609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.545700</td>\n",
       "      <td>0.424231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.543000</td>\n",
       "      <td>0.420500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.539400</td>\n",
       "      <td>0.416579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.535100</td>\n",
       "      <td>0.413813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.533500</td>\n",
       "      <td>0.411064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.531200</td>\n",
       "      <td>0.408578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.529900</td>\n",
       "      <td>0.406687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.528700</td>\n",
       "      <td>0.403592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.527800</td>\n",
       "      <td>0.403347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.524800</td>\n",
       "      <td>0.399865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.524000</td>\n",
       "      <td>0.395966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.523200</td>\n",
       "      <td>0.396166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.520800</td>\n",
       "      <td>0.394693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.520300</td>\n",
       "      <td>0.392943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.518900</td>\n",
       "      <td>0.391370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.517900</td>\n",
       "      <td>0.392575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.518200</td>\n",
       "      <td>0.390573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.515400</td>\n",
       "      <td>0.388803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.515600</td>\n",
       "      <td>0.387259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.514800</td>\n",
       "      <td>0.388412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.515200</td>\n",
       "      <td>0.386256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>0.386799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>0.385557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.511700</td>\n",
       "      <td>0.384201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.511800</td>\n",
       "      <td>0.384079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.511100</td>\n",
       "      <td>0.385114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.511500</td>\n",
       "      <td>0.382106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.510600</td>\n",
       "      <td>0.382077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.510900</td>\n",
       "      <td>0.380390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.509300</td>\n",
       "      <td>0.381248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.509100</td>\n",
       "      <td>0.380218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.508900</td>\n",
       "      <td>0.379493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.509000</td>\n",
       "      <td>0.379289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.507600</td>\n",
       "      <td>0.380049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.506800</td>\n",
       "      <td>0.377768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.507000</td>\n",
       "      <td>0.378478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.508300</td>\n",
       "      <td>0.376867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.507100</td>\n",
       "      <td>0.375633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.506800</td>\n",
       "      <td>0.377964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.506400</td>\n",
       "      <td>0.375799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.505700</td>\n",
       "      <td>0.376281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.505800</td>\n",
       "      <td>0.377528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.504900</td>\n",
       "      <td>0.377521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.505600</td>\n",
       "      <td>0.376372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.505200</td>\n",
       "      <td>0.376596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.504200</td>\n",
       "      <td>0.374555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.504000</td>\n",
       "      <td>0.375740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.504500</td>\n",
       "      <td>0.375888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.504200</td>\n",
       "      <td>0.376910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.504300</td>\n",
       "      <td>0.374891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.504700</td>\n",
       "      <td>0.376103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.503600</td>\n",
       "      <td>0.375080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.503200</td>\n",
       "      <td>0.372504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.503800</td>\n",
       "      <td>0.374926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.502200</td>\n",
       "      <td>0.372086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.502800</td>\n",
       "      <td>0.372617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.502200</td>\n",
       "      <td>0.373677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.501700</td>\n",
       "      <td>0.373919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.502600</td>\n",
       "      <td>0.373604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.503100</td>\n",
       "      <td>0.373319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.502600</td>\n",
       "      <td>0.374478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.502300</td>\n",
       "      <td>0.373058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.502000</td>\n",
       "      <td>0.374053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.502800</td>\n",
       "      <td>0.372649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.502400</td>\n",
       "      <td>0.372881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=19656, training_loss=0.5365301802918151, metrics={'train_runtime': 206.0018, 'train_samples_per_second': 3899.48, 'train_steps_per_second': 122.329, 'total_flos': 665284684087296.0, 'train_loss': 0.5365301802918151, 'epoch': 78.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0cdbaba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.41572117805480957,\n",
       " 'eval_runtime': 0.0766,\n",
       " 'eval_samples_per_second': 36356.648,\n",
       " 'eval_steps_per_second': 39.163,\n",
       " 'epoch': 78.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain_trainer.evaluate(dset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2086b481",
   "metadata": {},
   "source": [
    "### Save batch and output for pytests (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fb79fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<accelerate.data_loader.DataLoaderShard at 0x152ada876f10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get train dataloader\n",
    "eval_dataloader = pretrain_trainer.get_eval_dataloader()\n",
    "eval_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7a29ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['context_values'])\n",
      "torch.Size([1024, 512, 7])\n"
     ]
    }
   ],
   "source": [
    "for X in eval_dataloader:\n",
    "    print(X.keys())\n",
    "    print(X[\"context_values\"].shape)\n",
    "    torch.save(X, \"./dump/etth2/pretrain/batch.pt\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12799fe",
   "metadata": {},
   "source": [
    "### Saving and loading the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "373c489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_trainer.save_model(\"./dump/etth2/pretrain/patchtsmixer_pretrained_etth2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "270fdb67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_model = PatchTSMixerForMaskPretraining.from_pretrained('./dump/etth2/pretrain/patchtsmixer_pretrained_etth2').to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e5bb8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0342]],\n",
      "\n",
      "        [[-0.0571]],\n",
      "\n",
      "        [[ 0.7122]],\n",
      "\n",
      "        [[ 0.3961]],\n",
      "\n",
      "        [[-0.8683]],\n",
      "\n",
      "        [[-0.3770]],\n",
      "\n",
      "        [[ 1.0956]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "loaded_model.eval()\n",
    "with torch.no_grad():\n",
    "    d_out = loaded_model.forward(X['context_values'].reshape(1024,seq_len,n_features).to(\"cuda\"))\n",
    "print(d_out.prediction_logits[0, :7, :1, :1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb34608",
   "metadata": {},
   "source": [
    "Copy the above values in a pytest and use the dumped model to verify (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154222d4",
   "metadata": {},
   "source": [
    "## 3. Use the pretrained model (step 2) to finetune for a forecasting task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce160d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PatchTSMixerForForecasting were not initialized from the model checkpoint at ./dump/etth2/pretrain/patchtsmixer_pretrained_etth2 and are newly initialized: ['head.head.base_forecast_block.1.bias', 'head.head.base_forecast_block.1.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "finetune_forecast_model = PatchTSMixerForForecasting.from_pretrained('./dump/etth2/pretrain/patchtsmixer_pretrained_etth2')\n",
    "\n",
    "finetune_forecast_args = TrainingArguments(\n",
    "        output_dir='./dump/etth2/finetune_forecast/checkpoint',\n",
    "        overwrite_output_dir=True,\n",
    "        learning_rate=0.0001,\n",
    "        num_train_epochs=100,\n",
    "        do_eval=True,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=1024,\n",
    "        report_to='tensorboard',\n",
    "        save_strategy='epoch',\n",
    "        logging_strategy=\"epoch\",\n",
    "        save_total_limit=3,\n",
    "        logging_dir='./dump/etth2/finetune_forecast/logs',  # Make sure to specify a logging directory\n",
    "        \n",
    "        load_best_model_at_end=True,  # Load the best model when training ends\n",
    "        metric_for_best_model=\"eval_loss\",  # Metric to monitor for early stopping\n",
    "        greater_is_better=False,  # For loss\n",
    "    )\n",
    "\n",
    "finetune_forecast_trainer = Trainer(\n",
    "    model=finetune_forecast_model,\n",
    "    args=finetune_forecast_args,\n",
    "    train_dataset=dset_train,\n",
    "    eval_dataset=dset_val,\n",
    "    callbacks=[early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fdd4e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6048' max='25200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6048/25200 01:09 < 03:40, 86.98 it/s, Epoch 24/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.563300</td>\n",
       "      <td>0.246430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.479900</td>\n",
       "      <td>0.233743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.449200</td>\n",
       "      <td>0.228402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.431700</td>\n",
       "      <td>0.225942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.421800</td>\n",
       "      <td>0.222442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.413400</td>\n",
       "      <td>0.218763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.407200</td>\n",
       "      <td>0.219262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.402500</td>\n",
       "      <td>0.219313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.398400</td>\n",
       "      <td>0.219780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.395000</td>\n",
       "      <td>0.222942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.393100</td>\n",
       "      <td>0.220741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.389700</td>\n",
       "      <td>0.220671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.388200</td>\n",
       "      <td>0.218605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.386000</td>\n",
       "      <td>0.218292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.385600</td>\n",
       "      <td>0.218794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.381800</td>\n",
       "      <td>0.218965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.382000</td>\n",
       "      <td>0.221990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.380800</td>\n",
       "      <td>0.220109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.377600</td>\n",
       "      <td>0.221260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.375700</td>\n",
       "      <td>0.219073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.374000</td>\n",
       "      <td>0.222383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.372600</td>\n",
       "      <td>0.220890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.370500</td>\n",
       "      <td>0.219661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.370600</td>\n",
       "      <td>0.221456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6048, training_loss=0.4037793338614166, metrics={'train_runtime': 69.529, 'train_samples_per_second': 11553.456, 'train_steps_per_second': 362.439, 'total_flos': 813173632008192.0, 'train_loss': 0.4037793338614166, 'epoch': 24.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_forecast_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e69a9b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.27261653542518616,\n",
       " 'eval_runtime': 0.1176,\n",
       " 'eval_samples_per_second': 23682.364,\n",
       " 'eval_steps_per_second': 25.511,\n",
       " 'epoch': 24.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_forecast_trainer.evaluate(dset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fc885c",
   "metadata": {},
   "source": [
    "### Save/Load and dump outputs for pytest (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84784cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_forecast_trainer.save_model(\"./dump/etth2/finetune_forecast/patchtsmixer_finetune_forecast_etth2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0ccd20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<accelerate.data_loader.DataLoaderShard at 0x152ad9e0cfa0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get train dataloader\n",
    "eval_dataloader = finetune_forecast_trainer.get_eval_dataloader()\n",
    "eval_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3895d845",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_model = PatchTSMixerForForecasting.from_pretrained('./dump/etth2/finetune_forecast/patchtsmixer_finetune_forecast_etth2').to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0947c4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['context_values', 'target_values'])\n",
      "torch.Size([1024, 512, 7]) torch.Size([1024, 96, 7])\n"
     ]
    }
   ],
   "source": [
    "for X in eval_dataloader:\n",
    "    print(X.keys())\n",
    "    print(X[\"context_values\"].shape, X[\"target_values\"].shape)\n",
    "    torch.save(X, \"./dump/etth2/finetune_forecast/batch_forecast.pt\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "611fbd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9324, -0.8006, -0.3696,  0.1158, -1.9465, -0.1188,  0.8556]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "loaded_model.eval()\n",
    "with torch.no_grad():\n",
    "    output_batch = loaded_model(X[\"context_values\"])\n",
    "print(output_batch.prediction_logits[0, :1, :7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a41797a",
   "metadata": {},
   "source": [
    "Copy the above values in a pytest and use the dumped model to verify (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3141c25",
   "metadata": {},
   "source": [
    "## 4. Use pretrained model to finetune for a prediction task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9155bc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PatchTSMixerForForecasting were not initialized from the model checkpoint at ./dump/etth2/pretrain/patchtsmixer_pretrained_etth2 and are newly initialized: ['head.head.base_forecast_block.1.bias', 'head.head.base_forecast_block.1.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# We can either provide the forecast channel indices during pretraining\n",
    "# Or, we can update the config and pass it again\n",
    "pretrain_config.update({\"forecast_channel_indices\": [3,5]})\n",
    "finetune_prediction_model = PatchTSMixerForForecasting.from_pretrained('./dump/etth2/pretrain/patchtsmixer_pretrained_etth2', config=pretrain_config)\n",
    "\n",
    "\n",
    "finetune_prediction_args = TrainingArguments(\n",
    "        output_dir='./dump/etth2/finetune_prediction/checkpoint',\n",
    "        overwrite_output_dir=True,\n",
    "        learning_rate=0.0001,\n",
    "        num_train_epochs=100,\n",
    "        do_eval=True,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=1024,\n",
    "        report_to='tensorboard',\n",
    "        save_strategy='epoch',\n",
    "        logging_strategy=\"epoch\",\n",
    "        save_total_limit=3,\n",
    "        logging_dir='./dump/etth2/finetune_prediction/logs',  # Make sure to specify a logging directory\n",
    "        \n",
    "        load_best_model_at_end=True,  # Load the best model when training ends\n",
    "        metric_for_best_model=\"eval_loss\",  # Metric to monitor for early stopping\n",
    "        greater_is_better=False,  # For loss\n",
    "    )\n",
    "\n",
    "finetune_prediction_trainer = Trainer(\n",
    "    model=finetune_prediction_model,\n",
    "    args=finetune_prediction_args,\n",
    "    train_dataset=dset_train,\n",
    "    eval_dataset=dset_val,\n",
    "    callbacks=[early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b01afc36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15876' max='25200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15876/25200 02:51 < 01:41, 92.31 it/s, Epoch 63/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.700700</td>\n",
       "      <td>0.265937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.583400</td>\n",
       "      <td>0.252445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.542200</td>\n",
       "      <td>0.247008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.512900</td>\n",
       "      <td>0.246625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.493400</td>\n",
       "      <td>0.241394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.481700</td>\n",
       "      <td>0.238852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.475600</td>\n",
       "      <td>0.237129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.467800</td>\n",
       "      <td>0.237282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.460200</td>\n",
       "      <td>0.238435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.452800</td>\n",
       "      <td>0.238463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.449100</td>\n",
       "      <td>0.237656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.443900</td>\n",
       "      <td>0.236127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.439300</td>\n",
       "      <td>0.234764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.435600</td>\n",
       "      <td>0.234314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.432100</td>\n",
       "      <td>0.234812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.425600</td>\n",
       "      <td>0.234329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.423700</td>\n",
       "      <td>0.237624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.420700</td>\n",
       "      <td>0.235130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.417300</td>\n",
       "      <td>0.237198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.413800</td>\n",
       "      <td>0.234289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.409500</td>\n",
       "      <td>0.236680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.406400</td>\n",
       "      <td>0.235558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.402800</td>\n",
       "      <td>0.231179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.400800</td>\n",
       "      <td>0.232898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.396800</td>\n",
       "      <td>0.233225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.391000</td>\n",
       "      <td>0.231323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.389200</td>\n",
       "      <td>0.229587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.385900</td>\n",
       "      <td>0.228643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.384100</td>\n",
       "      <td>0.226545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.382600</td>\n",
       "      <td>0.225939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.381600</td>\n",
       "      <td>0.226443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.375300</td>\n",
       "      <td>0.227107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.376500</td>\n",
       "      <td>0.224848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.373500</td>\n",
       "      <td>0.225849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.387300</td>\n",
       "      <td>0.222165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.373100</td>\n",
       "      <td>0.222764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.368500</td>\n",
       "      <td>0.226558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.370600</td>\n",
       "      <td>0.224675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.368200</td>\n",
       "      <td>0.224992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.365700</td>\n",
       "      <td>0.223841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.366400</td>\n",
       "      <td>0.223709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.364800</td>\n",
       "      <td>0.221558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.362400</td>\n",
       "      <td>0.220314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.362300</td>\n",
       "      <td>0.223481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.224415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.362200</td>\n",
       "      <td>0.223230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.361900</td>\n",
       "      <td>0.222140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.360700</td>\n",
       "      <td>0.222750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.362100</td>\n",
       "      <td>0.222872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.361900</td>\n",
       "      <td>0.223307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.357900</td>\n",
       "      <td>0.220012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.357500</td>\n",
       "      <td>0.223765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.358300</td>\n",
       "      <td>0.219327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.359000</td>\n",
       "      <td>0.221202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.356100</td>\n",
       "      <td>0.221299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.355700</td>\n",
       "      <td>0.220476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.355000</td>\n",
       "      <td>0.222173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.357000</td>\n",
       "      <td>0.220646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.355200</td>\n",
       "      <td>0.220801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.354300</td>\n",
       "      <td>0.220351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.220629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.352400</td>\n",
       "      <td>0.221252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.354300</td>\n",
       "      <td>0.221131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15876, training_loss=0.40379803917755797, metrics={'train_runtime': 172.0215, 'train_samples_per_second': 4669.766, 'train_steps_per_second': 146.493, 'total_flos': 2134580784021504.0, 'train_loss': 0.40379803917755797, 'epoch': 63.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_prediction_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9334450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3648090660572052,\n",
       " 'eval_runtime': 0.0856,\n",
       " 'eval_samples_per_second': 32525.663,\n",
       " 'eval_steps_per_second': 35.037,\n",
       " 'epoch': 63.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_prediction_trainer.evaluate(dset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96316210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.21932737529277802,\n",
       " 'eval_runtime': 0.0857,\n",
       " 'eval_samples_per_second': 32503.309,\n",
       " 'eval_steps_per_second': 35.013,\n",
       " 'epoch': 63.0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_prediction_trainer.evaluate(dset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "441b522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_prediction_trainer.save_model(\"./dump/etth2/finetune_prediction/patchtsmixer_finetune_prediction_etth2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13491baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<accelerate.data_loader.DataLoaderShard at 0x152ad99804c0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get train dataloader\n",
    "eval_dataloader = finetune_prediction_trainer.get_eval_dataloader()\n",
    "eval_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b378b8a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_model = PatchTSMixerForForecasting.from_pretrained('./dump/etth2/finetune_prediction/patchtsmixer_finetune_prediction_etth2').to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6801092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['context_values', 'target_values'])\n",
      "torch.Size([1024, 512, 7]) torch.Size([1024, 96, 7])\n"
     ]
    }
   ],
   "source": [
    "for X in eval_dataloader:\n",
    "    print(X.keys())\n",
    "    print(X[\"context_values\"].shape, X[\"target_values\"].shape)\n",
    "    torch.save(X, \"./dump/etth2/finetune_prediction/batch_prediction.pt\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8398422e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 96, 2])\n",
      "tensor([[-0.0119, -0.1193]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "loaded_model.eval()\n",
    "with torch.no_grad():\n",
    "    output_batch = loaded_model(X[\"context_values\"])\n",
    "print(output_batch.prediction_logits.shape)\n",
    "print(output_batch.prediction_logits[0, :1, :7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3285747",
   "metadata": {},
   "source": [
    "Note that, the output has only 2 channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c727630",
   "metadata": {},
   "source": [
    "## 5. Register model under Auto Classes and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1b02cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModel, AutoModelForPreTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6de52cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoConfig.register(\"patchtsmixer\", PatchTSMixerConfig)\n",
    "AutoModelForPreTraining.register(PatchTSMixerConfig, PatchTSMixerForMaskPretraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4741df98",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_model = AutoModelForPreTraining.from_pretrained('./dump/etth2/pretrain/patchtsmixer_pretrained_etth2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3979c6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.5046,  0.5407,  0.6637,  ..., -0.5177, -0.3761, -0.3467],\n",
       "          [-0.6514, -0.4129, -0.4830,  ...,  0.2448,  0.0976, -0.0072],\n",
       "          [-0.3787, -0.4964, -0.5847,  ..., -0.3529, -0.4473, -0.3129],\n",
       "          ...,\n",
       "          [-0.0609, -0.1377, -0.2635,  ...,  0.2893,  0.2889,  0.2220],\n",
       "          [ 0.4848,  0.7081,  0.8978,  ..., -0.3479, -0.1105, -0.3441],\n",
       "          [-0.1160, -0.0881, -0.0425,  ...,  0.3956,  0.3633,  0.2666]],\n",
       "\n",
       "         [[ 0.0827,  0.0317,  0.0927,  ...,  0.0183,  0.0377, -0.0851],\n",
       "          [ 0.0046, -0.0397, -0.0711,  ...,  0.2167,  0.2533,  0.2675],\n",
       "          [ 0.1585,  0.2033,  0.2134,  ..., -0.0770, -0.1297, -0.1355],\n",
       "          ...,\n",
       "          [ 0.1645,  0.2196,  0.2308,  ..., -0.0310, -0.0756, -0.0950],\n",
       "          [ 0.0134,  0.0433,  0.0939,  ...,  0.3673,  0.8900,  0.4729],\n",
       "          [ 0.0557,  0.0191, -0.0209,  ...,  0.3192,  0.3686,  0.3812]],\n",
       "\n",
       "         [[ 0.3790,  0.3740,  0.4299,  ..., -0.7452, -0.5525, -0.4198],\n",
       "          [-0.8011, -0.5474, -0.6288,  ..., -0.1263, -0.1924, -0.3038],\n",
       "          [-0.6827, -0.7230, -0.8078,  ..., -0.4311, -0.5395, -0.4704],\n",
       "          ...,\n",
       "          [-0.0135, -0.0229, -0.1383,  ...,  0.4856,  0.4547,  0.3363],\n",
       "          [ 0.6248,  0.7971,  0.9352,  ..., -0.2028, -0.0506, -0.2999],\n",
       "          [-0.0312,  0.0053,  0.0716,  ...,  0.3965,  0.3611,  0.2541]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.3628,  0.5428,  0.9298,  ...,  0.9516,  0.7079,  0.4415],\n",
       "          [ 0.1597,  0.1504,  0.1437,  ...,  1.5255,  1.3220,  1.4360],\n",
       "          [ 0.7908,  0.6218,  0.5666,  ...,  0.2352,  0.1785,  0.2294],\n",
       "          ...,\n",
       "          [-0.1982, -0.4107, -0.4463,  ..., -0.5493, -0.5603, -0.2975],\n",
       "          [-0.5290, -0.4871, -0.1884,  ..., -0.4824,  0.1279,  0.2689],\n",
       "          [-0.3797, -0.4190, -0.4775,  ...,  0.0592,  0.0951,  0.1305]],\n",
       "\n",
       "         [[ 0.3509,  0.4080,  0.4626,  ..., -0.2421, -0.3825, -0.4061],\n",
       "          [-0.3459, -0.4460, -0.4438,  ...,  0.7406,  0.7804,  0.7870],\n",
       "          [ 0.3909,  0.0865,  0.1358,  ..., -0.4096, -0.4048, -0.3081],\n",
       "          ...,\n",
       "          [ 0.8044,  0.7625,  0.4220,  ...,  0.8094,  0.7179,  0.5376],\n",
       "          [ 0.3079,  0.4833,  0.8670,  ...,  0.4754,  0.7579,  0.9303],\n",
       "          [ 0.2416,  0.2041,  0.1903,  ...,  0.7772,  0.7811,  0.7689]],\n",
       "\n",
       "         [[ 0.5168,  0.5428,  0.5165,  ...,  0.1571,  0.0953,  0.0825],\n",
       "          [ 0.2482,  0.3219,  0.3759,  ..., -0.2487, -0.4015, -0.4678],\n",
       "          [-0.5815, -0.6305, -0.6717,  ...,  0.5403,  0.5827,  0.5632],\n",
       "          ...,\n",
       "          [-0.5657, -0.7006, -0.8191,  ...,  1.2073,  1.3848,  1.4332],\n",
       "          [ 1.0882,  0.9749,  0.7887,  ..., -0.5293, -0.5174, -0.4464],\n",
       "          [ 0.4322,  0.4934,  0.5862,  ...,  0.2454,  0.1831,  0.1294]]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# auto_model(test_data.to('mps')).prediction_logits\n",
    "auto_model(dset_test.__getitem__(0)['context_values'].reshape(1,seq_len,n_features)).prediction_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524412e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
